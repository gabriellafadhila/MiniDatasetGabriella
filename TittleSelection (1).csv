type_of_reference,authors,primary_title,title,publication_year,year,abstract
JOUR,"Kanbar, Lara J., Mishra, Anagh, Osborn, Alexander, Cifuentes, Andrew, Combs, Jennifer, Sorter, Michael, Barzman, Drew, Dexheimer, Judith W.",Investigation of bias in the automated assessment of school violence,,,2024,"Objectives Natural language processing and machine learning have the potential to lead to biased predictions. We designed a novel Automated RIsk Assessment (ARIA) machine learning algorithm that assesses risk of violence and aggression in adolescents using natural language processing of transcribed student interviews. This work evaluated the possible sources of bias in the study design and the algorithm, tested how much of a prediction was explained by demographic covariates, and investigated the misclassifications based on demographic variables. Methods We recruited students 10–18 years of age and enrolled in middle or high schools in Ohio, Kentucky, Indiana, and Tennessee. The reference standard outcome was determined by a forensic psychiatrist as either a “high” or “low” risk level. ARIA used L2-regularized logistic regression to predict a risk level for each student using contextual and semantic features. We conducted three analyses: a PROBAST analysis of risk in study design; analysis of demographic variables as covariates; and a prediction analysis. Covariates were included in the linear regression analyses and comprised of race, sex, ethnicity, household education, annual household income, age at the time of visit, and utilization of public assistance. Results We recruited 412 students from 204 schools. ARIA performed with an AUC of 0.92, sensitivity of 71%, NPV of 77%, and specificity of 95%. Of these, 387 students with complete demographic information were included in the analysis. Individual linear regressions resulted in a coefficient of determination less than 0.08 across all demographic variables. When using all demographic variables to predict ARIA’s risk assessment score, the multiple linear regression model resulted in a coefficient of determination of 0.189. ARIA performed with a lower False Negative Rate (FNR) of 15.2% (CI [0 – 40]) for the Black subgroup and 12.7%, CI [0 – 41.4] for Other races, compared to an FNR of 26.1% (CI [14.1 – 41.8]) in the White subgroup. Conclusions Bias assessment is needed to address shortcomings within machine learning. In our work, student race, ethnicity, sex, use of public assistance, and annual household income did not explain ARIA’s risk assessment score of students. ARIA will continue to be evaluated regularly with increased subject recruitment."
JOUR,"Kazerouni, Ayaan M., Davis, James C., Basak, Arinjoy, Shaffer, Clifford A., Servant, Francisco, Edwards, Stephen H.",Fast and accurate incremental feedback for students’ software tests using selective mutation analysis,,,2021,"As incorporating software testing into programming assignments becomes routine, educators have begun to assess not only the correctness of students’ software, but also the adequacy of their tests. In practice, educators rely on code coverage measures, though its shortcomings are widely known. Mutation analysis is a stronger measure of test adequacy, but it is too costly to be applied beyond the small programs developed in introductory programming courses. We demonstrate how to adapt mutation analysis to provide rapid automated feedback on software tests for complex projects in large programming courses. We study a dataset of 1389 student software projects ranging from trivial to complex. We begin by showing that although the state-of-the-art in mutation analysis is practical for providing rapid feedback on projects in introductory courses, it is prohibitively expensive for the more complex projects in subsequent courses. To reduce this cost, we use a statistical procedure to select a subset of mutation operators that maintains accuracy while minimizing cost. We show that with only 2 operators, costs can be reduced by a factor of 2–3 with negligible loss in accuracy. Finally, we evaluate our approach on open-source software and report that our findings may generalize beyond our educational context."
JOUR,"Biao, Zhang Zong",Design and realization of data mining simulation and methodological models,,,2023,"Data mining in education is steadily gaining momentum to explore the learning analytics because of its easy to use with any programming knowledge. This emerging method primarily focus on developing methods for handling and exploring voluminous information represented in distinct types of data. Deployment of data mining in education helps to better understand the synergy between the learning and educational settings established by the institutions to foster their learning activity. This work presents a data mining based virtual simulation experimental teaching system which provisions personalized interactive learning, real-world scene experimental training and comprehensive assessment of the learning effect. The proposed system employs interactive programming, automatic evaluation of experimental results, assessing the impact of teaching effectiveness with other modules. The work also provides a series of comprehensive cases and programming experiments apart from presenting the execution pages. The results indicate that this system can intuitively help students to improve their learning process, student participation and foster independent learning ability. The application of data mining alleviates the dependency on complex programming paradigms to make learning analytics, which is beneficial to both the teaching and learning communities."
JOUR,"Santos Vieira, Felipe Alexandre, Vinhas Santos, Davi Teles, Bragagnolo, Chiara, Campos-Silva, João Vitor, Henriques Correia, Ricardo Aleixo, Jepson, Paul, Mendes Malhado, Ana Claudia, Ladle, Richard James",Social media data reveals multiple cultural services along the 8.500 kilometers of Brazilian coastline,,,2021,"Cultural ecosystem services (CES) are benefits that people receive from ecosystems, for example, through spiritual enrichment, cognitive development, recreation, and aesthetic experiences. These are important contributors to human well-being, but are challenging to measure due to their intangible nature and because they may vary spatially depending on ecosystem condition and restrictions on use. Here, we employ a big data methodology to identify CES over a large scale case study with the purpose of providing insights for marine and coastal management. First, we used machine learning to identify features present in 21,789 Flickr photographs taken across approximately 8,500 km of the Brazilian coastline. Then, we associated the keywords describing the identified features with broad CES categories allowing us to identify and map the geographical distribution of cultural services. We found that CES related to aesthetic experiences were more represented in photographs taken in protected areas, while other forms of cultural value (e.g. sport recreation, social recreation) were more frequent in unprotected areas. Notwithstanding the unavoidable biases in favour of certain CES representations, our results illustrate diverse forms of cultural services generated by the Brazilian coast. While there was a generally higher provision of CES per user in protected areas reflecting their enhanced potential to support tourism and other CES-related activities, the image classification algorithm was not able to identify CES which are less dependent on the biophysical domain such as spiritual values, inspiration, education and arts. We believe that our approach can be applied at broader scales (continental and global) in order to uncover cultural services in multiple environments while strongly recommending integration with social science based methodologies and expertise. We further advocate for the employment of such automatic evaluation at local scale as a tool to complement other approaches in support of protected area management, including resource allocation and investments to potentialize CES (i.e. recreational infrastructure, wildlife observation posts) or other relevant ecosystem services."
JOUR,"Ling, Jintao, Afzaal, Muhammad",Automatic question-answer pairs generation using pre-trained large language models in higher education,,,2024,"The process of manually generating question and answer (QA) pairs for assessments is known to be a time-consuming and energy-intensive task for teachers, specifically in higher education. Several studies have proposed various methods utilising pre-trained large language models for the generation of QA pairs. However, it is worth noting that these methods have primarily been evaluated on datasets that are not specifically educational in nature. Furthermore, the evaluation metrics and strategies employed in these studies differ significantly from those typically used in educational contexts. The present discourse fails to present a compelling case regarding the efficacy and practicality of stated methods within the context of higher education. This study aimed to examine multiple QA pairs generation approaches in relation to their performance and the efficacy and constraints within the context of higher education. The various approaches encompassed in this study comprise pipeline, joint, multi-task approach. The performance of these approaches under consideration was assessed on three datasets related to distinct courses. The evaluation integrates three automated methods, teacher assessments, and real-world educational evaluations to provide a comprehensive analysis. The comparison of various approaches was conducted by directly assessing their performance using the average scores of different automatic metrics on three datasets. The results of the teachers and real educational evaluation indicate that the assessments generated were beneficial in enhancing the understanding of concepts and overall performance of students. The implications of the findings from this study hold significant importance in enhancing the efficacy of QA pair generation tools within the context of higher education."
JOUR,"Pino Castillo, Patricio A., Soto, Christian, Asún, Rodrigo A., Gutiérrez, Fernando",Profiling support in literacy development: Use of natural language processing to identify learning needs in higher education,,,2023,"Reading and writing are core activities in higher education, by means of which students learn to participate in specialized discourses. Although there is consensus on the conceptualization of reading comprehension, its measurement, and development, the same is not true for written expression. Writing complexity has been found to improve with schooling, but there are ample differences between literacy practices at school and at the university that require extra attention in diagnosing students’ compositions. The present study set out to test a natural language processing tool to build domain profiles of writing complexity in first-year university students at a private university. The processing of texts resulted in 49 indices which, after exploratory factor analysis and theoretical discussion, gave rise to 4 dimensions of complexity explaining 52.3% of variance: lexical richness, syntactic complexity, informative text structure and specialized language use. Significant differences were found between more and less skilled writers in the aggregated scores, lexical richness, and syntactic complexity. Interestingly, novice and expert writers did not differ significantly in more over-arching aspects of writing. We discuss how this technology can help identify students’ needs in more superficial aspects of writing complexity that have been shown to improve by means of different strategies."
JOUR,"Wang, Lu, Mao, Yuqiang, Wang, Lin, Sun, Yujie, Song, Jiangdian, Zhang, Yang",Suitability of GPT-4o as an evaluator of cardiopulmonary resuscitation skills examinations,,,2024,"Aim To assess the accuracy and reliability of GPT-4o for scoring examinees’ performance on cardiopulmonary resuscitation (CPR) skills tests. Methods This study included six experts certified to supervise the national medical licensing examination (three junior and three senior) who reviewed the CPR skills test videos across 103 examinees. All videos reviewed by the experts were subjected to automated assessment by GPT-4o. Both the experts and GPT-4o scored the videos across four sections: patient assessment, chest compressions, rescue breathing, and repeated operations. The experts subsequently rated GPT-4o’s reliability on a 5-point Likert scale (1, completely unreliable; 5, completely reliable). GPT-4o’s accuracy was evaluated using the intraclass correlation coefficient (for the first three sections) and Fleiss’ Kappa (for the last section) to assess the agreement between its scores vs. those of the experts. Results The mean accuracy scores for the patient assessment, chest compressions, rescue breathing, and repeated operation sections were 0.65, 0.58, 0.60, and 0.31, respectively, when comparing the GPT-4o’s vs. junior experts’ scores and 0.75, 0.65, 0.72, and 0.41, respectively, when comparing the GPT-4o’s vs. senior experts’ scores. For reliability, the median Likert scale scores were 4.00 (interquartile range [IQR] = 3.66–4.33, mean [standard deviation] = 3.95 [0.55]) and 4.33 (4.00–4.67, 4.29 [0.50]) for the junior and senior experts, respectively. Conclusions GPT-4o demonstrated a level of accuracy that was similar to that of senior experts in examining CPR skills examination videos. The results demonstrate the potential for deploying this large language model in medical examination settings."
JOUR,"Novotny, Michal, Cmejla, Roman, Tykalova, Tereza",Automated prediction of children's age from voice acoustics,,,2023,"The emergence of a variety of applications aimed at video gaming, parental control, education, specific language impairment, child development assessment, and speech therapy create demands for age-targeted approaches. Yet, there is a lack of methods providing robust and easily interpretable age estimation of speakers from early childhood to post-pubertal stage. This study aims to provide a fully-automated approach for children's age prediction based on voice acoustics. Sustained phonation of vowels /a/, /e/, /i/, /o/, and /u/ recorded from 255 speakers (132 girls and 123 boys) ranging between 4 and 15 years of age were analysed. The first three formant frequencies and fundamental frequency across each vowel were automatically evaluated and used as features for linear and nonlinear regressors to estimate the prediction model. We demonstrate rapid, accurate age estimation with reasonable accuracy of an average 1.3-year difference from actual children's chronological age. The lower age prediction error of 1.2 years was achieved for boys compared to 1.5 years for girls. The early childhood age from 4 to 5 years was less accurate for prediction. No effect of utterance duration on estimated results was observed. Our results present a robust technology with clinically interpretable outcomes insusceptible to overfitting that enables to predict children's age in a wide range of ages. Better prediction accuracy for boys than girls appears to reflect the faster vocal tract growth for men. The lower prediction accuracy in early childhood can be attributed to rapid nonlinear development and greater variability in the level of motor control maturation."
JOUR,"Polito, Giuseppina, Temperini, Marco",A gamified web based system for computer programming learning,,,2021,"The availability of Automated Assessment tools for computer programming tasks can be a significant asset in Computer Science education. Systems providing such kind of service are built around an interface, allowing to administer the tasks (exercises to train programming skills), and show the results, accompanied by meaningful feedback. To produce such results, they apply techniques ranging from static analysis of program correctness, to testing-based evaluation. These systems can also support Competitive Programming, which is known to have educational meaning too. We developed the 2TSW system, supporting the automated correction of computer programming tasks, in a gamified web-based environment. The system let the student access a list of assignments (programming tasks), submit solutions to them, and have such solutions tested and graded. Accomplished tasks let the student gain experience points, represented also by medals, recognition of mastery on a topic, and improvements on a personal characterization of the student's status. The personal profile allows the student to monitor her/his proceedings and achievements. The gamified structure of the system, together with the availability of real-time automated assessment, offers the opportunity for an increasing level of students' personal engagement and motivation. Here we describe the system, and report on an experimentation, where students of a Bachelor Programme in Computer Engineering, first year, used 2TSW. In particular, we 1) present findings about the students' feedback, coming from a questionnaire administered after the experience, and 2) provide the reader with an analysis of the participation data, based on simple statistic tests. The students' feedback let us conclude that they appreciated the 2TSW gamified experience, perceived the system as useful, and maintained a high level of engagement. The data analysis allowed for less decisive conclusions, although it showed proof of the effectiveness of the system as a learning aid."
JOUR,"Chaudhuri, Nandita Bhanja, Dhar, Debayan, Yammiyavar, Pradeep G.",Automating assessment of design exams: A case study of novelty evaluation,,,2022,"An inherent criterion of evaluation in Design education is novelty. Novelty is a measure of newness in solutions which is evaluated based on relative comparison with its frame of reference. Evaluating novelty is subjective and generally depends on expert’s referential metrics based on their knowledge and persuasion. Pedagogues compare and contrast solution for cohort of students in mass examination aspiring admission to Design schools. Large number of students participate in mass examinations, and in situations like this, examiners are confronted with multiple challenges in subjective evaluation such as- 1) Errors encountered in evaluation due to stipulated timeline, 2) Errors encountered due to prolonged working hours, 3) Errors encountered due to stress in performing repeated task on a large-scale. Pedagogues remain ever-inquisitive and vigilant about the evaluation process being consistent and accurate due to monotony of repeated task. To mitigate these challenges, a computational model is proposed for automating evaluation of novelty in image-based solutions. This model is developed by mixed-method research, where features for evaluating novelty are investigated by conducting a survey study. Further, these features were utilized to evaluate novelty and generate score for image-based solutions using Computer Vision (CV) and Deep Learning (DL) techniques. The performance metric of the model when measured reveals a negligible difference between scores of experts and scores of proposed model. These comparative analysis of the proposed model with human experts’ confirm the competence of the devised model and would go a long way to establish trust of pedagogues by ensuring reduced error and stress during the evaluation process."
JOUR,"Sun, Xiaoning, Fan, Tao, Li, Hongxu, Wang, Guozhong, Ge, Peien, Shang, Xiwu",CLIP2TF:Multimodal video–text retrieval for adolescent education,,,2024,"With the rapid advancement of artificial intelligence technology, particularly within the sphere of adolescent education, a continual emergence of new challenges and opportunities is observed. The current educational system increasingly requires the automation of teaching activities detection and evaluation, offering fresh perspectives for enhancing the quality of adolescent education. Although large-scale models are receiving significant attention in educational research, their high demand for computational resources and limitations in specific applications constrain their widespread use in analyzing educational video content, especially when handling multimodal data. Current multimodal contrastive learning methods, which integrate video, audio, and text information, have achieved certain successes in video–text retrieval tasks. However, these methods typically employ simpler weighted fusion strategies and fail to avoid noise and information redundancy. Therefore, our study proposes a novel network framework, CLIP2TF, which includes an efficient audio–visual fusion encoder. It aims to dynamically interact and integrate visual and audio features, further enhancing the visual features that may be missing or insufficient in specific teaching scenarios while effectively reducing redundant information transfer during the modality fusion process. Through ablation experiments on the MSRVTT and MSVD datasets, we first demonstrate the effectiveness of CLIP2TF in video–text retrieval tasks. Subsequent tests on teaching video datasets further proves the applicability of the proposed method. This research not only showcases the potential of artificial intelligence in the automated assessment of teaching quality but also provides new directions for research in related fields studies."
JOUR,"Lou, Yingying, Li, Fan",Design of an online education student learning status evaluation model based on dual-improved neural networks,,,2024,"With the continuous development of network technology, online education has become an important form of education. However, in the online education model, it is difficult for educators to effectively evaluate students' learning status, and using a learning status evaluation model can effectively solve this problem. The main goal of this model is to comprehensively evaluate students' learning behavior, progress, and outcomes, in order to understand their learning status, provide effective teaching feedback to teachers, help students improve learning methods, and improve learning efficiency. The current automatic evaluation model for student learning status has certain limitations in terms of applicability and accuracy. A student learning state evaluation model based on Multi task Cascaded Convolutional Networks (MTCNN) is proposed to address the effectiveness of online education student learning state evaluation. Use the facial image acquisition function to extract students' facial features, process each feature through label classification, and then analyze the students' attention and learning emotions. Finally, analyze the effectiveness of the research method application. The results showed that the train_loss value of the learning state evaluation model proposed in the study can be reduced to about 0.1; the train_acc value can reach more than 95 %, and the overall volatility is small; the overall evaluation accuracy of facial expressions can reach 74.71 %, which is significantly better than cpc, VGG19 and other evaluation methods; compared with the comprehensive evaluation results and multi-modal analysis methods, only two evaluations at the critical value are different. The experimental results show that the online education students’ learning status evaluation model designed by the research has a high accuracy rate and has a certain application potential in the field of online education."
JOUR,"Sagheb, Elham, Wi, Chung-Il, Yoon, Jungwon, Seol, Hee Yun, Shrestha, Pragya, Ryu, Euijung, Park, Miguel, Yawn, Barbara, Liu, Hongfang, Homme, Jason, Juhn, Young, Sohn, Sunghwan",Artificial Intelligence Assesses Clinicians’ Adherence to Asthma Guidelines Using Electronic Health Records,,,2022,"Background Clinicians’ asthma guideline adherence in asthma care is suboptimal. The effort to improve adherence can be enhanced by assessing and monitoring clinicians’ adherence to guidelines reflected in electronic health records (EHRs), which require costly manual chart review because many care elements cannot be identified by structured data. Objective This study was designed to demonstrate the feasibility of an artificial intelligence tool using natural language processing (NLP) leveraging the free text EHRs of pediatric patients to extract key components of the 2007 National Asthma Education and Prevention Program guidelines. Methods This is a retrospective cross-sectional study using a birth cohort with a diagnosis of asthma at Mayo Clinic between 2003 and 2016. We used 1,039 clinical notes with an asthma diagnosis from a random sample of 300 patients. Rule-based NLP algorithms were developed to identify asthma guideline-congruent elements by examining care description in EHR free text. Results Natural language processing algorithms demonstrated a sensitivity (0.82-1.0), specificity (0.95-1.0), positive predictive value (0.86-1.0), and negative predictive value (0.92-1.0) against manual chart review for asthma guideline-congruent elements. Assessing medication compliance and inhaler technique assessment were the most challenging elements to assess because of the complexity and wide variety of descriptions. Conclusions Natural language processing technologies may enable the automated assessment of clinicians’ documentation in EHRs regarding adherence to asthma guidelines and can be a useful population management and research tool to assess and monitor asthma care quality. Multisite studies with a larger sample size are needed to assess the generalizability of these NLP algorithms."
JOUR,"Yamada, Toshiyuki, Suda, Hisao, Yoshitake, Akihiro, Shimizu, Hideyuki",Development of an Automated Smartphone-Based Suture Evaluation System,,,2022,"Objective Quantification of skill level in surgical training is necessary for effective skill development. In this study, we report the development of a smartphone application that automatically and objectively evaluates training in stitching goldfish scoop poi, a fragile material currently used for practice by young surgeons in Japan. Methods The application, named “e-Suture,” enables the automatic evaluation of surgical technique quality by evaluating the gap between the mark printed on the poi and the insertion/extraction point of the needle (Accuracy), analyzing suture placement (Deflection), detecting tears in the poi material/tissue (Tears), and the time taken to perform the exercise (Time). The algorithm for scoring used a sigmoid function, and the coefficients were adjusted so that the scores of a sample of 20 cases ranged between 20 and 100 points. Results The e-Suture prototype was completed. The e-Suture-derived ranking for 20 poi after training was significantly correlated with the mean of the rankings evaluated by 9 experts (correlation coefficient: 0.728; p = 0.000). We also tested which items the experts rated as the most important. The overall ratings obtained from the experts correlated with the e-Suture accuracy scoring results with a correlation coefficient of 0.836 (p = 0.000) for Accuracy, 0.31 (p = 0.173) for Deflection, and 0.518 (p = 0.019) for Tear. Conclusion The e-Suture application can easily and accurately quantify and evaluate the suturing skills of novie surgeons. Further studies should improve the accuracy of data to be analyzed by collecting more surgical data and applying it to other surgical techniques."
JOUR,"Rayhan, MD., Alam, MD. Golam Rabiul, Dewan, M. Ali Akber, Ahmed, M. Helal Uddin",Appraisal of high-stake examinations during SARS-CoV-2 emergency with responsible and transparent AI: Evidence of fair and detrimental assessment,,,2022,"In situations like the coronavirus pandemic, colleges and universities are forced to limit their offline and regular academic activities. Extended postponement of high-stakes exams due to health risk hereby reduces productivity and progress in later years. Several countries decided to organize the exams online. Since many other countries with large education boards had an inadequate infrastructure and insufficient resources during the emergency, education policy experts considered a solution to simultaneously protect public health and fully resume high-stakes exams -by canceling offline exam and introducing a uniform assessment process to be followed across the states and education boards. This research proposes a novel system using an AI model to accomplish the complex task of evaluating all students across education boards with maximum level of fairness and analyzes the ability to fairly appraise exam grades in the context of high-stakes examinations during SARS-CoV-2 emergency. Basically, a logistic regression classifier on top of a deep neural network is used to output predictions that are as fair as possible for all learners. The predictions of the proposed grade-awarding system are explained by the SHAP (SHapley Additive exPlanations) framework. SHAP allowed to identify the features of the students' portfolios that contributed most to the predicted grades. In the setting of an empirical analysis in one of the largest education systems in the Global South, 81.85% of learners were assigned fair scores while 3.12% of the scores were significantly smaller than the actual grades, which would have had a detrimental effect if it had been applied for real. Furthermore, SHAP allows policy-makers to debug the predictive model by identifying and measuring the importance of the factors involved in the model's final decision and removing those features that should not play a role in the model's “reasoning” process."
JOUR,"Larraga-García, Blanca, Monforte-Escobar, Fernando, Quintero Mínguez, Rubén, Quintana-Díaz, Manuel, Gutiérrez, Álvaro",Modified Needleman-Wunsch algorithm for trauma management performance evaluation,,,2023,"Background Trauma injuries are one of the leading causes of death in the world, representing approximately 8 % of all deaths. Therefore, trauma management training is of great importance and new training courses have arisen during the last decades. However, actual training courses do not typically analyze compliance with the protocols and guidelines available in the literature. Considering general trauma management guidelines such as the Advanced Trauma Life Support (ATLS) manual and the expertise of trauma specialists, a trauma management automated evaluation system has been designed in this paper. Methods A modification to the Needleman-Wunsch (NW) algorithm is developed, including all relevant aspects of trauma management to automatically evaluate how a trauma intervention has been implemented according to trauma protocols. This allows to consider more information with respect to the order of the actions taken and the type of actions performed than current evaluation methods, such as checklists or videos recorded in simulation. A web-based trauma simulator is used so that it can be used at any setting with internet connection. Final-year medical students and first- and second-year residents performed an experimental test, where a trauma score is obtained with the modified NW algorithm. This automatic score relates to how similar the actions are to trauma protocols. Results The results show the best combination of the scores used for the modified NW variables. This combination has an error, for the different case scenarios created, below 0.07 which verifies the values obtained. Additionally, trauma experts verified the results obtained showing a median difference of 0 between the protocol adherence evaluation using the algorithm and the one provided by the trauma experts. Conclusions The best set of score values to apply to the modified NW algorithm show that the modified NW algorithm provides a successful objective measurement with respect to the protocol compliance."
JOUR,"D. Galan, R. Heradio, H. Vargas, I. Abad, J. A. Cerrada",,Automated Assessment of Computer Programming Practices: The 8-Years UNED Experience,2019,2019,"The increasing popularity of distance education poses exciting new challenges. In particular, current pedagogical paradigms, such as competency-based education, require students' continuous evaluation. That is, to master skills, students need to receive constant feedback to guide their experimentation processes. However, teaching teams are usually under-dimensioned to support the large number of students that online courses usually have. This paper presents the approach we have adopted at the National University of Distance Education to overcome this problem for the case of computer programming practices, which complements human evaluation with an automatic assessment system. The paper describes our system and reports its benefits with an empirical study from 2011 to 2018 that involved 14,944 students."
JOUR,"H. Vargas, R. Heradio, J. Chacon, L. De La Torre, G. Farias, D. Galan, S. Dormido",,Automated Assessment and Monitoring Support for Competency-Based Courses,2019,2019,"Competency-based education is becoming increasingly adopted by higher education institutions all over the world. This paper presents a framework that assists instructors in this pedagogical paradigm and its corresponding open-source implementation. The framework supports the formal definition of competency assessment models and the students' evaluation under these models. It also provides distinct learning analytics for identifying course shortcomings and validating corrective actions instructors have introduced in a course. Finally, this paper reports the benefits of applying our framework to an engineering course at the Pontifical Catholic University, Valparaíso, Chile for three years."
JOUR,M. Ge,,A Granular Computing-Based Deep Neural Network Approach for Automatic Evaluation of Writing Quality,2023,2023,"As a subjective behaviour relying on expert experience, automatic evaluation of writing quality always remains a technical issue. It requires both effective semantic understanding and structure analysis towards writing contents. To deal with this challenge, this paper combines speed superiority of granular computing and the effective approximation ability of deep neural network towards nonlinear mapping relationships. On this basis, a granular computing-based deep neural network approach for automatic evaluation of writing quality, is developed in this paper. Specifically, the granular computing is used as the front-end processor of deep neural network, so as to reduce the following information density. Then, the deep neural network serves as the main backbone structure to extract semantic features of writing contents. Such combination of two modules can improve processing speed in large-scale textual analysis scenes, under insurance of evaluation performance. The simulation experiments are also conducted to test performance of the proposed technical framework, and the results show that both high accuracy and proper running speed are endowed with the proposal."
JOUR,"J. Skalka, M. Drlík",,Development of Automatic Source Code Evaluation Tests Using Grey-Box Methods: A Programming Education Case Study,2023,2023,"Increasing the effectiveness of programming education has emerged as an important goal in teaching programming languages in the last decade. Automatic evaluation of the correctness of the student’s source code saves teachers time and effort and allows a more comprehensive focus on the preparation of assignments with integrated feedback. The study aims to present an approach that will enable effective testing of students’ source codes within object-oriented programming courses while minimising the demands on teachers when preparing the assignment. This approach also supports variability in testing and preventing student cheating. Based on the principles of different types of testing (black-box, white-box, grey-box), an integrated solution for source code verification was designed and verified. The basic idea is to use a reference class, which is assumed to be part of every assignment, as the correct solution. This reference class is compared to the student solution using the grey-box method. Due to their identical interface (defined by assignment), comparing instance states and method outputs is a matter of basic programming language mechanisms. A significant advantage is that a random generation of test cases can be used in such a case, while the rules for their generation can be determined using simple formulas. The proposed procedure was implemented and gradually improved over 4 years on groups of bachelor students of applied informatics with a high level of acceptance."
JOUR,"M. N. Demaidi, M. Qamhieh, A. Afeefi",,Applying Blended Learning in Programming Courses,2019,2019,"The C programming course is mandatory for undergraduate engineering students enrolled at universities in Palestine. The programming courses are taught by applying a traditional learning method in which the programming concepts are explained theoretically and minimal practical work is applied. In addition, students receive either no formative feedback or minimal manual delayed feedback after submitting their practical work. This negatively affects students' performance as students find it difficult to understand the programming concepts. This paper addresses the aforementioned drawbacks by applying blended learning for the first time to the C programming course which is taught to more than 1000 students each year at An-Najah National University, Palestine. Blended learning is a hybrid learning method which integrates the traditional learning method with technology and online learning. It provides students with more practical work and automated immediate formative feedback. This paper aims to study the effect of blended learning on students' performance, and students' satisfaction with the blended learning method. An independent experimental design was applied on 1374 undergraduate students enrolled in C programming course. Students were divided into two groups based on the learning method. The first group consisted of 632 students who studied the course using the traditional learning method, while the second group consisted of 742 students in which blended learning was applied. Quantitative and qualitative research methods were applied and the results revealed that blended learning improved student performance significantly compared with traditional learning. In addition, the results revealed that students were satisfied with the blended learning method in terms of easiness to use and suitability for programming and submitting assignments."
JOUR,"S. López-Pernas, M. Saqr",,Bringing Synchrony and Clarity to Complex Multi-Channel Data: A Learning Analytics Study in Programming Education,2021,2021,"Supporting teaching and learning programming with learning analytics is an active area of inquiry. Most data used for learning analytics research comes from learning management systems. However, such systems were not developed to support learning programming. Therefore, educators have to resort to other systems that support the programming process, which can pose a challenge when it comes to understanding students’ learning since it takes place in different contexts. Methods that support the combination of different data sources are needed. Such methods would ideally account for the time-ordered sequence of students’ learning actions. In this article, we use a novel method (multi-channel sequence mining with Hidden Markov Models, HMMs) that allows the combination of multiple data sources, accounts for the temporal nature of students’ learning actions, and maps the transitions between different learning tactics. Our study included 291 students enrolled in a higher education programming course. Students’ trace-log data were collected from the learning management system and from a programming automated assessment tool. Data were analyzed using multi-channel sequence mining and HMM. The results reveal different patterns of students’ approaches to learning programming. High achievers start earlier to work on the programming assignments, use more independent strategies and consume learning resources more frequently, while the low achievers procrastinate early in the course and rely on help forums. Our findings demonstrate the potentials of multi-channel sequence mining and how this method can be analyzed using HMM. Furthermore, the results obtained can be of use for educators to understand students’ strategies when learning programming."
JOUR,"H. Zhang, J. Wang",,A Smart Knowledge Discover System for Teaching Quality Evaluation via Genetic Algorithm-Based BP Neural Network,2023,2023,"The intelligent and automatic evaluation for teaching quality has been a more and more general demand in the digital society. The most intuitive solution is to make an assessment based on examination results, which cannot comprehensively reflect the course situation. To deal with such a problem, this paper designs a smart knowledge discovery system for teaching quality evaluation using a genetic algorithm-based BP neural network. Three aspects of factors are selected as the features: teaching conditions, teaching process, and teaching effect. The BP neural network is formulated to learn a nonlinear mapping from initial features to evaluation results. The learned parameters are then re-optimized by introducing the genetic algorithm. The proposed evaluation framework is also assessed concerning running performance on a real-world course-teaching dataset. The obtained results reflect that the proposal can realize the intelligent evaluation of the teaching effect and the evaluation effect is close to artificial experience-based evaluation results."
JOUR,"M. Campoverde-Molina, S. Luján-Mora, L. V. García",,Empirical Studies on Web Accessibility of Educational Websites: A Systematic Literature Review,2020,2020,"Web accessibility means that people with some type of disability can make use of the Web in the same conditions as the rest of the people. When we talk about web accessibility, we refer to a web design and development that allows these people to perceive, understand, navigate and interact with the Web. Web accessibility also benefits other people, including elderly people whose abilities have declined as a result of age. The Web is an essential resource in human activity: education, employment, government, commerce, health, entertainment and many others benefit of the power of the Web. The aim of this systematic literature review is to analyze the empirical methods of evaluating accessibility to educational websites, disabilities and their errors described in a total of 25 selected studies. The results show that in 20 of the 25 papers, web accessibility was evaluated with automatic tools, in 2 papers it was evaluated with real users and in the other 3 papers with automatic tools, real users and experts. There is also evidence that all the educational websites analyzed in the papers need to correct errors. In conclusion, educational websites do not meet any version of the Web Content Accessibility Guidelines (WCAG) and their conformance levels. According to the results, the empirical evaluation methods used for web accessibility could be improved by adopting automatic evaluation tools for website construction and manual mechanisms with web accessibility experts. The challenge for educational institutions is to carry out web accessibility projects to comply with WCAG and other web accessibility standards and current laws of educational inclusion."
JOUR,"K. A. Kroeze, S. M. van den Berg, B. P. Veldkamp, T. de Jong",,Automated Assessment of and Feedback on Concept Maps During Inquiry Learning,1 Aug. 2021,2021,"A tool is presented that can automatically assess the quality of students’ concept maps and provide feedback based on a reference concept map. It is shown that this tool can effectively assess the quality of concept maps, and that it can provide accurate and helpful feedback on a number of specific shortcomings often evident in students’ concept maps. However, it was also found that students who had access to feedback often did not request it, or did not take full advantage of the feedback given."
JOUR,"W. E. Villegas-Ch, J. Govea, R. Gutierrez, A. Mera-Navarrete",,Improving Interaction and Assessment in Hybrid Educational Environments: An Integrated Approach in Microsoft Teams With the Use of AI Techniques,2024,2024,"The current education landscape is marked by the growing integration of artificial intelligence technologies, which seek to improve interaction and efficiency in educational environments. However, many of these tools operate on separate platforms, complicating their use and reducing their potential effectiveness. This study introduces InteractiveClass, an innovative tool that fully integrates with Microsoft Teams, facilitating automated assessment and student interaction without requiring multiple interfaces. InteractiveClass encourages active student participation through real-time questions, quizzes, discussion forums, and other activities. In addition, it uses AI capabilities to offer immediate and personalized feedback and perform automatic evaluations. This integration improves usability and promotes student engagement in hybrid or fully online environments. Study results reveal significant improvements in assessment efficiency and student satisfaction. Students who used the tool showed a 30% increase in class participation and improved their grades by 25% compared to those who did not use it. Additionally, the tool demonstrated high consistency in assessments, with a precision of 95% compared to manual assessments. These findings underline the potential of InteractiveClass to transform education through AI technology, offering a practical and effective solution to the challenges of modern education."
JOUR,R. Wu,,A Hybrid Intelligence-Based Integrated Smart Evaluation Model for Vocal Music Teaching,2023,2023,"The smart evaluation for teaching effect has received much attention, especially in field of vocal music. Currently, such evaluation mainly relies on expert rating, which costs much human labors. Fortunately, the machine learning and deep learning-based techniques have been applied to evaluation affairs in a number of areas. This work takes the vocal music teaching as the main object, and introduces several typical intelligent algorithms to construct a smart evaluation workflow. Thus in this paper, a hybrid intelligence-based integrated smart evaluation model for vocal music teaching is proposed. First of all, a comprehensive evaluation system is formulated from mechanism as the main feature space. Then, convolutional neural network, long short-term memory network and multi-layer perceptrons are employed to establish a novel integrated structure as the main evaluation model. To assess the proposed technical framework in this paper, a case study is conducted and some simulation experiments are carried out for this purpose. The experimental results show that the proposal can well realize automatic evaluation for vocal music teaching."
JOUR,"H. -M. Chen, B. -A. Nguyen, Y. -X. Yan, C. -R. Dow",,Analysis of Learning Behavior in an Automated Programming Assessment Environment: A Code Quality Perspective,2020,2020,"Automated programming assessment systems are useful tools to track the learning progress of students automatically and thereby reduce the workload of educators. They can also be used to gain insights into how students learn, making it easier to formulate strategies aimed at enhancing learning performance. Rather than functional code which is always inspected, code quality remains an essential aspect to which not many educators consider when designing an automated programming assessment system. In this study, we applied data mining techniques to analyze the results of an automated assessment system to reveal unexpressed patterns in code quality improvement that are predictive of final achievements in the course. Cluster analysis is first utilized to categorize students according to their learning behavior and outcomes. Cluster profile analysis is then leveraged to highlight actionable factors that could affect their final grades. Finally, the same factors are employed to construct a classification model by which to make early predictions of the students' final results. Our empirical results demonstrate the efficacy of the proposed scheme in providing valuable insights into the learning behaviors of students in novice programming courses, especially in code quality assurance, which could be used to enhance programming performance at the university level."
JOUR,"A. Praveen Kumar, A. Nayak, M. Shenoy K., R. J. Manoj, A. Priyadarshi",,Pattern-Based Syntactic Simplification of Compound and Complex Sentences,2022,2022,"With the advent of new technologies, simplifying text automatically has been very popular and of high importance among natural language researchers during the last decade. The predominant research done in the area of Automatic Sentence Simplification(ASS) is inclined to either lexical or syntactical simplification of sentences. From the literature survey, it is observed that existing research in lexical simplification makes use of word substitution technique. This causes word sense ambiguity in cases where the word synonyms are not appropriate for a sentence in the given context. In contrast, syntactical simplification though accurate and applicable to Natural Language Processing (NLP) tasks, requires tremendous efforts to construct rules for a given domain. The research proposes a framework called Pattern-based Automatic Syntactic Simplification(PASS) which identifies sentences and applies rules based on grammatical patterns to simplify the sentences thereby making it more generic for NLP tasks. PASS is evaluated by human experts to rate the usefulness of the framework based on fluency, adequacy and simplicity of the sentences. Furthermore, the framework is automatically evaluated with the available online corpus using automatic metrics of SARI, BLEU, and FKGL. The proposed approach generates promising results in the field of ASS and could be used as a preliminary module for NLP tasks as well as other natural language-related applications like summarization, anaphora resolution, question-answering, and many more."
JOUR,"J. Xu, Y. Sun, J. Gan, M. Zhou, D. Wu",,Leveraging Structured Information from a Passage to Generate Questions,June 2023,2023,"Question Generation (QG) is the task of utilizing Artificial Intelligence (Al) technology to generate questions that can be answered by a span of text within a given passage. Existing research on QG in the educational field struggles with two challenges: the mainstream QG models based on seq-to-seq fail to utilize the structured information from the passage; the other is the lack of specialized educational QG datasets. To address the challenges, a specialized QG dataset, reading comprehension dataset from examinations for QG (named RACE4QG), is reconstructed by applying a new answer tagging approach and a data-filtering strategy to the RACE dataset. Further, an end-to-end QG model, which can exploit the intra- and inter-sentence information to generate better questions, is proposed. In our model, the encoder utilizes a Gated Recurrent Units (GRU) network, which takes the concatenation of word embedding, answer tagging, and Graph Attention neTworks(GAT) embedding as input. The hidden states of the GRU are operated with a gated self-attention to obtain the final passage-answer representation, which will be fed to the decoder. Results show that our model outperforms baselines on automatic metrics and human evaluation. Consequently, the model improves the baseline by 0.44, 1.32, and 1.34 on BLEU-4, ROUGE-L, and METEOR metrics, respectively, indicating the effectivity and reliability of our model. Its gap with human expectations also reflects the research potential."
JOUR,"Y. Rong, T. Leemann, T. -T. Nguyen, L. Fiedler, P. Qian, V. Unhelkar, T. Seidel, G. Kasneci, E. Kasneci",,Towards Human-Centered Explainable AI: A Survey of User Studies for Model Explanations,April 2024,2024,"Explainable AI (XAI) is widely viewed as a sine qua non for ever-expanding AI research. A better understanding of the needs of XAI users, as well as human-centered evaluations of explainable models are both a necessity and a challenge. In this paper, we explore how human-computer interaction (HCI) and AI researchers conduct user studies in XAI applications based on a systematic literature review. After identifying and thoroughly analyzing 97 core papers with human-based XAI evaluations over the past five years, we categorize them along the measured characteristics of explanatory methods, namely trust, understanding, usability, and human-AI collaboration performance. Our research shows that XAI is spreading more rapidly in certain application domains, such as recommender systems than in others, but that user evaluations are still rather sparse and incorporate hardly any insights from cognitive or social sciences. Based on a comprehensive discussion of best practices, i.e., common models, design choices, and measures in user studies, we propose practical guidelines on designing and conducting user studies for XAI researchers and practitioners. Lastly, this survey also highlights several open research directions, particularly linking psychological science and human-centered XAI."
JOUR,"D. Halvoník, J. Kapusta",,Large Language Models and Rule-Based Approaches in Domain-Specific Communication,2024,2024,"Currently, we are once again experiencing a frenzy related to artificial intelligence. Generative Pre-trained Transformers (GPT) models are highly effective at various natural language processing tasks. Different varieties of GPT models are widely used these days to improve productivity. Graphic departments generate art designs, developers engineer intricate software solutions, leveraging services predicated on the GPT framework, and many other industries are also following the lead and implementing these new sets of tools in their workflow. However, there are areas in natural language processing where a simple solution is often more suitable and effective than current Large Language Models. In this article, we decided to analyze and compare the practical use of one of the more popular GPT solutions, J-Large, and the simple rule-based model we implemented. We integrated these two models into the internal information system of a private company focused on communication with customers in the gaming industry. Both models were trained on the same dataset provided as a log of conversational interactions for the last two years in the given system. We observed that GPT models exhibited superior performance in terms of comprehensibility and adequacy. The rule-based models showed noticeable proficiency in handling domain-specific tasks, mainly when fed with datasets extracted from the historical communication between users and a specialized domain system, such as a customer care department. As a result, with a sufficiently tailored and specific dataset at their disposal, rule-based models can effectively outpace GPT models in performing domain-specific tasks."
JOUR,"F. Škopljanac-Mačina, I. Zakarija, B. Blašković",,Towards Automated Assessment Generation in e-Learning Systems Using Combinatorial Testing and Formal Concept Analysis,2021,2021,"In this paper, we research the use of software combinatorial testing techniques and the Formal Concept Analysis method for preparing sets of questions for student assessment in e-learning systems. Utilizing these techniques and methods, we ensure that the selected questions optimally cover the course material and that each question combines multiple topics. Therefore, in this paper we introduce our method for preparing student assessments that performs automated combinatorial testing and selection of questions, as well as automated generation of appropriate sequences of questions. The input for our method is a set of questions labelled with attributes or features. This set of questions is pre-processed using the Formal Concept Analysis method, and then the combinatorial testing of question features is performed, which generates a concise list of test-cases covering all pairs or triples of question features. Correspondingly, our method helps in identifying and selecting a subset of questions that covers all generated test-cases. Afterwards, the Formal Concept Analysis method automatically generates suitable sequences of selected questions for formative student assessments in e-learning systems. In this paper we implemented the proposed combinatorial testing method, and also demonstrated the feasibility of the proposed method on a use-case from an actual e-learning system."
JOUR,"M. Duan, Q. Li, L. Xiao",,Topic-extended Emotional Conversation Generation Model Based on Joint Decoding,2021,2021,"The research on the expression of emotion in human-computer dialogue can greatly improve the user experience. Existing research has paid a lot of attention to how to generate specific emotional content and how to improve the extraction rate of emotions, while ignoring the reduction of emotion expression caused by factors such as topics and emotions added to the encoder. This paper proposes a novel Topic-extended Emotional Conversation Generation Model Based on Joint Decoding (TECM-JD). The model embeds the specified emotion category as an additional input into the emotional independent unit of the decoder, in order to reduce the expression of the content affected by adding emotion into the model. The joint attention mechanism is used to obtain the input sequence content and the input sequence topic word content obtained by the Twitter LDA model, which ensures that the output topic and the input are under the same topic. The experimental results show that the proposed model can generate richer emotional content related to the topic and have good performance and are superior to traditional dialogue models."
JOUR,"R. Zhang, Z. Wang, K. Yin, Z. Huang",,Emotional Text Generation Based on Cross-Domain Sentiment Transfer,2019,2019,"Emotional intelligence plays an important role in human intelligence and is a recent research hotspot. With the rapid development of deep learning techniques in recent years, several neural network-based emotional text generation methods have been investigated. However, the existing emotional text generation approaches often suffer from the problem of requiring large-scale annotated data. Generative adversarial network (GAN) has shown promising results in natural language generation and data enhancement. In order to solve the above problem, this paper proposes a GAN-based cross-domain text sentiment transfer model, which uses annotated data from other domains to assist in the training of emotional text generation network. By combining adversarial reinforcement learning with supervised learning, our model is able to extract patterns of sentiment transformation and apply them in emotional text generation. The experimental results have shown that our approach outperforms the state-of-the-art methods and is able to generate high-quality emotional text while maintaining the consistency of domain information and content semantics."
JOUR,"C. Gupta, H. Li, M. Goto",,Deep Learning Approaches in Topics of Singing Information Processing,2022,2022,"Singing, the vocal productionof musical tones, is one of the most important elements of music. Addressing the needs of real-world applications, the study of technologies related to singing voices has become an increasingly active area of research. In this paper, we provide a comprehensive overview of the recent developments in the field of singing information processing, specifically in the topics of singing skill evaluation, singing voice synthesis, singing voice separation, and lyrics synchronization and transcription. We will especially focus on deep learning approaches including modern representation learning techniques for singing voices. We will also provide an overview of contributions in public datasets for singing voice research."
JOUR,"Y. Ahn, S. -G. Lee, J. Park",,Exploiting Text Matching Techniques for Knowledge-Grounded Conversation,2020,2020,"Knowledge-grounded conversation models aim at generating informative responses for the given dialogue context, based on external knowledge. To generate an informative and context-coherent response, it is important to conjugate dialogue context and external knowledge in a balanced manner. However, existing studies have paid less attention to finding appropriate knowledge sentences from external knowledge sources than to generating proper sentences with correct dialogue acts. In this paper, we propose two knowledge selection strategies: 1) Reduce-Match and 2) Match-Reduce and explore several neural knowledge-grounded conversation models based on each strategy. Models based on Reduce-Match strategy first distill the whole dialogue context into a single vector with salient features preserved and then compare this context vector with the representation of knowledge sentences to predict a relevant knowledge sentence. Models based on Match-Reduce strategy first match every turn of the context with knowledge sentences to capture fine-grained interactions and aggregate them while minimizing information loss to predict the knowledge sentence. Experimental results show that conversation models using each of our knowledge selection strategies outperform the competitive baselines not only in terms of knowledge selection accuracy but also in response generation performance. Our best model based on Match-Reduce outperforms the baselines in the comparative studies with the Wizard of Wikipedia dataset. Also, our best model based on Reduce-Match outperforms them with the CMU Document Grounded Conversations dataset."
JOUR,M. Chen,,A Deep Learning-Based Intelligent Quality Detection Model for Machine Translation,2023,2023,"With more and more active international connections, the complex scenes-aware machine translation has been a novel concern in the area of natural language processing. Although various machine translation methods have been proposed during the past few years, automatic and intelligent quality detection for translation results failed to receive sufficient attention. Actually, the real-time quality evaluation for machine translation results remains important, because it can facilitate constant debugging and optimization of machine translation products. Existing approaches mostly focused on the offline written contents rather than real-time extensive oral contents. To bridge current gap, a sentence-level machine translation quality estimation method is deployed in this paper. In particular, a specifical recurrent neural network with double directions (Double-RNN) is proposed as the backbone network structure. The feature extraction process utilizes the Double-RNN translation model, which makes full use of a large amount of parallel corpus. The evaluations show that Double-RNN method proposed in this paper is the closest to the standard quality assessment, and thus can also evaluate the quality of Chinese and English translations more fairly."
JOUR,"I. Phueaksri, M. A. Kastner, Y. Kawanishi, T. Komamizu, I. Ide",,An Approach to Generate a Caption for an Image Collection Using Scene Graph Generation,2023,2023,"Summarization is a challenging task that aims to generate a summary by grasping common information of a given set of information. Text summarization is a popular task of determining the topic or generating a textual summary of documents. In contrast, image summarization aims to find a representative summary of a collection of images. However, current methods are still restricted to generating a visual scene graph, tags, and noun phrases, but cannot generate a fitting textual description of an image collection. Thus, we introduce a novel framework for generating a summarized caption of an image collection. Since scene graph generation shows advancement in describing objects and their relationships on a single image, we use it in the proposed method to generate a scene graph for each image in an image collection. Then, we find common objects and their relationships from all scene graphs and represent them as a summarized scene graph. For this, we merge all scene graphs and select part of it by estimating the most common objects and relationships. Finally, the summarized scene graph is input into a captioning model. In addition, we introduce a technique to generalize specific words in the final caption into common concept words incorporating external knowledge. To evaluate the proposed method, we construct a dataset for this task by extending the annotation of the MS-COCO dataset using an image retrieval method. The evaluation of the proposed method on this dataset showed promising performance compared to text summarization-based methods."
JOUR,"X. Shou, X. Huang, W. Xi",,Conceptual Metaphor Theory Guides GANs for Generating Metaphors and Interpretations,2024,2024,"Metaphor is a distinctive linguistic phenomenon, pervasive in real-life communication. The generation and comprehension of metaphors are intricately connected, making metaphor interpretation and generation enduringly challenging tasks in the field of natural language processing. Existing methods for crafting metaphorical sentences often grapple with the production of metaphorical expressions that innovatively align with real-world examples. Additionally, generating metaphorical interpretations from unlabeled metaphorical sentences presents the inherent challenge of domain specificity. In this paper, we proposed GMAI (GANs Metaphor And Interpretation), an adversarial generative model guided by Conceptual Metaphor Theory. This model seamlessly integrates modules for both metaphor generation and metaphor interpretation, facilitating the creation of metaphorical sentences and their corresponding interpretations. GMAI has the capability to employ information labels for identifying specific words within sentences and transforming them into metaphorical expressions tailored to particular domains. Furthermore, the proposed model can generate a spectrum of metaphorical expressions by modifying domain labels. The downstream metaphor interpretation module, working with the generation module, can get a wealth of novel text. It is trained on sentences generated across various domains in an unlabeled state, thus enhancing the precision of the metaphor interpretation. The experimental findings underscore improvements in the precision and stability of both generated metaphors and their interpretations when compared to prior models."
JOUR,"Y. Qian, Y. Wu",,Exploring the Effectiveness of Data-Driven Learning Materials for Promoting Student Performance in Introductory Programming,2024,2024,"Cryptic and ambiguous error messages provided by programming environments are crucial barriers to beginners when learning to program. This study designed a coding manual to explain common Python programming errors to students using a data-driven approach, following guidelines suggested by prior studies. A quasi-experiment with two groups of middle school students was conducted to examine the effectiveness of the coding manual in reducing student errors, increasing confidence, and promoting learning performance. By analyzing 6015 erroneous student programs collected by the automated assessment tool (AAT) Mulberry, we found that the experimental group who used the coding manual during learning did not make fewer language specification errors (LSEs) in general. However, for LSEs indicating the actual errors in the program, the coding manual showed significant effects in reducing error frequencies. We also found that the coding manual failed to increase students’ confidence in programming and promote learning performance. Possible causes of the ineffectiveness may include high cognitive loads during programming, the productivity of learning from the debugging process, and the incompleteness of the explanations and examples in the coding manual. We recommend that computer programming instructors use AATs or similar tools to collect learning data and identify students’ common errors, directly explain identified common LSEs in class, and explicitly teach debugging methods and strategies. Future research should focus on students’ self-regulation during programming, better methods of explaining common errors to novices, and the long-term effects of using a coding manual on students’ learning in introductory programming."
JOUR,"L. Rodríguez-Gil, J. García-Zubia, P. Orduña, A. Villar-Martinez, D. López-De-Ipiña",,New Approach for Conversational Agent Definition by Non-Programmers: A Visual Domain-Specific Language,2019,2019,"Intelligent tutors and conversational agents (CAs) have proven to be useful learning tools. They have potential not only as stand-alone devices but also as integrable components to enrich and complement other educational resources. For this, new authoring approaches and platforms are required. They should be accessible to non-programmers (such as most teachers) and they should be integrable into current web-based educational platforms. This paper proposes a new approach to define such agents through a visual domain-specific language based on Google Blockly (a scratch-like language). It also develops a web-based integrable authoring platform to serve as a prototype, describing the requirements and architecture. To evaluate whether this novel approach is effective, a multi-stage experiment was conducted. First, participants learned to use the prototype authoring platform through an interactive tutorial. Second, they created a CA with a specific domain model. Times and performance were measured. Finally, they answered a standardized usability questionnaire (UMUX) and a purpose-specific survey. Results show that participants were able to learn to use the domain-specific language in a short time. Moreover, the purpose-specific survey indicates that their perception of the approach (and its potential) is positive. The standardized questionnaire indicates that even in its prototype stage, its usability is satisfactory."
JOUR,"A. M. Abd El-Haleem, M. M. Eid, M. M. Elmesalawy, H. A. H. Hosny",,A Generic AI-Based Technique for Assessing Student Performance in Conducting Online Virtual and Remote Controlled Laboratories,2022,2022,"Due to the COVID-19 pandemic and the development of educational technology, e-learning has become essential in the educational process. However, the adoption of e-learning in sectors such as engineering, science, and technology faces a particular challenge as it needs a special Laboratory Learning Management System (LLMS) capable of supporting online lab activities through virtual and controlled remote labs. One of the most challenging tasks in designing such LLMS is how to assess a student’s performance while an experiment is being conducted and how stuttering students can be automatically detected while experimenting and providing the appropriate assistance. For this, a generic technique based on Artificial Intelligence (AI) is proposed in this paper for assessing student performance while conducting online labs and implemented as a performance evaluation module in the LLMS. The performance evaluation module is designed to automatically detect the student performance during the experiment run time and triggers the LLMS virtual assistant service to provide struggling students with the appropriate help when they need it. Also, the proposed performance assessment technique is used during the lab exam sessions to support the automatic grading process conducted by the LLMS Auto-Grading Module. The proposed performance evaluation technique has been developed based on analyzing the student’s mouse dynamics to work generally with any type of simulation or control software used by virtual or remote controlled laboratories; without the need for special interfacing. The study has been applied to a novel dataset built by the course instructors and students simulating a circuit on TinkerCad. Using mouse dynamics fetching, the system extracts features and evaluates them to determine if the student has built the experiment steps in the right way or not. A comparison study has been developed between different Machine Learning (ML) models and a number of performance metrics are calculated. The study confirmed that Artificial Neural Network (ANN) and Support Vector Machine (SVM) are the best models to be used for automatically evaluating student performance while conducting the online labs with a precision reaching up to 91%."
JOUR,"I. Alsmadi, N. Aljaafari, M. Nazzal, S. Alhamed, A. H. Sawalmeh, C. P. Vizcarra, A. Khreishah, M. Anan, A. Algosaibi, M. A. Al-Naeem, A. Aldalbahi, A. Al-Humam",,Adversarial Machine Learning in Text Processing: A Literature Survey,2022,2022,"Machine learning algorithms represent the intelligence that controls many information systems and applications around us. As such, they are targeted by attackers to impact their decisions. Text created by machine learning algorithms has many types of applications, some of which can be considered malicious especially if there is an intention to present machine-generated text as human-generated. In this paper, we surveyed major subjects in adversarial machine learning for text processing applications. Unlike adversarial machine learning in images, text problems and applications are heterogeneous. Thus, each problem can have its own challenges. We focused on some of the evolving research areas such as: malicious versus genuine text generation metrics, defense against adversarial attacks, and text generation models and algorithms. Our study showed that as applications of text generation will continue to grow in the near future, the type and nature of attacks on those applications and their machine learning algorithms will continue to grow as well. Literature survey indicated an increasing trend in using pre-trained models in machine learning. Word/sentence embedding models and transformers are examples of those pre-trained models. Adversarial models may utilize same or similar pre-trained models as well. In another trend related to text generation models, literature showed effort to develop universal text perturbations to be used in both black-and white-box attack settings. Literature showed also using conditional GANs to create latent representation for writing types. This usage will allow for a seamless lexical and grammatical transition between various writing styles. In text generation metrics, research trends showed developing successful automated or semi-automated assessment metrics that may include human judgement. Literature showed also research trends of designing and developing new memory models that increase performance and memory utilization efficiency without validating real-time constraints. Many research efforts evaluate different defense model approaches and algorithms. Researchers evaluated different types of targeted attacks, and methods to distinguish human versus machine generated text."
JOUR,"X. Ning, Y. Kim, S. D. Min, X. Guo, J. Gab Ho",,Exploring Achilles Tendon Vibration Data Classification for Balance Training: A Wavelet-Based Machine Learning Approach,2024,2024,"Balance training is widely used to improve stability, and Achilles tendon vibration is an effective method. However, evaluation of training progress often relies on Center of Pressure (COP) analysis, which can be challenging for non-experts. To provide an objective and automated assessment, this study explores machine learning techniques. Achilles tendon vibration was applied during standing, and COP data were collected under various conditions, including eyes open/closed and cognitive/non-cognitive tasks. To more accurately assess the training effects, this study applied machine learning techniques that combine wavelet decomposition for feature extraction. Three genetic algorithm-based machine learning models (GA-SVM, GA-LGBM, and GA-LR) were constructed for feature selection and classification. The results showed that all three models achieved classification accuracies above 80% in identifying Achilles tendon vibration and non-vibration data, with SVM achieving the highest accuracy of 89.59%. Among the selected features, entropy category features played a crucial role, and entropy values were higher under Achilles tendon vibration conditions than under non-vibration conditions. This study confirms the feasibility of applying machine learning to Achilles tendon vibration rehabilitation training in the future, and the identified key features also provide a theoretical basis for the analysis of Achilles tendon vibration data. These findings provide valuable insights for further optimization of balance rehabilitation training programs."
CONF,"W. Dai, J. Lin, H. Jin, T. Li, Y. -S. Tsai, D. Gašević, G. Chen",,Can Large Language Models Provide Feedback to Students? A Case Study on ChatGPT,10-13 July 2023,2023,"Educational feedback has been widely acknowledged as an effective approach to improving student learning. However, scaling effective practices can be laborious and costly, which motivated researchers to work on automated feedback systems (AFS). Inspired by the recent advancements in the pre-trained language models (e.g., ChatGPT), we posit that such models might advance the existing knowledge of textual feedback generation in AFS because of their capability to offer natural-sounding and detailed responses. Therefore, we aimed to investigate the feasibility of using ChatGPT to provide students with feedback to help them learn better. Our results show that i) ChatGPT is capable of generating more detailed feedback that fluently and coherently summarizes students' performance than human instructors; ii) ChatGPT achieved high agreement with the instructor when assessing the topic of students' assignments; and iii) ChatGPT could provide feedback on the process of students completing the task, which might benefit students developing learning skills."
JOUR,"Dai, Wei, Tsai, Yi-Shan, Lin, Jionghao, Aldino, Ahmad, Jin, Hua, Li, Tongguang, Gašević, Dragan, Chen, Guanliang",Assessing the proficiency of large language models in automatic feedback generation: An evaluation study,,,2024,"Assessment feedback is important to student learning. Learning analytics (LA) powered by artificial intelligence exhibits profound potential in helping instructors with the laborious provision of feedback. Inspired by the recent advancements made by Generative Pre-trained Transformer (GPT) models, we conducted a study to examine the extent to which GPT models hold the potential to advance the existing knowledge of LA-supported feedback systems towards improving the efficiency of feedback provision. Therefore, our study explored the ability of two versions of GPT models – i.e., GPT-3.5 (ChatGPT) and GPT-4 – to generate assessment feedback on students' writing assessment tasks, common in higher education, with open-ended topics for a data science-related course. We compared the feedback generated by GPT models (namely GPT-3.5 and GPT-4) with the feedback provided by human instructors in terms of readability, effectiveness (content containing effective feedback components), and reliability (correct assessment on student performance). Results showed that (1) both GPT-3.5 and GPT-4 were able to generate more readable feedback with greater consistency than human instructors, (2) GPT-4 outperformed GPT-3.5 and human instructors in providing feedback containing information about effective feedback dimensions, including feeding-up, feeding-forward, process level, and self-regulation level, and (3) GPT-4 demonstrated higher reliability of feedback compared to GPT-3.5. Based on our findings, we discussed the potential opportunities and challenges of utilising GPT models in assessment feedback generation."
CONF,"J. L. Reguera, Y. F. Leiva",,A learning methodology for object oriented programming with effective support from the PA3P automatic evaluation platform,16-20 Oct. 2017,2017,"This article presents a methodology that uses the Platform for Active Programming Learning Support PA3P in the first stage of an Object Programming (OOP) course. The platform tests online the Java Programs that students write as exercises, enabling testing and personalized feedback generation for students. PA3P is a new version of a previous platform developed for introductory programming course in languages such as C, Java and Matlab, but with evaluation mechanisms adapted for handling Java projects and carry at automated evaluation of OOP concepts. This work presents the criteria used for creating didactic problem sequences and effectively applying them through automatic evaluation. The results obtained after two semesters of use show that that automatic evaluation positively affects students and performance. To obtain preliminary information about de effectiveness of platform, a qualitative and quantitative was carried out. The qualitative aspects where extracted by observing students behavior during the learning process, while quantitative analysis is based on data registered by platform and the evolution of students grades."
CONF,"K. Umbleja, V. Kukk, M. Jaanus",,Analysis of competency-based learning — 6 Years later,25-28 April 2017,2017,"Competency-based learning (CBL) has gained a lot of momentum lately but rarely has it been implemented fully in e-learning environment as a central, driving force for learning. In 2010 ISC e-learning environment was switched from classical topic-based learning to CBL. Two years into the new approach, detailed analysis was conducted. Now, 6 years since introducing CBL, another analysis using educational data mining principles is conducted to compare how learning patterns and student behavior has changed during the years. At first, current framework of CBL used in ISC is covered that contains automatic answer evaluation, uninterrupted learning process, self-regulated learning, usage of memory model and personal learning control engine. Then, different aspects of the framework are analyzed - the usage of competences in the system, time spent in the system by the student, amount of work required to complete the courses, students' results and study patterns. Three distinct behavior periods are identified."
CONF,"J. Krugel, P. Hubwieser, M. Goedicke, M. Striewe, M. Talbot, C. Olbricht, M. Schypula, S. Zettler",,Automated Measurement of Competencies and Generation of Feedback in Object-Oriented Programming Courses,27-30 April 2020,2020,"To overcome the shortage of computer specialists, there is an increased need for correspondent study and training offers, in particular for learning programming. The automated assessment of solutions to programming tasks could relieve teachers of time-consuming corrections and provide individual feedback even in online courses without any personal teacher. The e-assessment system JACK has been successfully applied for more than 12 years up to now, e.g., in a CS1 lecture. However, there are only few solid research results on competencies and competence models for object-oriented programming (OOP), which could be used as a foundation for high-quality feedback.In a joint research project of research groups at two universities, we aim to empirically define competencies for OOP using a mixed-methods approach. In a first step, we performed a qualitative content analysis of source code (sample solutions and students’ solutions) and as a result identified a set of suitable competency components that forms the core of further investigations. Semi-structured interviews with learners will be used to identify difficulties and misconceptions of the learners and to adapt the set of competency components. Based on that we will use Item Response Theory (IRT) to develop an automatically evaluable test instrument for the implementation of abstract data types. We will further develop empirically founded and competency-based feedback that can be used in e-assessment systems and MOOCs."
JOUR,"H. -M. Chen, B. -A. Nguyen, Y. -X. Yan, C. -R. Dow",,Analysis of Learning Behavior in an Automated Programming Assessment Environment: A Code Quality Perspective,2020,2020,"Automated programming assessment systems are useful tools to track the learning progress of students automatically and thereby reduce the workload of educators. They can also be used to gain insights into how students learn, making it easier to formulate strategies aimed at enhancing learning performance. Rather than functional code which is always inspected, code quality remains an essential aspect to which not many educators consider when designing an automated programming assessment system. In this study, we applied data mining techniques to analyze the results of an automated assessment system to reveal unexpressed patterns in code quality improvement that are predictive of final achievements in the course. Cluster analysis is first utilized to categorize students according to their learning behavior and outcomes. Cluster profile analysis is then leveraged to highlight actionable factors that could affect their final grades. Finally, the same factors are employed to construct a classification model by which to make early predictions of the students' final results. Our empirical results demonstrate the efficacy of the proposed scheme in providing valuable insights into the learning behaviors of students in novice programming courses, especially in code quality assurance, which could be used to enhance programming performance at the university level."
JOUR,"Stahovich, Thomas F., Lin, Hanlung",Enabling data mining of handwritten coursework,,,2016,"Data mining has become an increasingly important tool for education researchers and practitioners. However, work in this field has focused on data from online educational systems. Here, we present techniques to enable data mining of handwritten coursework, which is an essential component of instruction in many disciplines. Our techniques include methods for classifying pen strokes as diagram, equation, and cross-out strokes. The latter are used to strike out erroneous work. We have also created techniques for grouping equation strokes into equation groups and then individual characters. Our results demonstrate that our classification and grouping techniques are more accurate than prior techniques for this task. We also demonstrate applications of our techniques for automated assessment of student competence. We present a novel approach for measuring the correctness of exam solutions from an analysis of lexical features of handwritten equations. This analysis demonstrates, for example, that the number of equation groups correlates positively with grade. We also use our techniques to extend graphical protocol analysis to free-form, handwritten problem solutions. While prior work in a laboratory setting suggests that long pauses are indicative of low competence, our work shows that the frequency of long pauses during exams correlates positively with competence."
JOUR,"Hung, Andrew J., Rambhatla, Sirisha, Sanford, Daniel I., Pachauri, Nilay, Vanstrum, Erik, Nguyen, Jessica H., Liu, Yan",Road to automating robotic suturing skills assessment: Battling mislabeling of the ground truth,,,2022,"Objective To automate surgeon skills evaluation using robotic instrument kinematic data. Additionally, to implement an unsupervised mislabeling detection algorithm to identify potentially mislabeled samples that can be removed to improve model performance. Methods Video recordings and instrument kinematic data were derived from suturing exercises completed on the Mimic FlexVR robotic simulator. A structured human consensus-building process was developed to determine Robotic Anastomosis Competency Evaluation technical scores across 3 human graders. A 2-layer long short-term memory–based classification model used instrument kinematic data to automate suturing skills assessment. An unsupervised label analyzer (NoiseRank) was used to identify potential mislabeling of skills data. Performance of the long short-term memory model’s technical skill score prediction was measured by best area under the curve over the training runs. NoiseRank outputted a ranked list of rated skills assessments based on likelihood of mislabeling. Results 22 surgeons performed 226 suturing attempts, which were broken down into 1,404 individual skill assessment points. Automation of needle entry angle, needle driving, and needle withdrawal technical skill scores performed better (area under the curve 0.698–0.705) than needle positioning (0.532) at baseline using all available data. Potential mislabels were subsequently identified by NoiseRank and removed, improving model performance across all domains (area under the curve 0.551–0.766). Conclusion Using ground truth labels from human graders and robotic instrument kinematic data, machine learning models have automated assessment of detailed suturing technical skills with good performance. Further, an unsupervised mislabeling detection algorithm projected mislabeled data, allowing for their removal and subsequent improvement of model performance."
JOUR,"Gearhart, Addison, Dwork, Nicholas, Jone, Pei-Ni",Artificial intelligence in echocardiography to diagnose congenital heart disease and fetal echocardiography,,,2022,"Echocardiography is the primary tool in pediatric cardiology for diagnosing and managing congenital heart disease (CHD). Accurate and reliable echocardiographic assessment is critical in clinical decision making. Artificial intelligence (AI), in particular deep learning, has the potential to reduce labor and provide automated assessment of CHD. In this review, the application of AI in pediatric and fetal echocardiography are described with the need for future multicenter collaboration to fully leverage the use of AI for echocardiography in the pediatric population."
JOUR,"Birla, Nayna, Kumar Jain, Manoj, Panwar, Avinash",Automated assessment of subjective assignments: A hybrid approach,,,2022,"Machine learning (ML) has recently gained popularity in a variety of domains for automating tasks. This has also been used in the evaluation of student responses/ assignments. This paper presents a qualitatively enhanced methodology for automated score prediction of subjective assignments. To consider all the major aspects of a human grader, 21 linguistic features related to syntactical, grammatical, sentimental, and readability are analyzed from the assignments. This study makes use of the ASAP competition dataset from Kaggle. The evaluation metric used is Quadratic Weighted Kappa (QWK), which measures the agreement between the human graded score and the predicted score. The effect of appropriate feature selection has been observed using Mutual Information Regression. Four ML algorithms are investigated on identified linguistic features. 3 Layer Neural Network with feature selection performed well among all chosen ML algorithms with average QWK of 0.678. To include the benefits of deep learning, a new hybrid model (LF-BiLSTM-att-FS) is proposed that combines a higher level deep neural network (DNN) with the selected features. Pre-trained Glove embedding is used to include contextual information of the text. The proposed model results demonstrated an improvement in overall accuracy, with an average QWK value of 0.768."
JOUR,"Starmans, Martijn P.A., Miclea, Razvan L., Vilgrain, Valerie, Ronot, Maxime, Purcell, Yvonne, Verbeek, Jef, Niessen, Wiro J., Ijzermans, Jan N.M., de Man, Rob A., Doukas, Michael, Klein, Stefan, Thomeer, Maarten G.",Automated Assessment of T2-Weighted MRI to Differentiate Malignant and Benign Primary Solid Liver Lesions in Noncirrhotic Livers Using Radiomics,,,2024,"Rationale and Objectives Distinguishing malignant from benign liver lesions based on magnetic resonance imaging (MRI) is an important but often challenging task, especially in noncirrhotic livers. We developed and externally validated a radiomics model to quantitatively assess T2-weighted MRI to distinguish the most common malignant and benign primary solid liver lesions in noncirrhotic livers. Materials and Methods Data sets were retrospectively collected from three tertiary referral centers (A, B, and C) between 2002 and 2018. Patients with malignant (hepatocellular carcinoma and intrahepatic cholangiocarcinoma) and benign (hepatocellular adenoma and focal nodular hyperplasia) lesions were included. A radiomics model based on T2-weighted MRI was developed in data set A using a combination of machine learning approaches. The model was internally evaluated on data set A through cross-validation, externally validated on data sets B and C, and compared to visual scoring of two experienced abdominal radiologists on data set C. Results The overall data set included 486 patients (A: 187, B: 98, and C: 201). The radiomics model had a mean area under the curve (AUC) of 0.78 upon internal validation on data set A and a similar AUC in external validation (B: 0.74 and C: 0.76). In data set C, the two radiologists showed moderate agreement (Cohen’s κ: 0.61) and achieved AUCs of 0.86 and 0.82. Conclusion Our T2-weighted MRI radiomics model shows potential for distinguishing malignant from benign primary solid liver lesions. External validation indicated that the model is generalizable despite substantial MRI acquisition protocol differences. Pending further optimization and generalization, this model may aid radiologists in improving the diagnostic workup of patients with liver lesions."
JOUR,"Kumar, D. Senthil, Askarunisa, A., Kumar, R. Mohan",Embedded processor based automated assessment of quality of the water in an IoT background,,,2020,"For the life of human beings, water is necessary. While nearly 70% of the earth is drained, just 3% are known to be fresh water. Moreover, approximately 2.6% of the cooling water is not accessible to people. They are either trapped in glaciers and polar ice caps, contained in the soil or water, heavily poisoned, or unnecessarily drained below the Earth's surface. So only 0.4% of the drinkable water in the world is shared by the 7 billion inhabitants. Fresh water is therefore a valuable resource to be regulated and properly maintained. Only 80% of liquid fresh water should not be available to the public in many developing countries. By exponentially increasing the population of India, Fresh Water management in the farming, manufacturing and other fields is much more critical because of water requirements. “Physical, biological and chemical” parameters can be analyzed in determining the Fresh Water Quality. The scientists will manually carry out traditional water quality sampling. Nonetheless, this method takes a little bit of time and is cost-effective. Now, the IoT technology is used to track, capture and analyze the data in various fields of research. In this paper, we design a low-cost system to achieve water value in an IOT environment. The system consists of several sensors used for the calculation of chemical and physical water parameters. The machine learning algorithm has also been used to forecast water quality based on its data set, which were learned from a number of water samples. This system was modeled by using the U D00* 86 Ultra and Teensy++2.0 data processors at low budgets."
JOUR,"Yurk, Dominic, Barrios, Joshua P., Labrecque Langlais, Elodie, Avram, Robert, Aras, Mandar A., Abu-Mostafa, Yaser, Padmanabhan, Arun, Tison, Geoffrey H.",Automated Assessment of Right Atrial Pressure From Ultrasound Videos Using Machine Learning,,,2024,"Background Early recognition of volume overload is essential for heart failure patients. Volume overload can often be easily treated if caught early but causes significant morbidity if unrecognized and allowed to progress. Intravascular volume status can be assessed by ultrasound-based estimation of right atrial pressure (RAP), but the availability of this diagnostic modality is limited by the need for experienced physicians to accurately interpret these scans. Objectives We sought to evaluate whether machine learning can accurately estimate echocardiogram-measured RAP. Methods We developed fully automated deep learning models for identifying inferior vena cava scans with rapid inspiration in echocardiogram studies and estimating RAP from those scans. The RAP estimation model was trained and evaluated using 15,828 ultrasound videos of the inferior vena cava and coupled cardiologist-assessed RAP estimates as well as 319 RAP measurements from right heart catheterization. Results Our model agreed with cardiologist estimates 80.3% of the time (area under the receiver-operating characteristic of 0.844) in a test data set, at the upper end of interoperator agreement rates found in the literature of 70 to 75%. Our model’s RAP estimates were statistically indistinguishable from cardiologists’ ultrasound-based RAP estimates (P = 0.98) when compared against the gold standard of right heart catheterization RAP measurements in a subset of patients. Our model also generalized well to an external data set of echocardiograms from a different institution (area under the receiver-operating characteristic of 0.854 compared to cardiologist RAP estimates). Conclusions Machine learning is capable of accurately and robustly interpreting RAP from echocardiogram videos. This algorithm could be used to perform automated assessments of intravascular volume status."
JOUR,"Rahman, Md Juber, Nemati, Ebrahim, Rahman, Md Mahbubur, Nathan, Viswam, Vatanparvar, Korosh, Kuang, Jilong",Automated assessment of pulmonary patients using heart rate variability from everyday wearables,,,2020,"Everyday wearables with enhanced computational capacity, good quality sensors, and machine learning/artificial intelligence enabled algorithms have the potential to play a key role not only in the fitness and wellness sector but also in the field of disease diagnostics and monitoring. The major challenges are a limited number of sensors, reliable data collection and processing, and deployment of computationally efficient algorithms. In this multi-cohort study, we have used everyday wearables such as chest band and smartwatch to investigate the heart rate variability (HRV) of 131 subjects which include 40 healthy controls, 69 asthma patients, 9 COPD patients and 13 patients with a co-morbidity of asthma and COPD. We aimed at a comprehensive investigation by exploring a total of 58 features including time domain, frequency domain, non-linear and entropy measures of HRV to identify the HRV indices that provide significant discriminatory information for classification between healthy and pulmonary patients. Feature ranking has been done by the area under the receiver operating characteristics curve. Classification of patients with the 15 top ranked features using data from the chest band heart rate sensor as well as estimated HRV parameters from smartwatch PPG signal have been investigated separately. Using the chest band data, a classification accuracy of 82.07%, precision of 83.13%, recall of 81.53% and F-1 score of 81.7% have been achieved; whereas using the smartwatch data, a classification accuracy of 80%, precision of 79.9%, recall of 80% and F-1 score of 79.94% have been achieved for the test set with an AdaBoost classifier. Heart rate variability metrics also showed significant correlation with disease severity and impact on health-related quality of life as measured by pulmonary function test, Asthma Symptoms Utility Index and COPD assessment test score respectively. The results indicate that HRV analysis using everyday wearables may be helpful in the assessment and management of asthma and COPD."
JOUR,"Ioshchikhes, Borys, Borst, Fabian, Weigold, Matthias",Assessing Energy Efficiency Measures for Hydraulic Systems using a Digital Twin,,,2022,"As manufacturing companies around the world face the challenge of reducing CO2 emissions and achieving their climate goals, increasing energy efficiency provides a promising solution while potentially reducing costs. Hydraulic systems are used in a wide range of applications such as heating, ventilation, air conditioning or machine tools and account for approximately 11 % of the electric energy demand in the German industry in 2017. Furthermore, up to 25 million tons of CO2 are emitted annually in Germany as a result of their operation. Against this background, the following paper aims to increase the energy efficiency of hydraulic systems through automated assessment of energy efficiency measures during system operation. Therefore, we present a modular approach for real-time assessing of energy efficiency measures using a digital twin, which contains an expert system combined with real-time simulation models. To detect inefficiencies without time consuming analysis and substantial user expertise, the expert system automatically identifies system leakage and increased flow resistance using a multi-output regression model. Finally, the expert system aims at engaging operators to implement energy efficiency measures by quantifying their respective energy saving potentials. The proposed measures are applied to the virtual representation of a hydraulic system in real-time. Therefore, a Modelica simulation model is developed, which is exported as a functional mock-up unit (FMU) and integrated into a Python framework. If measures lead to an improvement in energy efficiency, these are recommended to the operator. The overall concept is validated using a physical hydraulic system within the ETA Research Factory. The validation of the prototype shows that the developed approach can be applied to industrial applications and help in reducing their energy consumption."
JOUR,"Fatimah, Binish, Singhal, Amit, Singh, Pushpendra",A multi-modal assessment of sleep stages using adaptive Fourier decomposition and machine learning,,,2022,"Healthy sleep is essential for the rejuvenation of the body and helps in maintaining good health. Many people suffer from sleep disorders that are characterized by abnormal sleep patterns. Automated assessment of such disorders using biomedical signals has been an active subject of research. Electroencephalogram (EEG) is a popular diagnostic used in this regard. We consider a widely-used publicly available database and process the signals using the Fourier decomposition method (FDM) to obtain narrowband signal components. Statistical features extracted from these components are passed on to machine learning classifiers to identify different stages of sleep. A novel feature measuring the non-stationarity of the signal is also used to capture salient information. It is shown that classification results can be improved by using multi-channel EEG instead of single-channel EEG data. Simultaneous utilization of multiple modalities, such as Electromyogram (EMG), Electrooculogram (EOG) along with EEG data leads to further enhancement in the obtained results. The proposed method can be efficiently implemented in real-time using fast Fourier transform (FFT), and it provides better classification results than the other algorithms existing in the literature. It can assist in the development of low-cost sensor-based setups for continuous patient monitoring and feedback."
JOUR,"Alter, Benedict J., Moses, Mark, DeSensi, Rebecca, O’Connell, Brian, Bernstein, Cheryl, McDermott, Sean, Jeong, Jong-Hyeon, Wasan, Ajay D.",Hierarchical Clustering Applied to Chronic Pain Drawings Identifies Undiagnosed Fibromyalgia: Implications for Busy Clinical Practice,,,2024,"Currently-used assessments for fibromyalgia require clinicians to suspect a fibromyalgia diagnosis, a process susceptible to unintentional bias. Automated assessments of standard patient-reported outcomes (PROs) could be used to prompt formal assessments, potentially reducing bias. We sought to determine whether hierarchical clustering of patient-reported pain distribution on digital body map drawings predicted fibromyalgia diagnosis. Using an observational cohort from the University of Pittsburgh’s Patient Outcomes Repository for Treatment registry, which contains PROs and electronic medical record data from 21,423 patients (March 17, 2016–June 25, 2019) presenting to pain management clinics, we tested the hypothesis that hierarchical clustering subgroup was associated with fibromyalgia diagnosis, as determined by ICD-10 code. Logistic regression revealed a significant relationship between the body map cluster subgroup and fibromyalgia diagnosis. The cluster subgroup with the most body areas selected was the most likely to receive a diagnosis of fibromyalgia when controlling for age, gender, anxiety, and depression. Despite this, more than two-thirds of patients in this cluster lacked a clinical fibromyalgia diagnosis. In an exploratory analysis to better understand this apparent underdiagnosis, we developed and applied proxies of fibromyalgia diagnostic criteria. We found that proxy diagnoses were more common than ICD-10 diagnoses, which may be due to less frequent clinical fibromyalgia diagnosis in men. Overall, we find evidence of fibromyalgia underdiagnosis, likely due to gender bias. Coupling PROs that take seconds to complete, such as a digital pain body map, with machine learning is a promising strategy to reduce bias in fibromyalgia diagnosis and improve patient outcomes. Perspective This investigation applies hierarchical clustering to patient-reported, digital pain body maps, finding an association between body map responses and clinical fibromyalgia diagnosis. Rapid, computer-assisted interpretation of pain body maps would be clinically useful in prompting more detailed assessments for fibromyalgia, potentially reducing gender bias."
JOUR,"Gawrieh, Samer, Sethunath, Deepak, Cummings, Oscar W., Kleiner, David E., Vuppalanchi, Raj, Chalasani, Naga, Tuceryan, Mihran",Automated quantification and architectural pattern detection of hepatic fibrosis in NAFLD,,,2020,"Accurate detection and quantification of hepatic fibrosis remain essential for assessing the severity of non-alcoholic fatty liver disease (NAFLD) and its response to therapy in clinical practice and research studies. Our aim was to develop an integrated artificial intelligence-based automated tool to detect and quantify hepatic fibrosis and assess its architectural pattern in NAFLD liver biopsies. Digital images of the trichrome-stained slides of liver biopsies from patients with NAFLD and different severity of fibrosis were used. Two expert liver pathologists semi-quantitatively assessed the severity of fibrosis in these biopsies and using a web applet provided a total of 987 annotations of different fibrosis types for developing, training and testing supervised machine learning models to detect fibrosis. The collagen proportionate area (CPA) was measured and correlated with each of the pathologists semi-quantitative fibrosis scores. Models were created and tested to detect each of six potential fibrosis patterns. There was good to excellent correlation between CPA and the pathologist score of fibrosis stage. The coefficient of determination (R2) of automated CPA with the pathologist stages ranged from 0.60 to 0.86. There was considerable overlap in the calculated CPA across different fibrosis stages. For identification of fibrosis patterns, the models areas under the receiver operator curve were 78.6% for detection of periportal fibrosis, 83.3% for pericellular fibrosis, 86.4% for portal fibrosis and >90% for detection of normal fibrosis, bridging fibrosis, and presence of nodule/cirrhosis. In conclusion, an integrated automated tool could accurately quantify hepatic fibrosis and determine its architectural patterns in NAFLD liver biopsies."
JOUR,"Thi Dieu Truong, Hien, Al-Sarayreh, Mahmoud, Reddy, Pullanagari, Reis, Marlon M, Archer, Richard",The potential of deep learning to counter the matrix effect for assessment of honey quality and monoflorality,,,2024,"The complexity of biological matrices affects Near-infrared (NIR) signals. Honey, a complex food matrix, changes in chemical and physical properties over time indicating strong matrix effects when capturing NIR spectra. The varied floral sources in most honeys also contribute to this effect. A real dataset of 1656 honey samples spanning eight geographic districts of the North Island of New Zealand captured by NIR hyperspectral camera was analyzed with machine learning and deep learning models to assess mānuka honey quality and identity. One-dimensional neural network (1D-CNN) showed high capacity to accommodate the complexity of the honey matrix, better than did linear machine learning models, particularly for prediction of a trademarked continuous quality score of mānuka honey, known as Unique Mānuka Factor (UMFTM). Monofloral mānuka honey was distinguished well from multi-floral and non-mānuka when classified with 1D-CNN, achieving > 90 % class accuracy, better than conventional classifiers. Interestingly, 1D-CNN models could precisely identify important spectral regions such as Visible (666–725 nm) & NIR (991 and 1435 nm) supporting the evaluation of mānuka honey quality and determining botanical origin as Leptospermum scoparium. Both are useful for future model development and application to automated assessment of honey quality and monoflorality before lumped extraction."
JOUR,"Summers, Ronald M., Elton, Daniel C., Lee, Sungwon, Zhu, Yingying, Liu, Jiamin, Bagheri, Mohammedhadi, Sandfort, Veit, Grayson, Peter C., Mehta, Nehal N., Pinto, Peter A., Linehan, W. Marston, Perez, Alberto A., Graffy, Peter M., O'Connor, Stacy D., Pickhardt, Perry J.",Atherosclerotic Plaque Burden on Abdominal CT: Automated Assessment With Deep Learning on Noncontrast and Contrast-enhanced Scans,,,2021,"Background Abdominal aortic atherosclerotic plaque burden may have clinical significance but manual measurement is time-consuming and impractical. Purpose To perform external validation on an automated atherosclerotic plaque detector for noncontrast and postcontrast abdominal CT. Materials and Methods The training data consisted of 114 noncontrast CT scans and 23 postcontrast CT urography scans. The testing data set consisted of 922 CT colonography (CTC) scans, and 1207 paired noncontrast and postcontrast CT scans from renal donors from a second institution. Reference standard data included manual plaque segmentations in the 137 training scans and manual plaque burden measurements in the 922 CTC scans. The total Agatston score and group (0–3) was determined using fully-automated deep learning software. Performance was assessed by measures of agreement, linear regression, and paired evaluations. Results On CTC scans, automated Agatston scoring correlated highly with manual assessment (R2 = 0.94). On paired renal donor CT scans, automated Agatston scoring on postcontrast CT correlated highly with noncontrast CT (R2 = 0.95). When plaque burden was expressed as a group score, there was excellent agreement for both the CTC (weighted kappa 0.80 ± 0.01 [95% confidence interval: 0.78–0.83]) and renal donor (0.83 ± 0.02 [0.79–0.86]) assessments. Conclusion Fully automated detection, segmentation, and scoring of abdominal aortic atherosclerotic plaques on both pre- and post-contrast CT was validated and may have application for population-based studies."
JOUR,"Kanbar, Lara J., Mishra, Anagh, Osborn, Alexander, Cifuentes, Andrew, Combs, Jennifer, Sorter, Michael, Barzman, Drew, Dexheimer, Judith W.",Investigation of bias in the automated assessment of school violence,,,2024,"Objectives Natural language processing and machine learning have the potential to lead to biased predictions. We designed a novel Automated RIsk Assessment (ARIA) machine learning algorithm that assesses risk of violence and aggression in adolescents using natural language processing of transcribed student interviews. This work evaluated the possible sources of bias in the study design and the algorithm, tested how much of a prediction was explained by demographic covariates, and investigated the misclassifications based on demographic variables. Methods We recruited students 10–18 years of age and enrolled in middle or high schools in Ohio, Kentucky, Indiana, and Tennessee. The reference standard outcome was determined by a forensic psychiatrist as either a “high” or “low” risk level. ARIA used L2-regularized logistic regression to predict a risk level for each student using contextual and semantic features. We conducted three analyses: a PROBAST analysis of risk in study design; analysis of demographic variables as covariates; and a prediction analysis. Covariates were included in the linear regression analyses and comprised of race, sex, ethnicity, household education, annual household income, age at the time of visit, and utilization of public assistance. Results We recruited 412 students from 204 schools. ARIA performed with an AUC of 0.92, sensitivity of 71%, NPV of 77%, and specificity of 95%. Of these, 387 students with complete demographic information were included in the analysis. Individual linear regressions resulted in a coefficient of determination less than 0.08 across all demographic variables. When using all demographic variables to predict ARIA’s risk assessment score, the multiple linear regression model resulted in a coefficient of determination of 0.189. ARIA performed with a lower False Negative Rate (FNR) of 15.2% (CI [0 – 40]) for the Black subgroup and 12.7%, CI [0 – 41.4] for Other races, compared to an FNR of 26.1% (CI [14.1 – 41.8]) in the White subgroup. Conclusions Bias assessment is needed to address shortcomings within machine learning. In our work, student race, ethnicity, sex, use of public assistance, and annual household income did not explain ARIA’s risk assessment score of students. ARIA will continue to be evaluated regularly with increased subject recruitment."
JOUR,"Razfar, Najmeh, Kashef, Rasha, Mohammadi, Farah",An Artificial Intelligence model for smart post-stroke assessment using wearable sensors,,,2023,"Wearable sensors provide a recording capability of the body segments’ motion. By collecting and analyzing the segments’ movements, automating the post-stroke assessment process would be feasible and reliable. Post-stroke classification of impaired or non-impaired body parts is the first step of automating the assessment process. It is recently achievable by utilizing enhancements in supervised machine learning (ML) using wearable sensors. Many classification-based approaches have numerous complexity/quality trade-offs with no optimal solution for all datasets of various structures, properties, distributions, and sizes. Ensemble machine learning provides reliable classification systems for diagnostic purposes. However, there are no criteria for identifying the baseline models in the aggregate (parallel or sequential aggregation), which significantly impacts the complexity and accuracy of the designed ensemble. In this paper, we propose an efficient post-stroke diagnosis system using the notion of multi-level ensemble learning, the Multi-Level Meta Learner (MLML) ensemble algorithm with heterogeneous or homogeneous baseline classifiers using Xsens wearable sensor collected dataset. The MLML outperforms the baseline models with comparable performance while generating a list of optimal candidate heterogeneous baseline classifiers. This list can provide only potential positive combinations, significantly improving the performance and reducing the complexity of building an ensemble. The linear acceleration and angular velocity derived from the wearable sensors are utilized. Experimental results show that the MLML has enhanced the accuracy of classifying the impaired hands from non-impaired hands with an improvement of up to 95.64% and 91.2% for boosting and Bagging learning, respectively."
JOUR,"Rozynek, Miłosz, Tabor, Zbisław, Kłęk, Stanisław, Wojciechowski, Wadim",Body composition radiomic features as a predictor of survival in patients with non-small cellular lung carcinoma: A multicenter retrospective study,,,2024,"Objectives This study combined two novel approaches in oncology patient outcome predictions—body composition and radiomic features analysis. The aim of this study was to validate whether automatically extracted muscle and adipose tissue radiomic features could be used as a predictor of survival in patients with non-small cell lung cancer. Methods The study included 178 patients with non-small cell lung cancer receiving concurrent platinum-based chemoradiotherapy. Abdominal imaging was conducted as a part of whole-body positron emission tomography/computed tomography performed before therapy. Methods used included automated assessment of the volume of interest using densely connected convolutional network classification model - DenseNet121, automated muscle and adipose tissue segmentation using U-net architecture implemented in nnUnet framework, and radiomic features extraction. Acquired body composition radiomic features and clinical data were used for overall and 1-y survival prediction using machine learning classification algorithms. Results The volume of interest detection model achieved the following metric scores: 0.98 accuracy, 0.89 precision, 0.96 recall, and 0.92 F1 score. Automated segmentation achieved a median dice coefficient >0.99 in all segmented regions. We extracted 330 body composition radiomic features for every patient. For overall survival prediction using clinical and radiomic data, the best-performing feature selection and prediction method achieved areas under the curve–receiver operating characteristic (AUC-ROC) of 0.73 (P < 0.05); for 1-y survival prediction AUC-ROC was 0.74 (P < 0.05). Conclusion Automatically extracted muscle and adipose tissue radiomic features could be used as a predictor of survival in patients with non-small cell lung cancer."
JOUR,"van der Woerd, Benjamin, Chen, Zhuohao, Flemotomos, Nikolaos, Oljaca, Maria, Sund, Lauren Timmons, Narayanan, Shrikanth, Johns, Michael M.",A Machine-Learning Algorithm for the Automated Perceptual Evaluation of Dysphonia Severity,,,2023,"Summary Objectives Auditory-perceptual assessments are the gold standard for assessing voice quality. This project aims to develop a machine-learning model for measuring perceptual dysphonia severity of audio samples consistent with assessments by expert raters. Methods The Perceptual Voice Qualities Database samples were used, including sustained vowel and Consensus Auditory-Perceptual Evaluation of Voice sentences, which were previously expertly rated on a 0–100 scale. The OpenSMILE (audEERING GmbH, Gilching, Germany) toolkit was used to extract acoustic (Mel-Frequency Cepstral Coefficient-based, n = 1428) and prosodic (n = 152) features, pitch onsets, and recording duration. We utilized a support vector machine and these features (n = 1582) for automated assessment of dysphonia severity. Recordings were separated into vowels (V) and sentences (S) and features were extracted separately from each. Final voice quality predictions were made by combining the features extracted from the individual components with the whole audio (WA) sample (three file sets: S, V, WA). Results This algorithm has a high correlation (r = 0.847) with estimates of expert raters. The root mean square error was 13.36. Increasing signal complexity resulted in better estimation of dysphonia, whereby combining the features outperformed WA, S, and V sets individually. Conclusion A novel machine-learning algorithm was able to perform perceptual estimates of dysphonia severity using standardized audio samples on a 100-point scale. This was highly correlated to expert raters. This suggests that ML algorithms could offer an objective method for evaluating voice samples for dysphonia severity. Level of Evidence 4"
JOUR,"Hathaway, Quincy A., Yanamala, Naveena, Siva, Nanda K., Adjeroh, Donald A., Hollander, John M., Sengupta, Partho P.",Ultrasonic Texture Features for Assessing Cardiac Remodeling and Dysfunction,,,2022,"Background Changes in cardiac size, myocardial mass, cardiomyocyte appearance, and, ultimately, the function of the entire organ are interrelated features of cardiac remodeling that profoundly affect patient outcomes. Objectives This study proposes that the application of radiomics for extracting cardiac ultrasonic textural features (ultrasomics) can aid rapid, automated assessment of left ventricular (LV) structure and function without requiring manual measurements. Methods This study developed machine-learning models using cardiac ultrasound images from 1,915 subjects in 3 clinical cohorts: 1) an expert-annotated cardiac point-of-care-ultrasound (POCUS) registry (n = 943, 80% training/testing and 20% internal validation); 2) a prospective POCUS cohort for external validation (n = 275); and 3) a prospective external validation on high-end ultrasound systems (n = 484). In a type 2 diabetes murine model, echocardiography of wild-type (n = 10) and Leptr−/− (n = 8) mice were assessed longitudinally at 3 and 25 weeks, and ultrasomics features were correlated with histopathological features of hypertrophy. Results The ultrasomics model predicted LV remodeling in the POCUS and high-end ultrasound external validation studies (area under the curve: 0.78 [95% CI: 0.68-0.88] and 0.79 [95% CI: 0.73-0.86], respectively). Similarly, the ultrasomics model predicted LV remodeling was significantly associated with major adverse cardiovascular events in both cohorts (P < 0.0001 and P = 0.0008, respectively). Moreover, on multivariate analysis, the ultrasomics probability score was an independent echocardiographic predictor of major adverse cardiovascular events in the high-end ultrasound cohort (HR: 8.53; 95% CI: 4.75-32.1; P = 0.0003). In the murine model, cardiomyocyte hypertrophy positively correlated with 2 ultrasomics biomarkers (R2 = 0.57 and 0.52, Q < 0.05). Conclusions Cardiac ultrasomics-based biomarkers may aid development of machine-learning models that provide an expert-level assessment of LV structure and function."
JOUR,"Tuan, Shao-Ang, Rustia, Dan Jeric Arcega, Hsu, Jih-Tay, Lin, Ta-Te",Frequency modulated continuous wave radar-based system for monitoring dairy cow respiration rate,,,2022,"Heat stress is one of the major challenges in livestock production and management. Due to heat stress, dairy cows experience health and fertility problems as well as lower milk production, resulting in great economic losses to dairy farmers. One of the approaches to assessing heat stress in dairy cows is by monitoring their respiration rate (RR). Many studies show that the RR of dairy cows is highly correlated to heat stress. The measurement of RR is most commonly taken by counting flank movements via human observation, which is labor-intensive and may vary across observers. This paper presents a non-contact system for RR monitoring of dairy cows using millimeter-wave frequency modulated continuous wave (FMCW) radar. The system utilizes an integrated sensor node that collects the data from a FMCW radar and a temperature-humidity sensor. The sensor node was installed in the milking parlor of an experimental dairy farm to continuously measure the displacements from cows’ flank movements. The radar data was converted by the sensor node into RR measurements and sent together with the environmental data to a remote server for post-processing. A dairy cow RR measurement algorithm was developed to process the radar data; it can be divided into three parts: cow presence state determination, timestamp labelling, and individual dairy cow RR matching. A model trained to automatically determine the presence of cows from the collected radar data had an F1-score of 0.95, as verified by manual observation. The timestamp labelling sub-routine was used to merge the predicted states and perform gap and chunk analyses for removing outliers and merging consecutive chunks. Finally, the RR measurements were matched to each timestamp in order to identify the RR of each cow in specific time periods. The algorithm had an R2 of 0.995 and root mean square error (RMSE) of 1.582 breaths/min, also verified by manual observation. The system was operated for a year to investigate the relationship between the RR and temperature-humidity index (THI); this relationship was described using a piecewise linear-exponential regression model, which revealed the effect of THI on the level of heat stress among dairy cows in a subtropical region. The proposed system herein proved the feasibility of employing a novel dairy cow RR monitoring system using FMCW radar, and demonstrated its potential applications for automated assessment of dairy cow heat stress and health monitoring."
JOUR,"Burrows, Liam, Sculthorpe, Declan, Zhang, Hongrun, Rehman, Obaid, Mukherjee, Abhik, Chen, Ke",Mathematical modelling and deep learning algorithms to automate assessment of single and digitally multiplexed immunohistochemical stains in tumoural stroma,,,2024,"Whilst automated analysis of immunostains in pathology research has focused predominantly on the epithelial compartment, automated analysis of stains in the stromal compartment is challenging and therefore requires time-consuming pathological input and guidance to adjust to tissue morphometry as perceived by pathologists. This study aimed to develop a robust method to automate stromal stain analyses using 2 of the commonest stromal stains (SMA and desmin) employed in clinical pathology practice as examples. An effective computational method capable of automatically assessing and quantifying tumour-associated stromal stains was developed and applied on cores of colorectal cancer tissue microarrays. The methodology combines both mathematical models and deep learning techniques with the former requiring no training data and the latter as many inputs as possible. The novel mathematical model was used to produce a digital double marker overlay allowing for fast automated digital multiplex analysis of stromal stains. The results show that deep learning methodologies in combination with mathematical modelling allow for an accurate means of quantifying stromal stains whilst also opening up new possibilities of digital multiplex analyses."
JOUR,"Lyashevskaya, Olga, Panteleeva, Irina, Vinogradova, Olga",Automated assessment of learner text complexity,,,2021,"EFL methodology has always recognized the importance of giving student learners of foreign languages regular and quick feedback on student production, both written and oral. The presented paper describes the decisions taken during the development of an application to measure text complexity, and shows how the results achieved with this application were translated into feedback related to the author’s language proficiency. Along with some standard text complexity features, this tool takes into account those that are significant for Russian learners of English. The application provides students with the statistics of the relevant linguistic features of the text in comparison with texts of the learner essays that were considered the top and the bottom levels in the learner corpus. The paper also points out what text features are especially relevant for the assessment of the essays written in English by Russian students. The choice was made possible after the analysis of 3440 texts from Russian Error-Annotated English Learner Corpus, and after applying methods of machine learning and statistical analysis to predict the grade that could be received for the essay."
JOUR,"Khorasgani, Ahmadreza Riyahi, Kundin, Julia, Divinski, Sergiy V., Steinbach, Ingo",Reassessment of mobility parameters for Cantor High Entropy Alloys through an automated procedure,,,2022,"An automated assessment procedure is performed in order to establish a sophisticated kinetic data bank, introduced and modified by applying consequential iteration steps through the cross-validation method. The nonlinear curve-fitting of the end-member parameters is replaced by a simple linear fitting function via the logarithmic form of the Arrhenius equation. The applied modifications allow us to increase the precision of the method by decreasing the fitting errors. The input data employed here are the tracer diffusion coefficients in the well investigated high entropy alloy Co–Cr–Fe–Mn–Ni. The resulting parameters are in an acceptable agreement with the previously defined parameters in the literature while providing an efficient robust tool for kinetic data base development so that it enable an adequate prediction of diffusion transport."
JOUR,"Girase, Harshayu, Nyayapati, Priya, Booker, Jacqueline, Lotz, Jeffrey C., Bailey, Jeannie F., Matthew, Robert P.","Automated assessment and classification of spine, hip, and knee pathologies from sit-to-stand movements collected in clinical practice",,,2021,"Efficient, cost-effective methods for quantifying patient biomechanics at the point of care can facilitate faster and more accurate diagnoses. This work presents a new method to diagnose pre-surgical back, hip, and knee patients by analysing their sit-to-stand motion captured by a Kinect camera. Kinematic and dynamic time-series features were extracted from patient movements collected in clinic. These features were used to test a variety of machine learning methods for patient classification. The performance of models trained on time-series features were compared against models trained on domain-knowledge features, highlighting the importance of using time-series data for the classification of human movement. Additionally, the effectiveness of using semi-supervised learning is tested on partially labelled datasets, providing insight on how to boost classification performance in situations where labelled patient data is difficult to obtain. The best semi-supervised model achieves ∼73% accuracy in distinguishing individuals with low-back pain, and hip and knee degeneration from control subjects."
JOUR,"Xu, Weizhe, Wang, Weichen, Portanova, Jake, Chander, Ayesha, Campbell, Andrew, Pakhomov, Serguei, Ben-Zeev, Dror, Cohen, Trevor",Fully automated detection of formal thought disorder with Time-series Augmented Representations for Detection of Incoherent Speech (TARDIS),,,2022,"Formal thought disorder (ThD) is a clinical sign of schizophrenia amongst other serious mental health conditions. ThD can be recognized by observing incoherent speech - speech in which it is difficult to perceive connections between successive utterances and lacks a clear global theme. Automated assessment of the coherence of speech in patients with schizophrenia has been an active area of research for over a decade, in an effort to develop an objective and reliable instrument through which to quantify ThD. However, this work has largely been conducted in controlled settings using structured interviews and depended upon manual transcription services to render audio recordings amenable to computational analysis. In this paper, we present an evaluation of such automated methods in the context of a fully automated system using Automated Speech Recognition (ASR) in place of a manual transcription service, with “audio diaries” collected in naturalistic settings from participants experiencing Auditory Verbal Hallucinations (AVH). We show that performance lost due to ASR errors can often be restored through the application of Time-Series Augmented Representations for Detection of Incoherent Speech (TARDIS), a novel approach that involves treating the sequence of coherence scores from a transcript as a time-series, providing features for machine learning. With ASR, TARDIS improves average AUC across coherence metrics for detection of severe ThD by 0.09; average correlation with human-labeled derailment scores by 0.10; and average correlation between coherence estimates from manual and ASR-derived transcripts by 0.29. In addition, TARDIS improves the agreement between coherence estimates from manual transcripts and human judgment and correlation with self-reported estimates of AVH symptom severity. As such, TARDIS eliminates a fundamental barrier to the deployment of automated methods to detect linguistic indicators of ThD to monitor and improve clinical care in serious mental illness."
JOUR,"Graybeal, Austin J., Brandner, Caleb F., Tinsley, Grant M.",Visual body composition assessment methods: A 4-compartment model comparison of smartphone-based artificial intelligence for body composition estimation in healthy adults,,,2022,"Summary Background & aims Visual body composition (VBC) estimates produced from smartphone-based artificial intelligence represent a user-friendly and convenient way to automate body composition remotely and without the inherent geographical and monetary restrictions of other body composition methods. However, there are limited studies that have assessed the reliability and agreement of this method and thus, the aim of this study was to evaluate VBC estimates compared to a 4-compartment (4C) criterion model. Methods A variety of body composition assessments were conducted across 184 healthy adult participants (114 F, 70 M) including dual-energy X-ray absorptiometry and bioimpedance spectroscopy for utilization in the 4C model and automated assessments produced from two smartphone applications (Amazon Halo®, HALO; and myBVI®) using either Apple® or Samsung® phones. Body composition components were compared to a 4C model using equivalence testing, root mean square error (RMSE), and Bland–Altman analysis. Separate analyses by sex and racial/ethnic groups were conducted. Precision metrics were conducted for 183 participants using intraclass correlation coefficients (ICC), root mean squared coefficients of variation (RMS-%CV) and precision error (PE). Results Only %fat produced from HALO devices demonstrated equivalence with the 4C model although mean differences for HALO were <±1.0 kg for FM and FFM. RMSEs ranged from 3.9% to 6.2% for %fat and 3.1–5.2 kg for FM and FFM. Proportional bias was apparent for %fat across all VBC applications but varied for FM and FFM. Validity metrics by sex and specific racial/ethnic groups varied across applications. All VBC applications were reliable for %fat, fat mass (FM), and fat-free mass (FFM) with ICCs ≥0.99, RMS-%CV between 0.7% and 4.3%, and PEs between 0.3% and 0.6% for %fat and 0.2–0.5 kg for FM and FFM including assessments between smartphone types. Conclusions Smartphone-based VBC estimates produce reliable body composition estimates but their equivalence with a 4C model varies by the body composition component being estimated and the VBC being employed. VBC estimates produced by HALO appear to have the lowest error, but proportional bias and estimates by sex and race vary across applications."
JOUR,"Bernhardt, Lisa-Victoria, Hafver, Andreas, Usman, Nafiha, Liu, Edward Yi, Vatn, Jørgen Andreas Åm, Ødegårdstuen, André, Mortensen, Heidi S., Johansen, Ida Beitnes",Automated assessment of cardiac morphological variation in Atlantic salmon (Salmo salar L.),,,2024,"Deviating heart shapes and poor cardiac health is a recurring concern in farmed Atlantic salmon. Morphometric analysis has so far improved our understanding of salmonid cardiac morphology, but assessment of morphological cardiac variation is usually performed manually through measurements of lengths, ratios, and angles. Manual assessment of heart shape is tedious, time-consuming, and not very standardized. It also requires training and alignment of personnel to achieve reliable results. Considering these challenges, we aimed to automate this process using a deep learning model for computer vision to measure the morphological variations of the heart. Here we developed an algorithm for a diagnostic tool to detect variation in cardiac morphology in farmed Atlantic salmon, which we believe can assess cardiac morphological variation in a more objective, reproducible, and reliable manner compared to the manual process. The knowledge derived from this study may represent a crucial step in comprehending and eventually reducing cardiac abnormalities in farmed salmonids, which is essential for improving fish health and welfare and ensuring aquaculture's sustainable growth."
JOUR,"Rayhan, MD., Alam, MD. Golam Rabiul, Dewan, M. Ali Akber, Ahmed, M. Helal Uddin",Appraisal of high-stake examinations during SARS-CoV-2 emergency with responsible and transparent AI: Evidence of fair and detrimental assessment,,,2022,"In situations like the coronavirus pandemic, colleges and universities are forced to limit their offline and regular academic activities. Extended postponement of high-stakes exams due to health risk hereby reduces productivity and progress in later years. Several countries decided to organize the exams online. Since many other countries with large education boards had an inadequate infrastructure and insufficient resources during the emergency, education policy experts considered a solution to simultaneously protect public health and fully resume high-stakes exams -by canceling offline exam and introducing a uniform assessment process to be followed across the states and education boards. This research proposes a novel system using an AI model to accomplish the complex task of evaluating all students across education boards with maximum level of fairness and analyzes the ability to fairly appraise exam grades in the context of high-stakes examinations during SARS-CoV-2 emergency. Basically, a logistic regression classifier on top of a deep neural network is used to output predictions that are as fair as possible for all learners. The predictions of the proposed grade-awarding system are explained by the SHAP (SHapley Additive exPlanations) framework. SHAP allowed to identify the features of the students' portfolios that contributed most to the predicted grades. In the setting of an empirical analysis in one of the largest education systems in the Global South, 81.85% of learners were assigned fair scores while 3.12% of the scores were significantly smaller than the actual grades, which would have had a detrimental effect if it had been applied for real. Furthermore, SHAP allows policy-makers to debug the predictive model by identifying and measuring the importance of the factors involved in the model's final decision and removing those features that should not play a role in the model's “reasoning” process."
JOUR,"I. Alsmadi, N. Aljaafari, M. Nazzal, S. Alhamed, A. H. Sawalmeh, C. P. Vizcarra, A. Khreishah, M. Anan, A. Algosaibi, M. A. Al-Naeem, A. Aldalbahi, A. Al-Humam",,Adversarial Machine Learning in Text Processing: A Literature Survey,2022,2022,"Machine learning algorithms represent the intelligence that controls many information systems and applications around us. As such, they are targeted by attackers to impact their decisions. Text created by machine learning algorithms has many types of applications, some of which can be considered malicious especially if there is an intention to present machine-generated text as human-generated. In this paper, we surveyed major subjects in adversarial machine learning for text processing applications. Unlike adversarial machine learning in images, text problems and applications are heterogeneous. Thus, each problem can have its own challenges. We focused on some of the evolving research areas such as: malicious versus genuine text generation metrics, defense against adversarial attacks, and text generation models and algorithms. Our study showed that as applications of text generation will continue to grow in the near future, the type and nature of attacks on those applications and their machine learning algorithms will continue to grow as well. Literature survey indicated an increasing trend in using pre-trained models in machine learning. Word/sentence embedding models and transformers are examples of those pre-trained models. Adversarial models may utilize same or similar pre-trained models as well. In another trend related to text generation models, literature showed effort to develop universal text perturbations to be used in both black-and white-box attack settings. Literature showed also using conditional GANs to create latent representation for writing types. This usage will allow for a seamless lexical and grammatical transition between various writing styles. In text generation metrics, research trends showed developing successful automated or semi-automated assessment metrics that may include human judgement. Literature showed also research trends of designing and developing new memory models that increase performance and memory utilization efficiency without validating real-time constraints. Many research efforts evaluate different defense model approaches and algorithms. Researchers evaluated different types of targeted attacks, and methods to distinguish human versus machine generated text."
JOUR,"D. Saravanakumar, G. Sakthivel, R. Jegadeeshwaran, J. L. Pathi, M. M. Kumar, T. Muthuramalingam",,Assessment of Vehicle Handling Performance of Drivers Using Machine Learning Algorithms,2022,2022,"Reliable assessment of an individual’s driving skills is very important. The growing population of unskilled drivers will result in disastrous and fatal road accidents. Current situation demands better and accurate automated assessment technique for driver performance. This research aims to development a portable independent assessment system which can be installed in any vehicle. This system will monitor and understand the driver’s skills based on the data from sensors and access their performance using machine learning algorithm. Machine learning based classifiers with more than 90% accuracy are developed for classifying the driver skills. This proposed system will ensure one from possibilities of beaching the formal process and getting the license without qualification, it is a suggestion to the conventional method of assessment. This system could help in building better-skilled driver on the road for a healthy road environment."
JOUR,"X. Ning, Y. Kim, S. D. Min, X. Guo, J. Gab Ho",,Exploring Achilles Tendon Vibration Data Classification for Balance Training: A Wavelet-Based Machine Learning Approach,2024,2024,"Balance training is widely used to improve stability, and Achilles tendon vibration is an effective method. However, evaluation of training progress often relies on Center of Pressure (COP) analysis, which can be challenging for non-experts. To provide an objective and automated assessment, this study explores machine learning techniques. Achilles tendon vibration was applied during standing, and COP data were collected under various conditions, including eyes open/closed and cognitive/non-cognitive tasks. To more accurately assess the training effects, this study applied machine learning techniques that combine wavelet decomposition for feature extraction. Three genetic algorithm-based machine learning models (GA-SVM, GA-LGBM, and GA-LR) were constructed for feature selection and classification. The results showed that all three models achieved classification accuracies above 80% in identifying Achilles tendon vibration and non-vibration data, with SVM achieving the highest accuracy of 89.59%. Among the selected features, entropy category features played a crucial role, and entropy values were higher under Achilles tendon vibration conditions than under non-vibration conditions. This study confirms the feasibility of applying machine learning to Achilles tendon vibration rehabilitation training in the future, and the identified key features also provide a theoretical basis for the analysis of Achilles tendon vibration data. These findings provide valuable insights for further optimization of balance rehabilitation training programs."
JOUR,"M. Bennasar, Y. A. Hicks, S. P. Clinch, P. Jones, C. Holt, A. Rosser, M. Busse",,Automated Assessment of Movement Impairment in Huntington’s Disease,Oct. 2018,2018,"Quantitative assessment of movement impairment in Huntington’s disease (HD) is essential to monitoring of disease progression. This paper aimed to develop and validate a novel low cost, objective automated system for the evaluation of upper limb movement impairment in HD in order to eliminate the inconsistency of the assessor and offer a more sensitive, continuous assessment scale. Patients with genetically confirmed HD and healthy controls were recruited to this observational study. Demographic data, including age (years), gender, and unified HD rating scale total motor score (UHDRS-TMS), were recorded. For the purposes of this paper, a modified upper limb motor impairment score (mULMS) was generated from the UHDRS-TMS. All participants completed a brief, standardized clinical assessment of upper limb dexterity while wearing a tri-axial accelerometer on each wrist and on the sternum. The captured acceleration data were used to develop an automatic classification system for discriminating between healthy and HD participants and to automatically generate a continuous movement impairment score (MIS) that reflected the degree of the movement impairment. Data from 48 healthy and 44 HD participants was used to validate the developed system, which achieved 98.78% accuracy in discriminating between healthy and HD participants. The Pearson correlation coefficient between the automatic MIS and the clinician rated mULMS was 0.77 with a p-value < 0.01. The approach presented in this paper demonstrates the possibility of an automated objective, consistent, and sensitive assessment of the HD movement impairment."
JOUR,"J. Gholizadeh, K. -S. Chun, C. Curd, N. Masters, D. Gibson, Y. Li",,Automated Assessment of Capital Allowances,2024,2024,"Capital allowances play a crucial role in enabling businesses to claim tax relief on specific capital expenditures, reducing their taxable profits and overall tax burden. However, the current manual process for managing capital allowance claims is time-consuming and complex, particularly for small and medium enterprises (SMEs) that often lack access to expert consultation. Furthermore, the distinct nature of construction expenditure on buildings adds to the complexity, with unique costs and data for each property and project. These challenges underscore the necessity for the development of automated technologies and systems for capital allowance assessment. To address these challenges, we present the development of an automated capital allowance assessment system comprising three key components: a capital allowance expert system, a tax coding system, and an integrated web-based application. The capital allowance expert system covers the entire process of capital allowance assessment, leveraging rules and procedures extracted from standardised processes and expertise. The tax coding system automatically classifies textual costing items into corresponding tax codes, addressing the complexity of capital allowance rules and frequent legislative changes. The integrated web-based application offers an interactive experience for data gathering, analysis, coding, and report generation, providing a comprehensive solution for efficient and accurate capital allowance assessment. This automated system addresses the complexities and inefficiencies associated with manual capital allowance assessment. It potentially benefits tax authorities in standardising and streamlining allowance assessment processes while fostering economic growth through accessible services for SMEs and promoting environmental sustainability by encouraging energy-efficient practices."
JOUR,"L. Formstone, W. Huo, S. Wilson, A. McGregor, P. Bentley, R. Vaidyanathan",,Quantification of Motor Function Post-Stroke Using Novel Combination of Wearable Inertial and Mechanomyographic Sensors,2021,2021,"Subjective clinical rating scales represent the gold-standard for diagnosis of motor function following stroke. In practice however, they suffer from well-recognized limitations including assessor variance, low inter-rater reliability and low resolution. Automated systems have been proposed for empirical quantification but have not significantly impacted clinical practice. We address translational challenges in this arena through: (1) implementation of a novel sensor suite combining inertial measurement and mechanomyography (MMG) to quantify hand and wrist motor function; and (2) introduction of a new range of signal features extracted from the suite to supplement predicted clinical scores. The wearable sensors, signal features, and machine learning algorithms have been combined to produce classified ratings from the Fugl-Meyer clinical assessment rating scale. Furthermore, we have designed the system to augment clinical rating with several sensor-derived supplementary features encompassing critical aspects of motor dysfunction (e.g. joint angle, muscle activity, etc.). Performance is validated through a large-scale study on a post-stroke cohort of 64 patients. Fugl-Meyer Assessment tasks were classified with 75% accuracy for gross motor tasks and 62% for hand/wrist motor tasks. Of greater import, supplementary features demonstrated concurrent validity with Fugl-Meyer ratings, evidencing their utility as new measures of motor function suited to automated assessment. Finally, the supplementary features also provide continuous measures of sub-components of motor function, offering the potential to complement low accuracy but well-validated clinical rating scales when high-quality motor outcome measures are required. We believe this work provides a basis for widespread clinical adoption of inertial-MMG sensor use for post-stroke clinical motor assessment."
JOUR,"LEE, Alwyn Vwen Yen",Supporting students’ generation of feedback in large-scale online course with artificial intelligence-enabled evaluation,,,2023,"Educators in large-scale online courses tend to lack the necessary resources to generate and provide adequate feedback for all students, especially when students’ learning outcomes are evaluated through student writing. As a result, students welcome peer feedback and sometimes generate self-feedback to widen their perspectives and obtain feedback, but often lack the support to do so. This study, as part of a larger project, sought to address this prevalent problem in large-scale courses by allowing students to write essays as an expression of their opinions and response to others, conduct peer and self-evaluation, using provided rubric and Artificial Intelligence (AI)-enabled evaluation to aid the giving and receiving of feedback. A total of 605 undergraduate students were part of a large-scale online course and contributed over 2500 short essays during a semester. The research design uses a mixed-methods approach, consisting qualitative measures used during essay coding, and quantitative methods from the application of machine learning algorithms. With limited instructors and resources, students first use instructor-developed rubric to conduct peer and self-assessment, while instructors qualitatively code a subset of essays that are used as inputs for training a machine learning model, which is subsequently used to provide automated scores and an accuracy rate for the remaining essays. With AI-enabled evaluation, the provision of feedback can become a sustainable process with students receiving and using meaningful feedback for their work, entailing shared responsibility from teachers and students, and becoming more effective."
JOUR,"Abo-Elghit, Amira Hamed, Hamza, Taher, Al-Zoghby, Aya",Embedding Extraction for Arabic Text Using the AraBERT Model,,,2022,"Nowadays, we can use the multi-task learning approach to train a machine-learning algorithm to learn multiple related tasks instead of training it to solve a single task. In this work, we propose an algorithm for estimating textual similarity scores and then use these scores in multiple tasks such as text ranking, essay grading, and question answering systems. We used several vectorization schemes to represent the Arabic texts in the SemEval2017-task3-subtask-D dataset. The used schemes include lexical-based similarity features, frequency-based features, and pre-trained model-based features. Also, we used contextual-based embedding models such as Arabic Bidirectional Encoder Representations from Transformers (AraBERT). We used the AraBERT model in two different variants. First, as a feature extractor in addition to the text vectorization schemes’ features. We fed those features to various regression models to make a prediction value that represents the relevancy score between Arabic text units. Second, AraBERT is adopted as a pre-trained model, and its parameters are fine-tuned to estimate the relevancy scores between Arabic textual sentences. To evaluate the research results, we conducted several experiments to compare the use of the AraBERT model in its two variants. In terms of Mean Absolute Percentage Error (MAPE), the results show minor variance between AraBERT v0.2 as a feature extractor (21.7723) and the fine-tuned AraBERT v2 (21.8211). On the other hand, AraBERT v0.2-Large as a feature extractor outperforms the fine-tuned AraBERT v2 model on the used data set in terms of the coefficient of determination (R2) values (0.014050,−0.032861), respectively."
JOUR,"Lyashevskaya, Olga, Panteleeva, Irina, Vinogradova, Olga",Automated assessment of learner text complexity,,,2021,"EFL methodology has always recognized the importance of giving student learners of foreign languages regular and quick feedback on student production, both written and oral. The presented paper describes the decisions taken during the development of an application to measure text complexity, and shows how the results achieved with this application were translated into feedback related to the author’s language proficiency. Along with some standard text complexity features, this tool takes into account those that are significant for Russian learners of English. The application provides students with the statistics of the relevant linguistic features of the text in comparison with texts of the learner essays that were considered the top and the bottom levels in the learner corpus. The paper also points out what text features are especially relevant for the assessment of the essays written in English by Russian students. The choice was made possible after the analysis of 3440 texts from Russian Error-Annotated English Learner Corpus, and after applying methods of machine learning and statistical analysis to predict the grade that could be received for the essay."
JOUR,"Sugiyama, Kohei, Yamanaka, Tsukasa",Proposals and Methods for Foreign Language Learning Using Machine Translation and Large Language Model,,,2023,"In this paper, we propose a new learning model that utilizes machine translation and large language models. While English education has traditionally been conducted through the relationship between English teachers and learners, replacing English teachers with machine translation and large language models may offer the potential to provide an equally or even more efficient and high-quality learning environment. The authors have developed a browser-based service to experience this educational environment for Japanese. To experience a new learning model that is high quality and efficient, we have implemented DeepL, a machine translation service that can translate with high accuracy, and ChatGPT, which uses a large language model that can generate natural sentences and adapt to a variety of tasks interactively. By combining these advanced services, it is now possible to provide explanations of the English translations and to evaluate the essays. This newly developed service is currently being experimentally used in English classes at a Japanese university. Interviews with users who used it revealed that they were easily exposed to English above their level. In other words, the results suggest that this proposed model can provide a better environment for English utilization than teachers. The developed service is available to anyone at the following URL. Transable: https://transable.net"
JOUR,"Süzen, Neslihan, Gorban, Alexander N., Levesley, Jeremy, Mirkes, Evgeny M.",Automatic short answer grading and feedback using text mining methods,,,2020,"Automatic grading is not a new approach but the need to adapt the latest technology to automatic grading has become very important. As the technology has rapidly became more powerful on scoring exams and essays, especially from the 1990s onwards, partially or wholly automated grading systems using computational methods have evolved and have become a major area of research. In particular, the demand of scoring of natural language responses has created a need for tools that can be applied to automatically grade these responses. In this paper, we focus on the concept of automatic grading of short answer questions such as are typical in the UK GCSE system, and providing useful feedback on their answers to students. We present experimental results on a dataset provided from the introductory computer science class in the University of North Texas. We first apply standard data mining techniques to the corpus of student answers for the purpose of measuring similarity between the student answers and the model answer. This is based on the number of common words. We then evaluate the relation between these similarities and marks awarded by scorers. We consider an approach that groups student answers into clusters. Each cluster would be awarded the same mark, and the same feedback given to each answer in a cluster. In this manner, we demonstrate that clusters indicate the groups of students who are awarded the same or the similar scores. Words in each cluster are compared to show that clusters are constructed based on how many and which words of the model answer have been used. The main novelty in this paper is that we design a model to predict marks based on the similarities between the student answers and the model answer. We argue that computational methods be used to enhance the reliability of human scoring, and not replace it. Humans are required to calibrate the system, and to deal with situations that are challenging. Computational methods can provide insight into which student answers will be found challenging and thus be a place human judgement is required."
JOUR,"Filho, Aluizio Haendchen, do Prado, Hércules A., Ferneda, Edilson, Nau, Jonathan",An approach to evaluate adherence to the theme and the argumentative structure of essays,,,2018,"This paper presents an approach based on machine learning for automatic grading of essay adherence to the theme and the argumentative structure of essays. The work was done according to the evaluation model adopted in Brazil to verify the mastery of skills and abilities of students who have completed high school. From specific adherence to the theme and the argumentative structure of essays features and others that are able to capture general aspects of the text, we trained and measured the efficiency of a classification and regression models based on support vector machines. The accuracy level found with this approach shows its effectiveness, pointing out the strategy as promising since other improvements can be achieved, such as improve the set of features with more effective essay-argumentative analysis techniques. Furthermore, we demonstrate how normalization and class balancing techniques are essential to improve our results using the small dataset available for this task. This work also introduces a set of textual cohesion features adapted to Portuguese that showed to be promising for evaluating adherence to the theme and the argumentative structure of essays."
JOUR,"de Carvalho Botega, Luiz Fernando, da Silva, Jonny Carlos",A data-driven Machine Learning approach to creativity and innovation techniques selection in solution development,,,2022,"The creation and refinement of new ideas is a strategic competence for teams and organization to innovate and prosper. This paper addresses the challenge of finding adequate creativity and innovation techniques (CITs) for improving individual or team creativity through the use of Machine Learning (ML). The process of choosing which CIT to use is complex and demanding, especially when taking into consideration the existence of hundreds of techniques and the plurality of different design contexts. This empiric knowledge, usually retained in an expert’s repertoire, can be extracted and implemented in a computational system, making it more available and permanent. This research focused on developing a Decision Support System embedded in an online application with a two-stage ML inference process able to evaluate users’ design scenario through an online form, and infer the most appropriate CITs from the database that would fit their needs. This paper presents two iterative development cycles of the prototype, first focused on core knowledge acquisition, representation, ML implementation, and verification; while second focused on system expansion, addition of web interface, and initial validation. After essaying 12 algorithms, the two-stage model achieved uses a Gradient Boosted Regression Trees algorithm using user provided information about the context to infer the required CITs characteristics; followed by a Logistic Regression classification-ranking algorithm that uses outputs from first model to define which CITs to present to users. To the best of our efforts, no other system was found to use ML approaches to address the problem of CIT selection."
JOUR,"Lotfy, Nourmeen, Shehab, Abdulaziz, Elhoseny, Mohammed, Abu-Elfetouh, Ahmed",An Enhanced Automatic Arabic Essay Scoring System Based on Machine Learning Algorithms,,,2023,"Despite the extensive effort to improve intelligent educational tools for smart learning environments, automatic Arabic essay scoring remains a big research challenge. The nature of the writing style of the Arabic language makes the problem even more complicated. This study designs, implements, and evaluates an automatic Arabic essay scoring system. The proposed system starts with pre-processing the student answer and model answer dataset using data cleaning and natural language processing tasks. Then, it comprises two main components: the grading engine and the adaptive fusion engine. The grading engine employs string-based and corpus-based similarity algorithms separately. After that, the adaptive fusion engine aims to prepare students’ scores to be delivered to different feature selection algorithms, such as Recursive Feature Elimination and Boruta. Then, some machine learning algorithms such as Decision Tree, Random Forest, Adaboost, Lasso, Bagging, and K-Nearest Neighbor are employed to improve the suggested system’s efficiency. The experimental results in the grading engine showed that Extracting DIStributionally similar words using the CO-occurrences similarity measure achieved the best correlation values. Furthermore, in the adaptive fusion engine, the Random Forest algorithm outperforms all other machine learning algorithms using the (80%–20%) splitting method on the original dataset. It achieves 91.30%, 94.20%, 0.023, 0.106, and 0.153 in terms of Pearson’s Correlation Coefficient, Willmot’s Index of Agreement, Mean Square Error, Mean Absolute Error, and Root Mean Square Error metrics, respectively."
JOUR,"Andersen, Michael Riis, Kabel, Kristine, Bremholm, Jesper, Bundsgaard, Jeppe, Hansen, Lars Kai",Automatic proficiency scoring for early-stage writing,,,2023,"In this work, we study the feasibility of using machine learning and natural language processing methods for assessing writing proficiency in Danish with respect to text construction, sentence construction, and use of modifiers. Our work is based on the analytical framework for scoring early writing proposed by Kabel et al. (2022), where each text is first annotated by a human expert according to a predefined coding scheme and subsequently scored using statistical Rasch modeling (Rasch, 1960). We investigate two different strategies for estimating these scores automatically: 1) we propose a system for identifying the central linguistic features automatically mimicking the role of the human experts and 2) we train state-of-the-art discriminative machine learning models to predict the proficiency scores directly from the texts. We conduct a number of experiments to evaluate and compare the two approaches. Our results show strong and statistically significant correlations between the scores generated using the automatic system and scores based on human experts. We also estimate and report the reliability of the individual linguistic features in the automatic annotation system. Finally, we also propose and evaluate an extension of the statistical model, which allows the model to compensate for potential systematic errors in the automatic annotations. The article thereby contributes to the area of automated essay scoring (AES) and shows that it is possible to provide teachers with automated valid and reliable knowledge about the development of their students' writing competences, which they can use in their feedback to students."
CONF,"P. Pathak, S. Raghav, S. Jain, S. Jalal",,Essay Rating System Using Machine Learning,22-23 Oct. 2021,2021,"Essay Rating is the process of assigning grades to the essays written for professional purposes. Automating this process implies the use of specified machine learning algorithms over the standard manual methods to evaluate the essays through Natural Language Processing. Essays can be termed as a large set of textual entities. Grading these essays involves distributing them into a fewer number of distinct categories based on certain constraints and standards. These categories are then used to assign the possible grades. Because of numerous factors like cost, time, biasness, and delay in results, there is a need to switch from manually checking the essays to automated grading. It is a very tedious task to evaluate a bulk of essays while probing every kind of error. Henceforth, this model of Automated Essay Grading System models seems quite assuring. It takes text input from the user and generates grades conforming to the pre-defined standards. After evaluating its useful attributes, an output is obtained in the form of a grade for the given essay. This project comprises of grammar-based Checking (Checking Unique Word count, Sentence Count, Grammatical Mistakes, Spelling Errors) and Context Based Checking (Application of NLP to categorize the essays)."
CONF,"A. M. Bojamma, M. Bhattacharya, T. C. F. Liu",,A Lexical Model for Automated Essay Evaluation System Using Ensemble Learning Techniques,3-5 Oct. 2024,2024,"Automated Essay Scoring (AES) systems have become an attractive alternative to manual scoring due to their cost-saving benefits. This paper assesses the feasibility of such systems by conducting a study using a custom-built machine learning model, which employs the Random Forest Classifier to predict essay grades. Among the features used to train the model, individual and unique word counts emerged as the most effective in influencing the ratings. However, excessive reliance on these features has often been criticized and labeled as reductive. Regarding practical applications, the AES system developed in this study may be better suited for making estimations rather than serving as a substitute for human reviewers. In the future, improvements could focus on enabling the model to analyze higher-level features, such as flow and style."
CONF,"R. Bhatt, M. Patel, G. Srivastava, V. Mago",,A Graph Based Approach to Automate Essay Evaluation,11-14 Oct. 2020,2020,"Despite studies of over six decades, research on automated essay scoring continues to grab ample attention in the Natural Language Processing (NLP) community in part because of its commercial and educational value. However, evaluating such writing compositions or essays in terms of reliability and time is a very challenging process. The need for reliable and rapid scores has elevated the need for a computer system that can answer essay questions that fit precise prompts automatically. NLP and machine learning strategies use Automated Essay Scoring (AES) systems to solve the difficulty of scoring writing tasks. In this paper, we suggest an AES approach that involves not only rule-based grammar and consistency tests, but also the semantic similarity of sentences, thus giving priority to question prompts. Similarity vectors are used obtained after applying semantic algorithms and calculated statistical features. Our system uses 22 features with high predicting power, which is less than current systems, while considering every aspect a human grader may focus on.Predicting scores is achieved using the data provided by Kaggle's ASAP competition using Random Forest. The resulting agreement between the score of the human grader and the prediction of the system is compared with promising results through experimental evaluation."
CONF,"B. S. J. Kapoor, S. M. Nagpure, S. S. Kolhatkar, P. G. Chanore, M. M. Vishwakarma, R. B. Kokate",,An Analysis of Automated Answer Evaluation Systems based on Machine Learning,26-28 Feb. 2020,2020,"Evaluation of the answers remain as one of the most important factors in the learning and teaching process. Automatic evaluation of the answers is very necessary thus, many system has been developed in this digital era. Usually, the subjective answers are in either short form or long answers. The existing system available for evaluation has shown mediocre result in evaluating and scoring the answers. In such frameworks, the data recovery technique to gauge likeness between understudies answer and references answer is utilized, yet such scoring framework doesn't give the best outcome yet. There are very few keywords available in short answers. The answers with such limited number of keywords needs special care, especially while calculating the weighting score of the answers. In the presented study, we try to summarize the existing mechanism and analyses the performance of the system used for automatic grading of the long and descriptive answers."
CONF,"N. G. Pasaribu, G. Budiman, I. D. Irawati",,NasNet Model for Image-Based Essay Scoring Deep Learning,20-21 Aug. 2024,2024,"Automated essay grading systems have increasingly become a focal point in the educational landscape, primarily due to their potential to enhance the efficiency and objectivity of essay evaluation processes. Recognizing this potential, the paper presents an innovative strategy for automated essay grading that leverages the NasNetMobile architecture as its foundational model. The methodology outlined involves a meticulous data division according to specific question numbers, followed by a manual aggregation of scores assigned to each question to derive a final grade for every essay. Through rigorous exper-imentation, the paper identifies an optimal data partitioning strategy, revealing that a 60% split for testing coupled with a 40% allocation for training purposes culminates in a remarkable accuracy rate of 84%. The technical implementation of this system is executed using the Python programming language, TensorFlow Keras for machine learning model development, and Google Colab for project collaboration and resource sharing. The choice of the Adam optimizer, characterized by a learning rate of 0.002 and a batch size of 32, significantly contributed to the system's adeptness in precisely classifying students' essay scores. Demonstrated through these findings, our proposed automated essay grading system showcases its substantial capability to serve as an effective and reliable tool in assessing student essays, thereby holding considerable promise for future adoption and further development within educational settings."
CONF,"H. C. R. Jeewantha, A. N. Gajasinghe, N. I. Naidabadu, T. N. Rajapaksha, D. Kasthurirathna, A. Karunasena",,"English Language Trainer for Non-Native Speakers using Audio Signal Processing, Reinforcement Learning, and Deep Learning",2-3 Dec. 2021,2021,"Lack of basic proficiency and confidence in writing and speaking in English is one of the major social problems faced by most non-native English speakers. Although the general adult literacy rate in Sri Lanka is above average by world standards, the English literacy rate is just 22% among the Sri Lankan adult population. Many individuals face setbacks in achieving their career and academic goals due to these language barriers. In a world where English has become a compulsory requirement to pursue higher education, career development, and performing day-to-day activities, ""English Buddy"" is a software solution developed to enhance the English learning experience of individuals in a more personalized and innovative way. The system provides an all-in-one solution while filling major research and market gaps in existing solutions in the e-learning domain. The system consists of a personalized learning environment, automated pronunciation error detection system, automated essay evaluation process, automated descriptive answer evaluation component based on semantic similarity, and real-time course content rating system. English Buddy is implemented using state-of-the-art technologies such as Audio Signal Processing, Reinforcement Learning, Deep Learning, and NLP. The LSTM, Sentiment Analysis, and Siamese network models have gained accuracy scores of 0.93, 0.92, and 0.81 respectively. Further, the UAT results proved that the personalized recommendations and pronunciation error detection processes are accurate and reliable. This research has been able to overcome the limitations of most existing solutions that follow traditional approaches and provide better results compared to the recent studies in the e-learning research domain."
JOUR,"Abo-Elghit, Amira Hamed, Hamza, Taher, Al-Zoghby, Aya",Embedding Extraction for Arabic Text Using the AraBERT Model,,,2022,"Nowadays, we can use the multi-task learning approach to train a machine-learning algorithm to learn multiple related tasks instead of training it to solve a single task. In this work, we propose an algorithm for estimating textual similarity scores and then use these scores in multiple tasks such as text ranking, essay grading, and question answering systems. We used several vectorization schemes to represent the Arabic texts in the SemEval2017-task3-subtask-D dataset. The used schemes include lexical-based similarity features, frequency-based features, and pre-trained model-based features. Also, we used contextual-based embedding models such as Arabic Bidirectional Encoder Representations from Transformers (AraBERT). We used the AraBERT model in two different variants. First, as a feature extractor in addition to the text vectorization schemes’ features. We fed those features to various regression models to make a prediction value that represents the relevancy score between Arabic text units. Second, AraBERT is adopted as a pre-trained model, and its parameters are fine-tuned to estimate the relevancy scores between Arabic textual sentences. To evaluate the research results, we conducted several experiments to compare the use of the AraBERT model in its two variants. In terms of Mean Absolute Percentage Error (MAPE), the results show minor variance between AraBERT v0.2 as a feature extractor (21.7723) and the fine-tuned AraBERT v2 (21.8211). On the other hand, AraBERT v0.2-Large as a feature extractor outperforms the fine-tuned AraBERT v2 model on the used data set in terms of the coefficient of determination (R2) values (0.014050,−0.032861), respectively."
JOUR,"LEE, Alwyn Vwen Yen",Supporting students’ generation of feedback in large-scale online course with artificial intelligence-enabled evaluation,,,2023,"Educators in large-scale online courses tend to lack the necessary resources to generate and provide adequate feedback for all students, especially when students’ learning outcomes are evaluated through student writing. As a result, students welcome peer feedback and sometimes generate self-feedback to widen their perspectives and obtain feedback, but often lack the support to do so. This study, as part of a larger project, sought to address this prevalent problem in large-scale courses by allowing students to write essays as an expression of their opinions and response to others, conduct peer and self-evaluation, using provided rubric and Artificial Intelligence (AI)-enabled evaluation to aid the giving and receiving of feedback. A total of 605 undergraduate students were part of a large-scale online course and contributed over 2500 short essays during a semester. The research design uses a mixed-methods approach, consisting qualitative measures used during essay coding, and quantitative methods from the application of machine learning algorithms. With limited instructors and resources, students first use instructor-developed rubric to conduct peer and self-assessment, while instructors qualitatively code a subset of essays that are used as inputs for training a machine learning model, which is subsequently used to provide automated scores and an accuracy rate for the remaining essays. With AI-enabled evaluation, the provision of feedback can become a sustainable process with students receiving and using meaningful feedback for their work, entailing shared responsibility from teachers and students, and becoming more effective."
JOUR,"Wilson, Joshua, Huang, Yue",Validity of automated essay scores for elementary-age English language learners: Evidence of bias?,,,2024,"Given increased prevalence of automated writing evaluation (AWE) systems in classroom settings, more research is needed to explore the potential for bias in automated scores with respect to English language learners (ELLs). Thus, this research study investigated and compared the predictive validity of automated and human scoring methods for elementary-age English ELLs on a writing test designed for ELLs and a state writing test designed for the general population. This study focused on the MI Write AWE system and sampled 2829 students comprising ELLs and non-ELLs in Grades 3–5. Results of multilevel regression analyses and simple slopes estimation indicated that, for ELLs, the automated MI Write score had similar predictive validity to the human score for both writing tests. However, automated and human scores for ELLs were less closely related to the state writing test score than scores for non-ELL students. Findings suggest that MI Write’s automated scoring was not uniquely biased relative to human scoring but does reproduce the same biases evident with human scoring. Implications and directions for future research are discussed."
JOUR,"Canz, Thomas, Hoffmann, Lars, Kania, Renate",Presentation-mode effects in large-scale writing assessments,,,2020,"To ensure valid measurement in large-scale assessments, avoiding incorporating construct-irrelevant aspects is crucial. We investigated a potential source of construct-irrelevant variance, i.e. the presentation mode of essays (handwritten vs. computer-typed) and its influence on scoring. Further, we investigated whether the presentation-mode effect is moderated by text quality and legibility, as well as by orthographic, grammatical, and punctuation erroneousness, and whether the presentation mode differs over text genres. Rater-teams scored two versions (originally handwritten vs. computer-typed transcripts) of 430 essays written by students at the end of lower secondary education in Germany on content quality and style quality, as well as the considered moderators. Statistical analyses showed a main effect for presentation mode: Computer-typed transcripts were scored higher than handwritten essays. This effect was moderated by text quality and grammatical erroneousness. Furthermore, the strength of the presentation-mode effect differed by text genre. We argued that the strength as well as the direction of the presentation mode are guided by these and further factors."
JOUR,"Wilson, Joshua, Rodrigues, Jessica",Classification accuracy and efficiency of writing screening using automated essay scoring,,,2020,"The present study leveraged advances in automated essay scoring (AES) technology to explore a proof of concept for a writing screener using the Project Essay Grade (PEG) program. First, the study investigated the extent to which an AES-scored multi-prompt writing screener accurately classified students as at risk of failing a Common Core-aligned English language arts state test. Second, the study explored whether a similar level of classification accuracy could be achieved with a more efficient form of the AES-screener with fewer writing prompts. Third, the classification accuracy of the AES-scored screeners was compared to that of screeners scored for word count. Students in Grades 3–5 (n = 185, 167, and 187, respectively) composed six essays in response to multiple writing-prompt screeners on six different randomly assigned topics, consisting of two essays in each of three different genres (narrative, informative, and persuasive). Receiver operating characteristic (ROC) curve analysis was used to assess classification accuracy and to identify multiple cut scores with associated sensitivity and specificity values, and positive and negative posttest probabilities. Results indicated that the AES-scored multi-prompt screener and screeners with fewer prompts yield acceptable classification accuracy, are efficient, and are more accurate than screeners scored for word count. Overall, results illustrate the viability of writing screening using AES."
JOUR,"Liu, Yuanchao, Han, Jiawei, Sboev, Alexander, Makarov, Ilya",GEEF: A neural network model for automatic essay feedback generation by integrating writing skills assessment,,,2024,"Assessing students' writing ability has always been an important component of research on automatic essay evaluation. The existing methods usually focus on outputting numerical scores, and there is little research on providing feedback on writing quality based on text generation techniques. We believe that the generation of quality feedback in essay writing is more valuable as a reference. In this study, we address the problem of essay feedback generation by proposing an encoder-decoder neural network model called GEEF (Generate Essay Feedback) and suppose that feedbacks are written based on the source essay text and the grading of important writing skills. Besides from the text of input essay, our model also takes in additional features including fluency, coherence, richness, and literary talent. We construct an essay feedback corpus along with human-tagged resources to facilitate the study. Experimental results demonstrate that the proposed approach achieves promising performance compared with other baseline methods on automatic and human evaluation metrics. The generated feedback sentences on different aspects of essay writing can help students understand their strengths and weaknesses in writing skills. In addition, the potential application of this study is that it can assist raters in writing more complex feedback on this basis, as it is often difficult to remember many commonly used feedback patterns when writing comments."
JOUR,"Meyer, Jennifer, Jansen, Thorben, Schiller, Ronja, Liebenow, Lucas W., Steinbach, Marlene, Horbach, Andrea, Fleckenstein, Johanna","Using LLMs to bring evidence-based feedback into the classroom: AI-generated feedback increases secondary students’ text revision, motivation, and positive emotions",,,2024,"Writing proficiency is an essential skill for upper secondary students that can be enhanced through effective feedback. Creating feedback on writing tasks, however, is time-intensive and presents a challenge for educators, often resulting in students receiving insufficient or no feedback. The advent of text-generating large language models (LLMs) offers a promising solution, namely, automated evidence-based feedback generation. Yet, empirical evidence from randomized controlled studies about the effectiveness of LLM-generated feedback is missing. To address this issue, the current study compared the effectiveness of LLM-generated feedback to no feedback. A sample of N = 459 upper secondary students of English as a foreign language wrote an argumentative essay. Students in the experimental group were asked to revise their text according to feedback that was generated using the LLM GPT-3.5-turbo. The control group revised their essays without receiving feedback. We assessed improvement in the revision using automated essay scoring. The results showed that LLM-generated feedback increased revision performance (d = .19) and task motivation (d = 0.36). Moreover, it increased positive emotions (d = 0.34) compared to revising without feedback. The findings highlight that using LLMs allows to create timely feedback that can positively relate to students’ cognitive and affective-motivational outcomes. Future perspectives and the implications for research and practice of using LLM-generated feedback in intelligent tutoring systems are discussed."
JOUR,"McCarthy, Kathryn S., Yan, Eleanor F., Allen, Laura K., Sonia, Allison N., Magliano, Joseph P., McNamara, Danielle S.",On the basis of source: Impacts of individual differences on multiple-document integrated reading and writing tasks,,,2022,"Few studies have explored how general skills in both reading and writing influence performance on integrated, source-based writing. The goal of the present study was to consider the relative contributions of reading and writing ability on multiple-document integrative reading and writing tasks. Students in the U.S. (n = 94) completed two tasks in which they read text sets about a socioscientific issue, generated constructed responses while reading, and then composed integrated essays. They also completed individual difference measures (general knowledge, reading skill, reading strategy use) and wrote independent essays to assess their writing ability. Mixed effect models revealed that general knowledge and reading skills contributed to integrated essay performance, but that once general writing ability was entered into the model, it became the strongest predictor of integrated writing scores. These results suggest the need for deeper consideration of the role of writing skills in integrated reading and writing tasks."
JOUR,"Li, Zhi","Teachers in automated writing evaluation (AWE) system-supported ESL writing classes: Perception, implementation, and influence",,,2021,"Automated writing evaluation (AWE) systems have attracted much attention for their efficiency in feedback provision and automated essay scoring in language classrooms. However, teachers’ roles in this technology-enhanced environment and their potential impact on students’ writing development are still under-investigated. To fill this gap, this classroom-based study examined three English as a second language (ESL) teacher’s perceptions and uses of Criterion®, an AWE system developed by Educational Testing Service (ETS), in four ESL writing classes at a large Midwestern U.S. university. Student’s writing performance data, including submission behaviors, revision types, and progress in grammatical accuracy, were then analyzed in light of teachers’ perceptions and reported uses of Criterion. The results indicate that the teachers took different approaches to integrating Criterion in their classes, which, in turn, was reflected in observable differences in students’ essay submission frequencies on Criterion, revision types, and changes in error rates. The findings shed light on the importance of teacher agency and cognition in technology-supported ESL classrooms. Implications for teaching English writing with AWE systems are discussed."
JOUR,"Lotfy, Nourmeen, Shehab, Abdulaziz, Elhoseny, Mohammed, Abu-Elfetouh, Ahmed",An Enhanced Automatic Arabic Essay Scoring System Based on Machine Learning Algorithms,,,2023,"Despite the extensive effort to improve intelligent educational tools for smart learning environments, automatic Arabic essay scoring remains a big research challenge. The nature of the writing style of the Arabic language makes the problem even more complicated. This study designs, implements, and evaluates an automatic Arabic essay scoring system. The proposed system starts with pre-processing the student answer and model answer dataset using data cleaning and natural language processing tasks. Then, it comprises two main components: the grading engine and the adaptive fusion engine. The grading engine employs string-based and corpus-based similarity algorithms separately. After that, the adaptive fusion engine aims to prepare students’ scores to be delivered to different feature selection algorithms, such as Recursive Feature Elimination and Boruta. Then, some machine learning algorithms such as Decision Tree, Random Forest, Adaboost, Lasso, Bagging, and K-Nearest Neighbor are employed to improve the suggested system’s efficiency. The experimental results in the grading engine showed that Extracting DIStributionally similar words using the CO-occurrences similarity measure achieved the best correlation values. Furthermore, in the adaptive fusion engine, the Random Forest algorithm outperforms all other machine learning algorithms using the (80%–20%) splitting method on the original dataset. It achieves 91.30%, 94.20%, 0.023, 0.106, and 0.153 in terms of Pearson’s Correlation Coefficient, Willmot’s Index of Agreement, Mean Square Error, Mean Absolute Error, and Root Mean Square Error metrics, respectively."
JOUR,"Stephen, Tracey C., Gierl, Mark C., King, Sharla",Automated essay scoring (AES) of constructed responses in nursing examinations: An evaluation,,,2021,"Nursing students’ higher-level thinking skills are ideally assessed through constructed-response items. At the baccalaureate level in North America, however, this exam format has largely fallen into disuse owing to the labor-intensive process of scoring written exam papers. The authors sought to determine if automated essay scoring (AES) would be an efficient and reliable alternative to human scoring. Four constructed-response exam items were administered to an initial cohort of 359 undergraduate nursing students in 2016 and to a second cohort of 40 students in 2018. The items were graded by two human raters (HR1 & HR2) and an AES software platform. AES approximated or surpassed agreement and reliability measures achieved by the HR1 and HR2 with each other, and AES surpassed both human raters in efficiency. A list of answer keywords was created to increase the efficiency and reliability of AES. Low agreement between human raters may be explained by rater drift and fatigue, and shortcomings in the development of Item 1 may have reduced its overall agreement and reliability measures. It can be concluded that AES is a reliable and cost-effective means of scoring constructed-response nursing examinations, but further studies employing greater sample sizes are needed to establish this definitively."
JOUR,"Wang, Elaine Lin, Matsumura, Lindsay Clare, Correnti, Richard, Litman, Diane, Zhang, Haoran, Howe, Emily, Magooda, Ahmed, Quintana, Rafael",eRevis(ing): Students’ revision of text evidence use in an automated writing evaluation system,,,2020,"We investigate students’ implementation of the feedback messages they received in an automated writing evaluation system (eRevise) that aims to improve students’ use of text evidence in their writing. Seven 5th and 6th-grade teachers implemented eRevise (n = 143 students). Qualitative analysis of students’ essays across first and second drafts suggests that the majority of students made changes to their essays that were in line with the feedback they received, though few of these changes resulted in substantive improvement in essay quality. Twenty percent of students did not attempt to implement the feedback; these students generally made small changes to wording or mechanics. In response to the feedback to add more evidence, students whose essays did not improve or showed only slight improvement frequently added in evidence that was not text based or repeated evidence already present in the first draft. When prompted to explain how the evidence they included connected to their claim, many students paraphrased the evidence, added a short conclusion, or explained generally how the evidence supports claims (not how this was instantiated in their writing). Implications for teaching argument writing and for designing AWE systems that support students to successfully revise their essays are discussed."
JOUR,"Al-Adeimi, Shireen, O'Connor, Catherine",Exploring the relationship between dialogic teacher talk and students’ persuasive writing,,,2021,"Studies have documented the importance of dialogic classroom discourse for supporting academic outcomes such as reading comprehension and vocabulary development. This study examines the relationship between teacher talk during whole-classroom discussions in 42 classrooms and post-discussion persuasive essays from students in grades four through seven (n = 471). Teacher talk was coded by type of question (contestable, semi-open, or quiz-like) and teachers' follow-ups (prompting, pressing for reasoning, active listening), and further categorized as indicating either high or low levels of dialogic talk. Multilevel modeling that accounts for student participation rate, discussion topic, and students' demographic information shows that high dialogic teacher talk positively predicts students’ persuasive essay scores, while low dialogic teacher talk negatively predicts their scores. The study supports existing hypotheses about the role of teacher dialogic talk in whole-class settings."
JOUR,"Kormos, Judit, Suzuki, Shungo, Rossi, Olena",The role of creativity in second language writing performance,,,2024,"Our study seeks to answer the question of what the impact of creativity is on teenage Hungarian L2 learners' performance in a written argumentative and narrative task. Ninety-five participants at an intermediate level of language proficiency wrote a story based on six unrelated pictures and an argumentative essay in English. Participants also completed the Megújított Barkóczy-Klein Kreatív Potenciálteszt (MKB, Revised Barkóczy-Klein Creative Potential test). A latent variable analysis using structural equation modelling was used to examine the relationship between two latent components of creativity: adaptivity (estimated by scores of elaboration, resistance to early closure and abstractness of title) and innovation (estimated by creative fluency and originality scores) and the latent variable of L2 writing which was estimated by rating scores of five assessment criteria. The results show that the argumentative essays of L2 learners characterized by high levels of creative fluency and originality demonstrated lower levels of writing quality. On the other hand, the argumentative essays of participants who scored higher on the adaptation aspects of creativity were more highly rated."
JOUR,"Smerdon, David","AI in essay-based assessment: Student adoption, usage, and performance",,,2024,"The rise of generative artificial intelligence (AI) has sparked debate in education about whether to ban AI tools for assessments. This study explores the adoption and impact of AI tools on an undergraduate research proposal assignment using a mixed-methods approach. From a sample of 187 students, 69 completed a survey, with 46 (67%) reporting the use of AI tools. AI-using students were significantly more likely to be higher-performing, with a pre-semester average GPA of 5.46 compared to 4.92 for non-users (7-point scale, p = .025). Most students used AI assistance for the highest-weighted components of the task, such as the research topic and methods section, using AI primarily for generating research ideas and gathering feedback. Regression analysis suggests that there was no statistically significant effect of AI use on student performance in the task, with the preferred regression specification estimating an effect size of less than 1 mark out of 100. The qualitative analysis identified six main themes of AI usage: idea generation, writing assistance, literature search, grammar checking, statistical analysis, and overall learning impact. These findings indicate that while AI tools are widely adopted, their impact on academic performance is neutral, suggesting a potential for integration into educational practices without compromising academic integrity."
JOUR,"Tate, Tamara P., Steiss, Jacob, Bailey, Drew, Graham, Steve, Moon, Youngsun, Ritchie, Daniel, Tseng, Waverly, Warschauer, Mark",Can AI provide useful holistic essay scoring?,,,2024,"Researchers have sought for decades to automate holistic essay scoring. Over the years, these programs have improved significantly. However, accuracy requires significant amounts of training on human-scored texts—reducing the expediency and usefulness of such programs for routine uses by teachers across the nation on non-standardized prompts. This study analyzes the output of multiple versions of ChatGPT scoring of secondary student essays from three extant corpora and compares it to quality human ratings. We find that the current iteration of ChatGPT scoring is not statistically significantly different from human scoring; substantial agreement with humans is achievable and may be sufficient for low-stakes, formative assessment purposes. However, as large language models evolve additional research will be needed to continue to assess their aptitude for this task as well as determine whether their proximity to human scoring can be improved through prompting or training."
JOUR,"McNamara, Danielle S., Watanabe, Micah, Huynh, Linh, McCarthy, Kathryn S., Allen, Laura K., Magliano, Joseph P.",Summarizing versus rereading multiple documents,,,2024,"Writing an integrated essay based on multiple-documents requires students to both comprehend the documents and integrate the documents into a coherent essay. In the current study, we examined the effects of summarization as a potential reading strategy to enhance participants’ multiple-document comprehension and integrated essay writing. Participants (n = 295) were randomly assigned to either summarize or reread five texts on sun exposure and radiation. They produced an integrated essay based on the texts that they read, which were scored by expert raters. Finally, the participants completed three knowledge assessments (topic, domain, general). Readers who summarized texts had lower essay scores than readers who reread the texts. However, within the summary group, summary quality was positively correlated with essay score. These findings are discussed within the context of multiple-document comprehension and writing skill."
JOUR,"Jansen, Thorben, Vögelin, Cristina, Machts, Nils, Keller, Stefan, Köller, Olaf, Möller, Jens",Judgment accuracy in experienced versus student teachers: Assessing essays in English as a foreign language,,,2021,"Teacher judgment accuracy (TJA) is a central part of diagnostic competence. Research has revealed heterogeneous results regarding teacher characteristics as determinants of TJA. In the present experimental study N = 36 experienced and N = 47 student teachers holistically and analytically assessed four student essays. We compared the judgments of teachers and student teachers to machine scores and expert ratings. Experienced teachers’ judgments were more negative than student teachers’, and both judgments were more negative than those made by experts, and the machine. The results remained stable, even after controlling for content knowledge. They are discussed in relation to the assumption of an expert-blind-spot."
JOUR,"Eurboonyanun, Chalerm, Wittayapairoch, Jakrapan, Aphinives, Potchavit, Petrusa, Emil, Gee, Denise W., Phitayakorn, Roy",Adaptation to Open-Book Online Examination During the COVID-19 Pandemic,,,2021,"INTRODUCTION COVID-19 altered medical education systems worldwide as many medical schools quickly changed to online assessment systems. However, the feasibility of online assessment and how it compares to traditional examinations is unclear. METHODS We compared 4th year medical students' online surgery clerkship assessment scores to the traditional written examinations. The percent of correct scores using online open-book examination was compared to the results of the traditional closed-book examination in the previous three rotations. Additional correlation between grade point average(GPA) and examination performance were reviewed. RESULTS Compared with the traditional groups, medical students who took the online, open-book examination had a significantly higher mean score in both MCQ(85.21 vs. 77.36, 72.43, 83.00, p<0.001) and essay examinations (187.36 vs. 158.77, 152.17, 152.29, p<0.001), but a significantly lower mean score in short answer examination (60.09 vs. 66.79, 67.73, 64.82, p<0.001). The online open-book examination group had a significantly lower correlation between the essay score and their GPA than the previous traditional groups (z=2.81 p=0.005, z=2.23 p=0.026, z=2.19 p=0.029). CONCLUSION Although an online, open-book examination was feasible during the COVID-19 pandemic, this study indicates that mean scores are significantly different which has important implications regarding grading and standard setting. More research is required to assess other effects of this new assessment on long-term knowledge retention and application."
JOUR,"Yasuda, Sachiko",Does “more complexity” equal “better writing”? Investigating the relationship between form-based complexity and meaning-based complexity in high school EFL learners’ argumentative writing,,,2024,"The study examines the relationship between form-based complexity and meaning-based complexity in argumentative essays written by high school students learning English as a foreign language (EFL) in relation to writing quality. The data comprise argumentative essays written by 102 Japanese high school learners at different proficiency levels. The students’ proficiency levels were determined based on the evaluation of their argumentative essays by human raters using the GTEC rubric. The students’ essays were analyzed from multiple dimensions, focusing on both form-based complexity (lexical complexity, large-grained syntactic complexity, and fine-grained syntactic complexity features) and meaning-based complexity (argument quality). The results of the multidimensional analysis revealed that the most influential factor in determining overall essay scores was not form-based complexity but meaning-based complexity achieved through argument quality. Moreover, the results indicated that meaning-based complexity was strongly correlated with the use of complex nominals rather than clausal complexity. These insights have significant implications for both the teaching and assessment of argumentative essays among high school EFL learners, underscoring the importance of understanding what aspects of writing to prioritize and how best to assess student writing."
JOUR,"Azmi, Aqil M., Al-Jouie, Maram F., Hussain, Muhammad",AAEE – Automated evaluation of students’ essays in Arabic language,,,2019,"Assessing student’s essay writing and providing thoughtful feedback is a truly labor-intensive and time-consuming task. With human instructors already overwhelmed, the alternate is to consider a computer-based grading. Recent advances have generated renewed interest in automatic evaluation of essays (AEE). The AEEs instantaneous feedback and more consistent grading helps students draft better essays. This work presents a system to automatically grade the school children essays in Arabic, calling it AAEE for “automatic Arabic essays evaluator”. The system is modeled upon the scoring scheme followed by the school instructors in Saudi Arabia. The instructors had specific criteria upon which an essay is assessed. Putting these criteria together we developed a system that relies on Latent Semantic Analysis, and Rhetorical Structure Theory. With this design we are able to assess individual components of the essay such as language proficiency, structure of the essay etc. To test the system, we collected essays by local school children covering grades 7–12. A total of 350 different handwritten essays—spanning eight different topics—each transcribed into computer readable format. The AAEE shows that 90% of the test essays were correctly scored, and a correlation of 0.756 between automatic and teachers’ scoring. This exceeds the human-human correlation of 0.709 for the Arabic essays."
JOUR,"Lyashevskaya, Olga, Panteleeva, Irina, Vinogradova, Olga",Automated assessment of learner text complexity,,,2021,"EFL methodology has always recognized the importance of giving student learners of foreign languages regular and quick feedback on student production, both written and oral. The presented paper describes the decisions taken during the development of an application to measure text complexity, and shows how the results achieved with this application were translated into feedback related to the author’s language proficiency. Along with some standard text complexity features, this tool takes into account those that are significant for Russian learners of English. The application provides students with the statistics of the relevant linguistic features of the text in comparison with texts of the learner essays that were considered the top and the bottom levels in the learner corpus. The paper also points out what text features are especially relevant for the assessment of the essays written in English by Russian students. The choice was made possible after the analysis of 3440 texts from Russian Error-Annotated English Learner Corpus, and after applying methods of machine learning and statistical analysis to predict the grade that could be received for the essay."
JOUR,"Whitelock-Wainwright, Alexander, Laan, Nathan, Wen, Dunwei, Gašević, Dragan",Exploring student information problem solving behaviour using fine-grained concept map and search tool data,,,2020,"For learners to be successful in an information problem solving task, they should be able to effectively regulate their own behaviour. Despite views that such behaviour may come naturally to an individual, research generally shows that some learners do experience problems with information problem solving that may stem from such things as limited prior knowledge. As a means of addressing this challenge, the authors explored how the provision of both a concept map and search tool could overcome barriers to effective information problem solving. This was explored in the current study using data collected from 111 undergraduate students who completed an information problem solving activity, wherein a concept map and search tool were provided to help them write two short essays. Through the use of event-sequence analysis and hierarchical clustering, two information problem solving strategy groups were identified (High Engagement and Low Engagement), which differed across time-on-task and essay grades. Additional analyses were undertaken to explore self-reported prior knowledge or motivation as predictors of group assignment. The findings show that even when presented with opportunities (i.e., concept map) to support effective information problem solving, not all learners will take advantage or glean the benefits of such tools. Trace data methodology is shown to be a promising approach to explore information problem solving behaviour that can overcome the limitations of solely relying upon self-report measures."
JOUR,"Liu, Yingliang, Huang, Jinyan",The quality assurance of a national English writing assessment: Policy implications for quality improvement,,,2020,"The purpose of this study was to examine the quality assurance issues of a national English writing assessment in Chinese higher education. Specifically, using generalizability theory and rater interviews, this study examined how the current scoring policy of the TEM-4 (Test for English Majors – Band 4, a high-stakes national standardized EFL assessment in China) writing could impact its score variability and reliability. Eighteen argumentative essays written by nine English major undergraduate students were selected as the writing samples. Ten TEM-4 raters were first invited to use the authentic TEM-4 writing scoring rubric to score these essays holistically and analytically (with time intervals in between). They were then interviewed for their views on how the current scoring policy of the TEM-4 writing assessment could affect its overall quality. The quantitative generalizability theory results of this study suggested that the current scoring policy would not yield acceptable reliability coefficients. The qualitative results supported the generalizability theory findings. Policy implications for quality improvement of the TEM-4 writing assessment in China are discussed."
JOUR,"Cong, Yan",Demystifying large language models in second language development research,,,2025,"Evaluating students' textual response is a common and critical task in language research and education practice. However, manual assessment can be tedious and may lack consistency, posing challenges for both scientific discovery and frontline teaching. Leveraging state-of-the-art large language models (LLMs), we aim to define and operationalize LLM-Surprisal, a numeric representation of the interplay between lexical diversity and syntactic complexity, and to empirically and theoretically demonstrate its relevance for automatic writing assessment and Chinese L2 (second language) learners’ English writing development. We developed an LLM-based natural language processing pipeline that can automatically compute text Surprisal scores. By comparing Surprisal metrics with the widely used classic indices in L2 studies, we extended the usage of computational metrics in Chinese learners’ L2 English writing. Our analyses suggested that LLM-Surprisals can distinguish L2 from L1 (first language) writing, index L2 development stages, and predict scores provided by human professionals. This indicated that the Surprisal dimension may manifest itself as critical aspects in L2 development. The relative advantages and disadvantages of these approaches were discussed in depth. We concluded that LLMs are promising tools that can enhance L2 research. Our showcase paves the way for more nuanced approaches to computationally assessing and understanding L2 development. Our pipelines and findings will inspire language teachers, learners, and researchers to operationalize LLMs in an innovative and accessible manner."
JOUR,"Andersen, Michael Riis, Kabel, Kristine, Bremholm, Jesper, Bundsgaard, Jeppe, Hansen, Lars Kai",Automatic proficiency scoring for early-stage writing,,,2023,"In this work, we study the feasibility of using machine learning and natural language processing methods for assessing writing proficiency in Danish with respect to text construction, sentence construction, and use of modifiers. Our work is based on the analytical framework for scoring early writing proposed by Kabel et al. (2022), where each text is first annotated by a human expert according to a predefined coding scheme and subsequently scored using statistical Rasch modeling (Rasch, 1960). We investigate two different strategies for estimating these scores automatically: 1) we propose a system for identifying the central linguistic features automatically mimicking the role of the human experts and 2) we train state-of-the-art discriminative machine learning models to predict the proficiency scores directly from the texts. We conduct a number of experiments to evaluate and compare the two approaches. Our results show strong and statistically significant correlations between the scores generated using the automatic system and scores based on human experts. We also estimate and report the reliability of the individual linguistic features in the automatic annotation system. Finally, we also propose and evaluate an extension of the statistical model, which allows the model to compensate for potential systematic errors in the automatic annotations. The article thereby contributes to the area of automated essay scoring (AES) and shows that it is possible to provide teachers with automated valid and reliable knowledge about the development of their students' writing competences, which they can use in their feedback to students."
CONF,"N. Zainal, M. H. Abu Hassan",,Automated Essay Scoring (AES) using English Essay Question,8-9 Nov. 2022,2022,"Automated Essay Scoring (AES) is a one of the important research areas in educational technology. Research about AES is started in the early 1960s and keep growing in development along with the advances of the computing technology. AES is more widely use by the educational system for assessment and classroom activities, it being use in all layers of education. The potential for Automated Essay Scoring is being used widely becomes a reality as more and more classroom activities, assessment, and test preparation materials are supplied online. These essay questions might include everything from arithmetic, where students are asked to explain how they arrived at their answers, to science, where they might be asked to define words or explain experiments, or history, where they must ask to explain or discuss an event. In this study we try to design the AES using Natural Language Processing (NLP) and machine learning techniques to evaluate the student's answer by comparing it with the answer scheme. It is not simply a string-matching program and need a proper system to process the students answer. We propose the 4 main process to the system that is Spelling Checking, Pre-Processing, Latent Semantic Analysis and Thesaurus Checking. All this process is combined and analyze to become a good AES system. Each of this process mean give somethings important to the system flow on how the essay going to be evaluate. The system has been done some experiment and the system get the average correlation between system scores and human appraiser scores is only 70%. However, there needs to be more research on the future use of this Automatic Essay Scoring system."
CONF,"Husni, F. H. Rachman, I. O. Suzanti, M. K. Sari",,Word Ambiguity Identification using POS Tagging in Automatic Essay Scoring,19-21 Oct. 2022,2022,"Automatic Essay Scoring (AES) is one of the evaluations carried out by teachers to measure their students. AES is an interesting topic and looking for better accuracy. In AES, the test documents are the student’s answers, and the ground truth is the teacher or book answers. Essay answers from students can consist of one or more sentences. The formation of words in a sentence can affect the meaning of the sentence. In Indonesia, some words can have more than one meaning (polysemy), which can lead to ambiguity of meaning. One example of an Indonesian word with an ambiguous meaning is ‘bisa’. Based on Indonesia Dictionary (KBBI), it has three meanings (capable, toxic substance, and greeting shaman in the traditional ‘pingitan’ ceremony). This research attempts to overcome the ambiguity by integrating POS tagging into the text preprocessing phase before calculating the similarity between student answers and book answers using cosine similarity. The test results show that these approaches can produce an accuracy of up to 79%."
CONF,"M. Idhom, I. G. P. A. Buditjahjanto, Munoto, M. Samani",,Performance Evaluation of Automated Essay Scoring Online System for Competency Assessment of Community Academy,10-11 Sept. 2022,2022,"The essay scoring system has been done manually so far, which has become an obstacle in the learning evaluation process. The use of the Automated Essay Scoring (AES) system is an alternative to developing automated scoring applications. The purpose of this research paper is to evaluate the performance of the AES online system on the assessment of vocational education competencies in the IT Multimedia field at the Community Academy in Blitar and Pacitan, East Java. The method of this study is consisting of pre-processing text, similarity calculation with cosine similarity and correlation method to measure performance of AES with human rater. This study compares the performance of the assessment system using a human rater and the AES online system. The results show that the correlation value is 0.903569186 with excellent criteria and the MAE (Mean Absolute Error) value is 0.133547009 which indicates a fairly small error value."
CONF,"L. B. Das, C. V. Raghu, G. Jagadanand, R. A. R. George, P. Yashasawi, N. A. A. Kumaran, V. K. Patnaik",,FACToGRADE: Automated Essay Scoring System,28-30 July 2022,2022,"The significance of technology has exponentially grown in this increasingly virtual world, making online learning and evaluation the new normal. In the evaluation of writing assignments, many existing automated methods either focus on semantics or machine-learned features alone. In our project, we incorporate content analysis with structural analysis to provide a complete grading system. Also, revision and feedback are essential aspects of the writing process, with the help of which, students may increase their writing quality. Here, Automated Essay Scoring (AES) systems can be very useful as they can provide the student with a score as well as a feedback within seconds. Below we present an automated scoring system, built using the concepts of Long Short Term Memory (LSTM) and Entity Detection, incorporating a User Interface to input an essay and obtain its score along with the breakdown analysis of the essay."
CONF,"S. Xue, J. Zhang, J. Zhou, F. Ren",,Robust Automated Essay Scoring by Using Attentive Capsule,26-28 Nov. 2022,2022,"The computer-assisted essay scoring systems can provide accurate scores in a short time, relieving the stress of teachers assessing student essays, which has attracted widespread attention from academia and industry fields. Considering the existing advanced NLP techniques, we propose a robust end-to-end AES model by leveraging the capsule network framework with multiple losses. The proposed model has testified with baseline models on the public Automated student Assessment Prize (ASAP) dataset. The results demonstrate that the proposed model achieved the stateof-the-art result of the ASAP dataset. The experiment results in the ASAP corpus proved that the proposed model can further improve the accuracy of the PLM model for the AES task."
CONF,"J. J. J. E. Catulay, M. E. Magsael, D. O. Ancheta, J. A. Costales",,Neural-Network Architecture Approach: An Automated Essay Scoring Using Bayesian Linear Ridge Regression Algorithm,26-27 Nov. 2021,2021,"Most people are relying on technology in various industries, such as education, where people are more likely to use technology as a platform for knowledge acquisition. In this study, the researchers proposed an Automated Essay Scoring or AES to help the teachers minimize the time in grading essay work of the student, prevent biased ratings and provide a feedback mechanism for the students. The study proposed a Neural-Network Approach Architecture and Bayesian Linear Ridge Regression Algorithm to improve the correctness and reliability of the AES system and dimensions we are going to use. We also use the new Hybrid Model or Hybrid Agile to have a detailed approach in developing our study. We used the dataset from the Hewlett Foundation, the Automated Student Assessment Prize (ASAP) from Kaggle. We also gather information in reliable sources and collect data to test the accuracy and reliability of our AES system."
CONF,"Gunawansyah, R. Rahayu, Nurwathi, B. Sugiarto, Gunawan",,Automated Essay Scoring Using Natural Language Processing And Text Mining Method,4-5 Nov. 2020,2020,"The use of technology really helps to maximized the effectiveness and efficiency of work expecially in the education field. Elearning is the concept of education that has begun to be widely implemented at this covid-19 pandemic to avoid the spread of transmission through social distancing. One of elearning types is essay but for large participants, it need much effort for evaluate by human rater. The inconsistency of assessment by the rater due to fatigue can also affect the quality of the assessment. Developing a system that can learn and understand on its own without having to be repeatedly programmed by humans used machine learning and computational linguistics to study the interaction between computers and human natural language used natural language processing proposed in this research. Natural language processing and text mining methods are able to provide a good assessment which is influenced by several processes, namely tokenization, stopword, stemming and support with the number of keywords, and the synonym of more complex keywords. The automated essay scoring system is proven to provide consistent and objective assessments and is able to approach human raters assessments."
CONF,"J. O. Contreras, S. Hilles, Z. A. Bakar",,Essay Question Generator based on Bloom’s Taxonomy for Assessing Automated Essay Scoring System,15-17 June 2021,2021,"An automated essay scoring system (AES) is advantageous in evaluating student’s learning outcomes since it gives them the chance to exhibit their knowledge. Most of the AES is using machine learning (ML) to enhance student’s scores but did not consider the proper construction of the essay questions. This study aims to integrate the cognitive level of Blooms’ taxonomy (BT) in constructing essay questions and compare the scores of the student. Identifying the most appropriate ML method in classifying essay exam questions (EEQ) based on BT that will be embedded in the Essay Question Generator (EQG). Using F1-Measure, the evaluation results show that the Support Vector Machine (SVM) (85.7%) outperforms Naïve Bayes (82.6%) and K-Nearest Neighbor (77.6%). Therefore, SVM together with the NLP techniques is applied to automatically extract essay questions from the given text for the teachers to select and apply. The EQG was evaluated using the scores of 375 students who answered two sets of essay exam questions using Bloom’s Taxonomy (BT) and without Bloom’s taxonomy (NBT). Using frequency distribution, the scores between two types were evaluated and the result shows that most students performed well in answering the essay exam using BT 5.6% of the students obtains a perfect score of 5.0 but nobody got 5.0 for NBT. In a conclusion, this study shows that the essay questions constructed according to BT cognitive level produce higher scores using EQG when compared to exam questions prepared by the teachers."
CONF,"A. N. Oktaviani, M. Z. Alief, L. Santiar, P. D. Purnamasari, A. A. P. Ratna",,Automatic Essay Grading System for Japanese Language Exam using CNN-LSTM,13-15 Oct. 2021,2021,"This paper discusses the design for the development of an automatic essay grading system (SIMPLEO) using variations of the Convolutional Neural Network (CNN) and hybrid Convolutional Neural Network (CNN)-Long Short-term Memory (LSTM) for the assessment of the Japanese essay exam which is being developed by the Department of Electrical Engineering, University of Indonesia. Of the several variations tested, the most stable model is a model that has CNN-LSTM with kernel sizes of 5, the number of filters 64, pool size of 4, LSTM hidden units of 25, batch size of 50, repeated training of 50 epochs, and the SGD optimizer with a learning rate of 0.01 produces the highest prediction accuracy, which is 70.07%."
CONF,"P. Lagakis, S. Demetriadis",,Automated essay scoring: A review of the field,11-13 Nov. 2021,2021,"This paper critically reviews the recently published scientific literature on the task of Automated Essay Scoring (AES), by examining the various systems and approaches used. Automated Essay Scoring, which is the process of automating the evaluation of answers to open-ended questions, most usually in educational settings, by utilizing NLP techniques, gathers an increasing amount of interest, due to its potential applications both commercially and as part of the learn-ing process. The focus of this paper is to analyze the most popular approaches in recently published AES systems, categorize the systems with respect to certain characteristics in their design, the datasets that they use and the evaluation schemas that are used to evaluate them, and finally discuss the recent trends and challenges of the field of AES."
CONF,"A. R. Arifin, P. D. Purnamasari, A. A. Putri Ratna",,Automatic Essay Scoring for Indonesian Short Answers using Siamese Manhattan Long Short-Term Memory,12-13 June 2021,2021,"Sistem Penilaian Esai Otomatis (SIMPLE-O) is developed by the Department of Electrical Engineering Universitas Indonesia to assess Indonesian short essay answers. This paper discusses the development of SIMPLE-O using Siamese Manhattan Long Short-Term Memory. Answers from students and lecturers are taken as the input of the system. Both answers are processed with identical LSTM layers. Then, the similarity between them is calculated with a simple similarity equation to determine the score. The average accuracy for the training phase is 92.82 and 84.03 for the validation"
CONF,"H. Thamrin, N. A. Verdikha, A. Triyono",,Text Classification and Similarity Algorithms in Essay Grading,16-17 Dec. 2021,2021,"Open and closed questions are both important in an examination to evaluate the teaching and learning process. Both types of questions have their own advantage and disadvantage. Open-ended questions in the form of essays require manual grading that is harder and time-consuming. This paper presents an effort to grade essay answers based on classification techniques and similarity algorithms. We examine 1648 essay answers from an examination of Bahasa Indonesia. Teachers use integer values in the range of 0–12 to score the answer. Our result suggests that both classification techniques and similarity algorithms result in about the same grading as shown by the RMSE values in the range of 2.7–3.0. Hence, the use of either technique is apparently acceptable depending on the situation."
CONF,"D. T. Dung, F. Triawan, H. Mima, J. S. Cross",,Automated Essay Grading of Constructive Response Test Responses for Mechanical Engineering Students,28 Nov.-1 Dec. 2023,2023,"Machine learning education related applications have increased with the appearance of large language models. While automatic essay grading (AEG) has been studied extensively in the past, most of these studies have focused on evaluating English competence instead of assessing knowledge competence in an engineering field. This study aimed to develop an AEG model to evaluate student’s mechanical engineering Constructive Response Test (CRT) question responses which were instructor graded. Because of the small number of student responses (45), a synthesized set of responses was also generated by using text-to-text paraphrasing models. A neural network grading engine was built and trained to assess comprehension utilizing the Bidirectional Encoder Representation Transformer (BERT) and related models on student and synthesized responses. This study showed that the AEG based Natural Language Processing (NLP) model showed high accuracy and a higher degree of consistency in grading student responses compared to instructor-graded responses."
CONF,"J. Gao, Q. Yang, Y. Zhang, L. Zhang, S. Wang",,A Bi-modal Automated Essay Scoring System for Handwritten Essays,18-22 July 2021,2021,"During the past few decades, Automated Essay Scoring (AES) technology has been widely used to alleviate the workload of teachers and improve the feedback cycle in educational systems. However, the scoring of handwritten essays poses great challenges for existing systems, since most of them only take text as input without consideration of errors or bias which may be introduced by Optical Character Recognition (OCR) as a necessary pre-processing step. This paper proposes VisualAES, a bimodal automated essay scoring system that utilizes both textual and visual features for handwritten essay scoring. Specifically, we first employ three powerful pre-trained transformer-based models as the backbone, and extend them to take both textual features and visual features extracted by Faster R-CNN. Then, a stacking ensemble model is subsequently adopted to robustly map their outputs to a final score. We evaluate VisualAES with the public Automated Student Assessment Prize (ASAP) dataset and our proposed handwritten Chinese Students' handwritten essay dataset (ChnStd). Results show that the proposed VisualAES outperforms all state-of-the-art methods on both datasets. More importantly, by incorporating handwritten image information, we also achieve a further performance improvement on ChnStd and reduce the side effects of OCR."
JOUR,"Y. Song, Q. Zhu, H. Wang, Q. Zheng",,Automated Essay Scoring and Revising Based on Open-Source Large Language Models,2024,2024,"Manually scoring and revising student essays has long been a time-consuming task for educators. With the rise of natural language processing techniques, automated essay scoring (AES) and automated essay revising (AER) have emerged to alleviate this burden. However, current AES and AER models require large amounts of training data and lack generalizability, which makes them hard to implement in daily teaching activities. Moreover, online sites offering AES and AER services charge high fees and have security issues uploading student content. In light of these challenges and recognizing the advancements in large language models (LLMs), we aim to fill these research gaps by analyzing the performance of open-source LLMs when accomplishing AES and AER tasks. Using a human-scored essay dataset (n = 600) collected in an online assessment, we implemented zero-shot, few-shot, and p-tuning AES methods based on the LLMs and conducted a human–machine consistency check. We conducted a similarity test and a score difference test for the results of AER with LLMs support. The human–machine consistency check result shows that the performance of open-source LLMs with a 10 B parameter size in the AES task is close to that of some deep-learning baseline models, and it can be improved by integrating the comment with the score into the shot or training continuous prompts. The similarity test and score difference test results show that open-source LLMs can effectively accomplish the AER task, improving the quality of the essays while ensuring that the revision results are similar to the original essays. This study reveals a practical path to cost-effectively, time-efficiently, and content-safely assisting teachers with student essay scoring and revising using open-source LLMs."
CONF,"R. K. Reddy Chavva, S. Reddy Muthyam, M. S. Seelam, N. Nalliboina",,A Transformer-Based Approach for Enhancing Automated Essay Scoring,23-24 Aug. 2024,2024,"Automated essay scoring (AES) is a crucial technology for modern educational systems, providing a consistent and efficient method for evaluating written assignments. Traditional manual grading is often time-consuming, subjective, and prone to inconsistency, which can impact the quality of education and feedback. To address these challenges, we developed an AES system using the RoBERTa model, utilizing its advanced natural language processing capabilities. Our approach involved training and fine-tuning the RobERTa model on the Automated Student Assessment Prize (ASAP) dataset, which consists of diverse student essays graded by human raters. The model was trained to understand and replicate the scoring patterns and criteria used in the ASAP dataset, enabling it to predict accurate scores for new essays. The performance of our AES system was evaluated using the quadratic weighted kappa (QWK) metric, a standard measure for assessing agreement between predicted scores and human grades. Our system achieved a QWK score of 0.815, indicating a high level of accuracy and reliability in essay scoring. By ensuring consistent and objective grading, our AES system can support educators in delivering better learning outcomes. This result demonstrates the potential of the RoBERTa-based AES system to enhance the educational process through timely and fair assessments of student writing."
CONF,"M. Alobed, A. M. M. Altrad, Z. B. A. Bakar",,"A Comparative Analysis of Euclidean, Jaccard and Cosine Similarity Measure and Arabic Wordnet for Automated Arabic Essay Scoring",15-16 June 2021,2021,"The Coronavirus crisis has cast a shadow over the education sector; As it pushed schools, universities, and educational institutions to close their doors, to reduce the chances of its spread. This raised great concern among those affiliated with this sector, especially students preparing to take important exams. All this pushed educational institutions to switch to E-learning, as an alternative that has long been talked about over the need to integrate it into the educational process. From this standpoint, the importance of electronic exams as an alternative to the traditional paper exams appears, there are many assessment methods in E-learning, one of these assessments is the essay. The study used a variety of similarity tests and used an Arabic data set of 40 student answers. The results indicate that the Arabic Automated Essay System will improve with Cosine similarity and Arabic WordNet. Automatic Arabic Essay Scoring using WordNet is higher in terms of precision than the Automated Arabic Essay Scoring without using WordNet dependent on the mean absolute error value and Pearson correlation. The results clearly show the Cosine similarity with Arabic WordNet has the lowest error. Cosine similarity with all stemming types has the lowest error compared with the Jaccard and Euclidean similarity. Euclidean similarity has the highest error."
CONF,"T. Sasaki, T. Masada",,Sentence-BERT Distinguishes Good and Bad Essays in Cross-prompt Automated Essay Scoring,28 Nov.-1 Dec. 2022,2022,"Automated Essay Scoring (AES) refers to a set of processes that automatically assigns grades to student-written essays with machine learning models. Existing AES models are mostly trained prompt-specifically with supervised learning, which requires the essay prompt to be accessible to the system vendor at the time of model training. However, essay prompts for high-stakes testing should usually be kept confidential before the test date, which demands the model to be cross-promptly trainable with pre-scored essay data already in hands. Document embeddings obtained from pretrained language models such as Sentence-BERT (sbert) are primarily expected to represent the semantic content of the text. We hypothesize SBERT embeddings also contain assessment-relevant elements that are extractable by document embedding decomposition through Principal Component Analysis (PCA) enhanced with Normalized Discounted Cumulative Gain (nDCG) measurement. The identified evaluative elements in the entire embedding space of the source essays are then cross-promptly transferred to the target essays written on different prompts for binary clustering task of dividing high/low-scored groups. The result implies non-finetuned SBERT already contains evaluative elements to distinguish good and bad essays."
JOUR,"R. H. Chassab, L. Q. Zakaria, S. Tiun",,An Optimized LSTM-Based Augmented Language Model (FLSTM-ALM) Using Fox Algorithm for Automatic Essay Scoring Prediction,2024,2024,"The computer-based Automated Essay Scoring (AES) system automatically marks or scores student replies by considering relevant criteria. The methodology systematically categorises writing quality and can increase operational effectiveness in academic and major commercial institutions. To study the projected score, AES relies on extracting numerous aspects from the student’s response, including grammatical and textural information. However, the recovered features may result in dimensionality reduction and a challenging-to-understand feature selection procedure. As the number of parameters rises, the model also demands a large cost for processing and training the data. However, these problems worsen the accuracy of score prediction and widen the gap between actual and anticipated results. This study suggested the Fox-optimised Long Short-Term Memory-based Augmented Language Model (FLSTM-ALM) as a solution to these problems for giving successful training to text features; the model uses an augmented learning paradigm. The retrieval score was then analysed and generated using a neural knowledge encoder and retriever. The neural model successfully classifies the output based on this score. The best features are chosen using the Fox optimisation algorithm based on the food-searching category. This choice of parameters solves the exploration and optimisation issues with document classification. The performance of the optimised AES system was assessed using the two datasets, ASAP and ETS, and it demonstrated a high accuracy of 98.92% and a low error rate of 0.096%. Dimensionality reduction can thus be fixed by optimising the FLSTM-ALM model with an appropriate meta-heuristic method, such as the FOX algorithm, which raises the predicted accuracy, recall, and f1 score for the AES model."
CONF,"F. P. Putra, P. D. Purnamasari, A. A. P. Ratna, L. Santiar",,Comparison of MLP-BPNN and MLP-PSO for Automatic Essay Grading System for Japanese Language Exam,13-15 Oct. 2021,2021,"In this paper, a study was conducted for a hybrid model for Multilayer Perceptron (MLP) with Particle Swarm optimization (PSO). The PSO was used to replace the Backpropagation method for the weight optimization. The comparison was conducted between MLP-BPNN and MLPPSO for an automated essay grading system for Japanese language exam. The MLP-PSO model achieved a more accurate but less stable result. The MLP-PSO model with 10 particles trained for 15 steps achieves the best result out of the two MLP-PSO models tested, with an average 8.48% error for the grade population. Compared to the MLP-PSO model, it was discovered that MLP-BPNN with Adam optimizer achieves better overall performance and results concerning both the accuracy and the stability of the model."
CONF,"A. A. P. Ratna, R. R. Noviaindriani, L. Santiar, I. Ibrahim, P. D. Purnamasari",,K-Means Clustering for Answer Categorization on Latent Semantic Analysis Automatic Japanese Short Essay Grading System,22-24 July 2019,2019,"This paper discusses about the development of an automatic essay grading system for Japanese short essay answer by applying the K-Means Clustering to group each question's topic and Latent Semantic Analysis to make the assessment. The system is developed to help facilitate the examination of essay answers that are currently still being done manually. The development of the system itself is done by using Python programming language. The test scenarios were carried out by varying the types of hiragana and romaji input also the process of stopwords elimination. From the results obtained and the analysis carried out, the form or type of text input used and the use of parameter such as stopwords affect the accuracy of the assessment. The developed automatic essay grading system was able to obtain the highest accuracy rate of 89% by using input in the form of romaji letters and without the stopwords elimination process."
CONF,"A. Sethi, K. Singh",,Natural Language Processing based Automated Essay Scoring with Parameter-Efficient Transformer Approach,29-31 March 2022,2022,"Existing automated scoring models implement layers of traditional recurrent neural networks to achieve reasonable performance. However, the models provide limited performance due to the limited capacity to encode long-term dependencies. The paper proposed a novel architecture incorporating pioneering language models of the natural language processing community. We leverage pre-trained language models and integrate it with adapter modules, which use a bottle-neck architecture to reduce the number of trainable parameters while delivering excellent performance. We also propose a model by re-purposing the bidirectional attention flow model to detect adversarial essays. The model we put forward achieves state-of-the-art performance on most essay prompts in the Automated Student Assessment Prize data set. We outline the previous methods employed to attempt this task, and show how our model outperforms them."
CONF,"M. Alobed, A. M. M. Altrad, Z. Binti Abu Bakar",,An Adaptive Automated Arabic Essay Scoring Model Using the Semantic of Arabic WordNet,15-17 June 2021,2021,"An Automated Essay Grading (AEG) system is designed to be used in public schools, universities and companies, which is used to saving time and cost and to reduction in errors and unfairness due to human bias. The AEG widespread use and applied for multi-language such as English and French and others, but the researches in automated Arabic essay is limited. Therefore, this research introduces an Arabic Automated Essay Grading (AAEG). The aim of this research is to build a new model that is able to evaluate students' answers to Arabic essay questions with a score that is close to that provided by the teacher manually. The model relies on the semantic of Arabic WordNet model to achieve the accuracy and to avoid the weakness in stemming, after using a hybrid method in stemming with Arabic WordNet tables and using Arabic WordNet to search for all synonyms for all reference answer words so that students' marks don't oppress because they didn't write the same words reference answer."
CONF,"N. G. Pasaribu, G. Budiman, I. D. Irawati",,NasNet Model for Image-Based Essay Scoring Deep Learning,20-21 Aug. 2024,2024,"Automated essay grading systems have increasingly become a focal point in the educational landscape, primarily due to their potential to enhance the efficiency and objectivity of essay evaluation processes. Recognizing this potential, the paper presents an innovative strategy for automated essay grading that leverages the NasNetMobile architecture as its foundational model. The methodology outlined involves a meticulous data division according to specific question numbers, followed by a manual aggregation of scores assigned to each question to derive a final grade for every essay. Through rigorous exper-imentation, the paper identifies an optimal data partitioning strategy, revealing that a 60% split for testing coupled with a 40% allocation for training purposes culminates in a remarkable accuracy rate of 84%. The technical implementation of this system is executed using the Python programming language, TensorFlow Keras for machine learning model development, and Google Colab for project collaboration and resource sharing. The choice of the Adam optimizer, characterized by a learning rate of 0.002 and a batch size of 32, significantly contributed to the system's adeptness in precisely classifying students' essay scores. Demonstrated through these findings, our proposed automated essay grading system showcases its substantial capability to serve as an effective and reliable tool in assessing student essays, thereby holding considerable promise for future adoption and further development within educational settings."
CONF,J. Hoblos,,Experimenting with Latent Semantic Analysis and Latent Dirichlet Allocation on Automated Essay Grading,14-16 Dec. 2020,2020,"The demand of scoring natural language responses has created a need for new computational tools that can be applied to automatically grade student essays. Systems for automatic essay assessment have been commercially available since 1990's. However, the progress in the field was obstructed by a lack of qualitative information regarding the effectiveness of such systems. Most of the research in automatic essay grading has been associated with English writing due to its widespread use and the availability of more learner collection and language processing software for the language. In addition, there is large number of commercial software for grading programming assignments automatically. In this work, we investigate document semantic similarity based on Latent Semantic Analysis (LSA) and on Latent Dirichlet Allocation (LDA). We use an open-source Python software, Gensim, to develop and implement an essay grading system able to compare an essay to an answer-key and assign to it a grade based on semantic similarity between the two. We test our tool on variable-size essays and conduct experimental tests to compare the results obtained from human grader (professor) and those obtained from the automatic grading system. Results show high correlation between the professor grades and the grades assigned by both modeling techniques. However, LSA-based modeling showed more promising results than the LDA-based method."
CONF,"L. Saskia, I. Hidayah, S. S. Kusumawardani",,Improvement of GAN-LCS Performance with Synonym Recognition,13-14 Dec. 2022,2022,"Automatic Essay Scoring (AES) is an automatic scoring system that compares answer keys with answers given by students and calculates the similarity of answers using intelligent system algorithms. The advantage of automatic essay scoring is that a computerized scoring system can provide faster assessments than manual scoring. This study will use the GAN-LCS (Geometric Average Normalized-Longest Common Subsequence) and MMR (Maximum Marginal Relevance) combined with Synonym Recognition in the text pre-processing section to improve the system performance. Synonym Recognition will be processed after the stemming part. Our proposed methods resulted in an accuracy of 86.77%, a correlation of 0.891, RMSE of 1.434, and MAPE of 13.23%. In terms of accuracy, our proposed method has improved from the original GAN-LCS results. However, there was a sharp increase in time performance resulting in 87.26 seconds of time execution. This is due to the large number of words scanned and converted to the main word form. There is also the ambiguity of words after changing the word in the answer sentence to the main word based on the Thesaurus Dictionary."
JOUR,"F. S. Mim, N. Inoue, P. Reisert, H. Ouchi, K. Inui",,Corruption Is Not All Bad: Incorporating Discourse Structure Into Pre-Training via Corruption for Essay Scoring,2021,2021,"Existing approaches for automated essay scoring and document representation learning typically rely on discourse parsers to incorporate discourse structure into text representation. However, the performance of parsers is not always adequate, especially when they are used on noisy texts, such as student essays. In this paper, we propose an unsupervised pre-training approach to capture discourse structure of essays in terms of coherence and cohesion that does not require any discourse parser or annotation. We introduce several types of token, sentence and paragraph-level corruption techniques for our proposed pre-training approach and augment masked language modeling pre-training with our pre-training method to leverage both contextualized and discourse information. Our proposed unsupervised approach achieves a new state-of-the-art result on the task of essay Organization scoring."
CONF,"N. G. Pasaribu, G. Budiman, I. D. Irawati",,Image-Based Essay Scoring Deep Learning Using a CNN Model GoogLeNet,29-30 Aug. 2024,2024,"Automatic essay assessment is a crucial aspect of evaluating students' academic performance, but the manual grading process by educators is often time-consuming and subjective. This paper proposes using a deep learning application for automatic essay assessment by leveraging GoogLeNet Convolutional Neural Network(CNN) for handwriting analysis. The system aims to alleviate the workload of educators by allowing them to upload answer sheets for automatic grading. Students can access their results through a separate application. The system is designed to handle various handwriting styles through a preprocessing stage that involves cleaning answer sheets, extracting answer boxes, and removing empty spaces. Labelled data is then used to train the GoogLeNet model, which analyzes the answer sheets and provides scores based on student data containing 12 answer keys. The final scores are returned to students via the application. This study employs a 60 % and 40 % ratio for testing and training data, which yielded the best performance after experimenting with other ratios. Additionally, experiments were conducted to optimize hyperparameters, resulting in a learning rate of 0.002, Adam optimizer, and batch size of 32. Grading was performed for each question number, as they have different datasets, with an average accuracy of 85%. The lowest result was obtained for question 3b with a percentage of 45.83 %, while the highest result for question 3c was 100%. In conclusion, the use of GoogLeNet CNN for automatic essay assessment shows significant potential for improving the efficiency and accuracy of academic grading, although accuracy still varies across different question numbers."
CONF,"A. A. P. Ratna, N. A. Wulandari, A. Kaltsum, I. Ibrahim, P. D. Purnamasari",,Answer Categorization Method Using K-Means for Indonesian Language Automatic Short Answer Grading System Based on Latent Semantic Analysis,22-24 July 2019,2019,"The Automatic Short Answer Grading (Simple-O) has been created for grading short answer with Bahasa Indonesia using K-Means and Latent Semantic Analysis (LSA) method. In this experiment, the text document feature will be extracted using Term Frequency-Inverse Document Frequency (TF-IDF) and then classified using K-Means. From the experiment, 149 documents are expected to be clustered into five classes. The result of the clustering using K-Means is 100% matched with clustering using human rater. The result of grading with LSA is 74%."
JOUR,H. A. Abdeljaber,,Automatic Arabic Short Answers Scoring Using Longest Common Subsequence and Arabic WordNet,2021,2021,"The manual process of scoring short answers of Arabic essay questions is exhaustive, susceptible to error and consumes instructor's time and resources. This paper explores longest common subsequence (LCS) algorithm as a string-based text similarity measure for effectively scoring short answers of Arabic essay questions. To achieve this effectiveness, the longest common subsequence is modified by developing weight-based measurement techniques and implemented along with using Arabic WordNet for scoring Arabic short answers. The experiments conducted on a dataset of 330 students' answers reported Root Mean Square Error (RMSE) value of 0.81 and Pearson correlation r value of 0.94. Findings based on experiments have shown improvements in the accuracy of performance of the proposed approach compared to similar studies. Moreover, the statistical analysis has shown that the proposed method scores students' answers similar to that of human estimator."
CONF,"A. A. S. Mukti, S. A. I. Alfarozi, S. S. Kusumawardani",,Transformers Based Automated Short Answer Grading with Contrastive Learning for Indonesian Language,26-27 Oct. 2023,2023,"The rapid development of technology has impacted various sectors, including education. These developments have enabled e-Learning to thrive, especially during the Covid-19 pandemic. Evaluating student performance and understanding in e-Learning is typically done through quizzes. However, these evaluations, especially in essay grading, still require manual effort. This can lead to exhaustion and introduce bias and inconsistency into the scoring process. To address this issue, one possible solution is to develop an automated short-answer grading system. This research explores large language model that has a general understanding of language. This model is then subjected to a finetuning process. Specifically, this study employs BERT model, with contrastive learning method to develop an automated short-answer scoring system and compare its performance with similar systems. The model is composed of two components, namely the model body which utilizes BERT variation and the model head which employs logistic regression. The model body is structured in a siamese architecture. The results demonstrate an improvement in model performance of BERT model with constrastive learning. When compared to the pretrained BERT and BERT with cosine similarity finetuning, the reduction in prediction MAE is 21.72% and 9.90%, while for the RMSE metric, it is 17.79% and 13.80%. The transformers-based model with contrastive learning achieves metrics of 0.191 for MAE and 0.231 for RMSE. These findings indicate the potential of using the contrastive learning method in transformers models to develop an automated short-answer scoring system."
CONF,"S. S. Ibrahim, E. F. Elfakharany, E. Hamed",,Improved Automated Essay Grading System Via Natural Language Processing and Deep Learning,27-28 Oct. 2022,2022,"In order to evaluate students’ total skills, educators repeatedly utilize questions based on free text to evaluate students’ total skills. Yet, when correction is done manually errors occur in addition to long time periods used, hard work, high costs and different opinions as to how to correct papers, a single paper is corrected by multiple people to avoid partiality. Thus, the smart system for automatic grading can solve the problem. Here, we present a very advanced system for grading essays automatically. This is based on Natural Language Processing and Deep Learning technologies. Thus, we need a system to automatically grade essays with low costs, less time and more accurate scores. We need thus an inelegant system for correcting essay questions on an automatic basis. We introduced a method which encodes essays in the form of sequential embeddings. We then use a long Short Term Memory Network (LSTM) working in two directions in order to register semantic information. This method also focuses concentration on each essay in order to be taught how to focus on those materials which are authentic in articles. We can also thus get a good proof of the result of prediction. This BI LSTM may be utilized also to produce neural networks which have the sequence information in the two directions: from the future to the past (backwards) or vice versa, which is called Bidirectional Long Short-Term Memory (BI-LSTM) (past to future). In order to train and test, we utilized the popular set of essays presented in the Automated Student Assessment Prize by Kaggle. The smart system used for automatic grading, in our research, predicts grades in an up-to-date manner. Moreover, the smart system for autograding we have proposed has the ability to highlight important words and sentences, evaluate the logical relationships in meaning in a sentence and gives us in advance grades that can be explained."
CONF,"V. Sreevidhya, J. Narayanan",,Short descriptive answer evaluation using word-embedding techniques,6-8 July 2021,2021,"The score given for short answers may vary from instructor to instructor. There are many short answer grading and essay grading systems existing that are either automated or semi-automated. Automated grading systems reduce human effort, but no popular tool still exists. In this paper, we are focusing on short-answer grading systems. We use simple and effective methods to evaluate short descriptive student answers. The similarity between each student's answer with its model answer is evaluated using word embedding algorithms. The similarity score is used to calculate the score. The accuracy of the scores obtained in the case of each algorithm is calculated and analyzed method-wise."
CONF,"N. Noiyoo, J. Thutkawkornpin",,A Comparison of Machine Learning and Neural Network Algorithms for An Automated Thai Essay Quality Checking,28 June-1 July 2023,2023,"Checking the quality of essay writing in Thai language is still a complicated task because Thai language is very complex language in terms of punctuation, sentence structure, word repetition, spelling, commenting, and reasoning in content. Therefore, checking the quality of an essay and scoring require the reviewer's skills in reading and interpreting that make long time to review. In addition, if in reviewing process using more than one reviewer, it might affect different quality checking standards. We collected essay in Thai language which is written by student who registered paragraph writing course from The Sirindhorn Thai Language Institute of Chulalongkorn University. This work implemented LSTM model, CNN model, BERT model and WangchanBERTa model to compare the effectiveness of checking the quality of Thai essay writing. Our experimental result shows that classification analysis compiled with WangchanBERTa can achieve high accuracy up to 90%. However, CNN model compiled with classification analysis can achieve high accuracy up to 87% while compiled with regression analysis can achieve high accuracy in the range 90%. In conclusion, the system that we proposed can predict the quality of Thai essays with high accuracy. Therefore, we recommended Wangchanberta model for classification problem and CNN model for regression problem."
CONF,"R. Johnsi, G. B. Kumar",,Digital Essay Assessment using Machine Learning Algorithms,4-5 April 2024,2024,"Essay are considered as the most prominent way in assessing the student performance. Manual grading of the essay are considered to be a hectic tasks for both students and instructors due to various reasons such as time consuming, prone to subjectivity, inconsistencies and lack of reliability may be influenced by biases, such as prior knowledge of the student or their back ground. The solution to all these problems has been rectified by using Automated Essay Scoring (AES) system. This technical paper proposes a novel AES system that utilizes various Machine Learning (ML) algorithms such as Linear Regression, Lasso Regression, Ridge Regression, Gradient Boosting Regression, Bayesian Regression, Elastic Net Regression, Random Forest Regression, Decision Tree Regression, Gaussian Process Regression, Support Vector Regression, Polynomial Regression, XG Boost regression and XGBoost with Polynomial Features and discovered that XGBoost with Polynomial features achieved the best results with an average Quadratic Weighted Kappa (QWK) value of 0.68."
CONF,"S. Riyanto, F. A. Lestari, C. Putri Riyanto, A. Ferdiansyah, E. Irfiani, A. H. Akbar Maulana Siagian, Sriyadi, F. B. Siahaan, N. Fitria Apriani",,Employing SBERT for Essay Assessment,9-10 Oct. 2024,2024,"Conducting exams is important not only to evaluate the performance of students but also to analyze that of learning process. However, it is not easy and even time consuming to assess exams, especially for essays. To address such issues, it is worthwhile to have a system that can help in assessing exams. In this study, we aim to develop an automated essay scoring system to assess essay exams in Cibinong Mechanical Vocational High School, Bogor, Indonesia. We utilize semantic similarity evaluation and syntactic analysis to enhance the evaluation system of the Cibinong Mechanical Vocational High School for essay answers. Specifically, we employ Sentence Bidirectional Encoder Representation from Transformer (SBERT) as our model. Our SBERT model results show that they could perform an automatic assessment as good as the conventional one in evaluating the essay exams. In particular, the average mean absolute error (MAE) between human assessment and SBERT one was 0.26. Then, the SBERT model is adopted to develop the automated essay scoring system to help Cibinong Mechanical Vocational High School staff assess their students’ exams."
CONF,"M. M. Saeed, W. H. Gomaa",,An Ensemble-Based Model to Improve the Accuracy of Automatic Short Answer Grading,8-9 May 2022,2022,"Since 1966 much research has been done on the automatic grading of student answers task, and it was divided into short answer grading and essay scoring. In this paper, on the short answer grading challenge, we are working with text similarity approaches that are being classified into string, semantic (corpus and knowledge-based), and embedding text similarity approaches are the three types of text similarity techniques. On the Texas data-structure data set, different experiments were examined individually before being merged to give a maximum correlation result of 0.65."
CONF,"X. Nyomi, L. Moccozet",,Anatomy of a large-scale real-time peer evaluation system,7-9 Nov. 2022,2022,"In the past decades, we have seen benefits from digital education tools to increase interaction and allow for more regular assessment of students’ knowledge. The existing suggestions are however limited in how comprehensively they can assess students’ production skills based on the taught syllabus. There are some endeavours in the area of automated essay scoring, automated short answer grading or similar methods which would provide feedback without necessarily providing a grade. In terms, of rapid in class feedback of open ended questions there aren’t many helpful solution for the population we want to help. More suggestions which focus on the people either evaluating or being evaluated is necessary. Given the pressures of teaching at scale, how can human-centered technology aid in the development of comprehensive evaluation methods? In this paper, we suggest and implement a method to conduct qualitative evaluations for large scale settings in the context of undergraduate education. To do this, we use word vectors to visualize what students think in response to a prompt."
CONF,V. Latypova,,Intelligent Decision Support System for Assessing Works with Free Response based on Production Model,14-16 June 2023,2023,"Works with free response are usually used in training, as well as in engineering education. These works assessment faces a lot of challenges, especially in conditions of online learning. The use of criteria system underlies the formation of a score for work with free response. In the case of works like essays the assessment can be made without the participation of expert-tutor by means of automated essay scoring systems. In the other cases his engagement is required, and the assessment takes place usually manually with the use of a rubric. This procedure is very long and labour-intensive for tutors, particularly with the large number of works, which are to be assessed as quickly as possible. The challenge is further amplified by iterativeness of assessment procedure which is typical, for example, to term papers, productive and pre-diploma practice reports actively used in engineering education when students are as close as possible to real tasks implementation. Another question arises, because work assessment is carried out without consideration for work correction characteristics, that is why a formed score is inaccurate. A student work with free response assessment model based on production model that takes into account the efficiency of work correction made by student, and whose application allows to ease the formation of a score for work with free response, is proposed in the paper. The assessment model is implemented in an intelligent decision support system, which was used in assessing pre-diploma practice reports in Ufa State Aviation Technical University during online learning."
CONF,"T. Dasgupta, G. K. Singh, L. Dey",,Style Augmented Transformer Architecture for Automatic Essay Assessment,10-13 July 2023,2023,"In this paper, we present a grammar and style aware transformer-based neural network for computing the quality of a text in an automatic essay-scoring task. The proposed model takes into consideration different grammatical error categories and discourse writing styles like, concreteness, uncertainty, conviction and commitment in text along with the pre-trained language models of a text document. We have evaluated the proposed model with the automated student assessment dataset. Our preliminary investigation shows that incorporating such stylistic vectors and grammatical error categories with the BERT based language model can give us a better understanding of improving the overall evaluation of the input essays."
CONF,"E. Amadea Tanaka, S. Christian, Anderies, A. Chowanda",,Evaluating Back Translation and Misspelling Correction Utilization on Indonesian AES,3-4 Sept. 2024,2024,"This paper aims to tackle the problem of Automatic Essay Scoring (AES), a method used to predict whether an answer is correct given a question based on the provided guidelines and criteria. AES helps teachers to score student answers based on the guidelines fed into the model, saving time and decreases the human-error rate. We had chosen the UKARA challenge dataset, an Indonesian binary classification dataset consisting of two different questions separated into two datasets A and B. Prior studies utilized a stacking approach with XGBoost and a Neural Network model, achieving F1-scores of 88.4% and 75.9% for problem A and B respectively. The latest study utilizing the UKARA dataset used SBERT sentence embeddings and a Neural Network model, resulting in F1-scores of 89.4% for problem A and 75.7% for problem B. Although the F1-score for problem A was satisfactory, the F1-score for problem B remained relatively low. Therefore, this research aim to improve the performance of problem B. This research also discusses the various data augmentation techniques that can be applied to the dataset, such as back translation and misspelling correction Peter Norvig method. Based on the latest research, we decided to use SBERT sentence embeddings and neural networks for the model. The experiment managed to improve the result for problem B with a maximum F1-score of 77.2% along with 89.7% for problem A."
CONF,"Y. Salim, V. Stevanus, E. Barlian, A. C. Sari, D. Suhartono",,Automated English Digital Essay Grader Using Machine Learning,10-13 Dec. 2019,2019,"Automatic essay grader is a program that is designed to grade an essay automatically. Some of automatic essay grader have been made using string kernel, word embedding and reinforced learning method. The objective of this research is to develop an application to help users in grading English digital essays. Grading is done based on 12 score features. Argumentative and narrative essays written by junior high school students are utilized as the dataset. By using XGBoost as the classifier, this research produces an automated essay grader with an average accuracy of 66.87%. Evaluation is conducted using 5-fold cross validation method."
CONF,"A. -R. Muhammad, A. E. Permanasari, I. Hidayah",,Personalized Recommendation of Study Materials Based on Automatic Short Answer Scoring Results,15-16 Oct. 2022,2022,"The results of automatic short answer scoring (ASAS) can be used to provide learning recommendations. However, previous studies on ASAS are focused on the quality of the scoring method, without considering giving feedback on the student performance in the exam sessions. Moreover, research on feedback in the learning activity is more concentrated on creating an adaptive learning process. Therefore, this study aims to combine the Automatic Short Answer Scoring method and an Automatic Recommendation System to create an adaptive feedback system that has the ability to personalize the recommendation of study materials for the student based on their exam result. This study uses a dataset of ten questions, including one reference answer per question. The experiment result shows the recommendation system gives the maximum similarity score at 0.8972, with the maximum average score for all questions is 0.801. Future studies may continue to examine a technique for automatically generating study materials from various resources."
CONF,"G. Lv, W. Song, M. Cheng, L. Liu",,Exploring the Effectiveness of Question for Neural Short Answer Scoring System,18-20 June 2021,2021,"Automatic short answer scoring is a significant branch in the field of Natural Language Processing. It can release teachers from the complicated correcting work. It is an effective method for students to recognize their knowledge weakness as well. With the development of neural network and deep learning, researchers have built many neural models to resolve the problem. To the best of our knowledge, no one uses question as a feature in neural models. Starting from human experience and common sense, we explore the effectiveness of incorporating question into neural models for short answer scoring. The experimental results show that, on average, our model gains 1.1&#x0025; improvement compared to the state-of-art model."
CONF,"P. Shweta, K. Adhiya",,Comparative Study of Feature Engineering for Automated Short Answer Grading,17-19 June 2022,2022,"Recent advancement in the field of Natural Language Processing (NLP) has shown promising results in numerous NLP applications. Automated Short Answer Grading (ASAG) is one of the challenging applications of NLP. Understanding the underlying context and semantics in text will help to evaluate short answer responses and predict the scores more similar to human evaluator. Training machine to understand the domain knowledge of courses and utilize the same for evaluation has demanded for more robust method to generate word vectors which are capable of understanding the meaning of words based on context. In this paper we have studied and experimented with already existing word vector generation techniques TF-IDF, word2vec and BERT. Along with the pre-trained word2vec we have computed domain specific word vectors too. Finally, by the utilization of XGBoost we have computed the category of student answer. The comparison of similarity between human evaluated category and category generated by all studied embedding technique along with XGBoost algorithm is computed with the help of Quadratic Weighted Kappa. The results have shown that domain specific embedding will help to predict correct category of student answer."
CONF,"A. A. S. Mukti, S. A. I. Alfarozi, S. S. Kusumawardani",,Transformers Based Automated Short Answer Grading with Contrastive Learning for Indonesian Language,26-27 Oct. 2023,2023,"The rapid development of technology has impacted various sectors, including education. These developments have enabled e-Learning to thrive, especially during the Covid-19 pandemic. Evaluating student performance and understanding in e-Learning is typically done through quizzes. However, these evaluations, especially in essay grading, still require manual effort. This can lead to exhaustion and introduce bias and inconsistency into the scoring process. To address this issue, one possible solution is to develop an automated short-answer grading system. This research explores large language model that has a general understanding of language. This model is then subjected to a finetuning process. Specifically, this study employs BERT model, with contrastive learning method to develop an automated short-answer scoring system and compare its performance with similar systems. The model is composed of two components, namely the model body which utilizes BERT variation and the model head which employs logistic regression. The model body is structured in a siamese architecture. The results demonstrate an improvement in model performance of BERT model with constrastive learning. When compared to the pretrained BERT and BERT with cosine similarity finetuning, the reduction in prediction MAE is 21.72% and 9.90%, while for the RMSE metric, it is 17.79% and 13.80%. The transformers-based model with contrastive learning achieves metrics of 0.191 for MAE and 0.231 for RMSE. These findings indicate the potential of using the contrastive learning method in transformers models to develop an automated short-answer scoring system."
CONF,"N. Kazi, I. Kahanda",,Enhancing Transfer Learning of LLMs through Fine- Tuning on Task - Related Corpora for Automated Short-Answer Grading,15-17 Dec. 2023,2023,"Automated short-answer grading (ASAG) is a cru-cial element of any intelligent tutoring platform. Machine Learning (ML) has shown great promise for ASAG. However, this task remains challenging even for Deep Learning (DL) approaches and Large Language Models (LLMs), requiring semantic inference and textual entailment recognition. The SemEval-2013 Task 7, The Joint Student Response Analysis and 8th Recognizing Textual Entailment Challenge, is a benchmark widely used for research on ASAG. The SciEntsBank data included in this collection contains nearly 11,000 answers to 197 assessment questions in 15 different science domains. Despite the popularity, only a few researchers have explored the potential of DL or LLMs for this task. In this project, we explore the effectiveness of the RoBERTa Large model, an LLM trained on an extensive text corpus for language comprehension. By fine-tuning the model on the Multi-Genre Natural Language Inference (MNLI) corpus for semantic inference and subsequently on the SciEntsBank dataset, with a focus on the 3-way labels of correct, incorrect, and contradictory, we achieved a weighted Fl-score of 0.77, 0.72, and 0.72 on unseen answers, questions, and domains, respectively. Notably, our model significantly benefits from fine-tuning on the MNLI corpus, particularly in enhancing its performance on the contradictory class (which constitutes only 10% of the dataset) through transfer learning leading to significant improvements on the more challenging test sets: unseen questions and unseen domains."
CONF,"A. Divya, V. Haridas, J. Narayanan",,Automation of Short Answer Grading Techniques: Comparative Study using Deep Learning Techniques,22-24 Feb. 2023,2023,"Automatic short answer grading (ASAG) techniques have been shown to cut down on the time and work needed to grade exams, and it is a method that is becoming more and more common, especially with the rise in popularity of online courses. This study compares the results of 7 pre-trained embedding models using just one feature to automatically grade brief responses: the similarity between the model answer's and the student answer's embeddings. Regression models are developed and evaluated to predict a short answer's score based on the similarities between all pairs of answers in the Mohler dataset. The predictions are evaluated by comparing the Root Mean Squared Error (RMSE) and Pearson correlation scores of each model."
JOUR,"A. Sahu, P. K. Bhowmick",,Feature Engineering and Ensemble-Based Approach for Improving Automatic Short-Answer Grading Performance,1 Jan.-March 2020,2020,"In this paper, we studied different automatic short answer grading (ASAG) systems to provide a comprehensive view of the feature spaces explored by previous works. While the performance reported in previous works have been encouraging, systematic study of the features is lacking. Apart from providing systematic feature space exploration, we also presented ensemble methods that have been experimentally validated to exhibit significantly higher grading performance over the existing papers in almost all the datasets in ASAG domain. A comparative study over different features and regression models toward short-answer grading has been performed with respect to evaluation metrics used in evaluating ASAG. Apart from traditional text similarity based features like WordNet similarity, latent semantic analysis, and others, we have introduced novel features like topic models suited for short text, relevance feedback based features. An ensemble-based model has been built using a combination of different regression models with an approach based on stacked regression. The proposed ASAG has been tested on the University of North Texas dataset for the regression task, whereas in case of classification task, the student response analysis (SRA) based ScientsBank and Beetle corpus have been used for evaluation. The grading performance in case of ensemble-based ASAG is highly boosted from that exhibited by an individual regression model. Extensive experimentation has revealed that feature selection, introduction of novel features, and regressor stacking have been instrumental in achieving considerable improvement in performance over the existing methods in ASAG domain."
CONF,"Z. H. Amur, Y. K. Hooi, G. M. Soomro",,Automatic Short Answer Grading (ASAG) using Attention-Based Deep Learning MODEL,1-2 Dec. 2022,2022,"In artificial intelligence, automatic short answer grading (ASAG) sparked the interest of many researchers. These Systems are used to evaluate the student's performance based on their intellectual and cognitive skills. Unfortunately, short answer grading poses various challenges to assess individual abilities. The first challenge, short sentences can be 10 to 20 words long. These short sentences include primary and secondary keywords, identifying such keywords is a challenge for syntactic processing. Furthermore, the order and relationship among the words affect the actual meaning of the answers. Answers provided by students may not be syntactically correct. The second challenge is different question types included in the short text: - factoid, descriptive, short, and long questions. Different question types influence the intent of the answer which affects the precision of grading accuracy. As a result, strategies for overcoming these problems in the assessment are required. In this study, we have proposed the attention-based deep learning model known as bidirectional encoder representation from a transformer (BERT) for the evaluation of short subjective answers. The measurement findings indicate that the BERT model is effective for automatic short answer grading."
CONF,"S. L. P, S. J. B",,A Hybrid Qualitative and Quantitative Approach for Automatic Short Answer Grading Using Classification Algorithms,21-23 Dec. 2022,2022,"Assessment plays a very important role in the teaching-learning process. Recently proposed techniques for short answer grading are either Qualitative or Quantitative. Qualitative methods use classification and give scores in an incomprehensible way like correct, incorrect, partially correct, etc., and Quantitative methods use Regression and MSE(Mean Square Error) which assigns scores like 2.3,4.2, etc. requires a learning method to convert those values to integers. In this paper, a hybrid Qualitative Quantitative approach is proposed which is based on machine learning that relies on Multi-class classification where each category of marks is considered as a class. This can be easily converted to qualitative or quantitative systems without additional learning methods. This system follows a model answer-based method where various similarities are extracted from both model and student answers including statistical, Bag of Words, TFIDF, Latent Semantic Analysis, and Neural sentence embedding based Infersent. Using these features various classification models are designed including K Nearest Neighbor, Naïve Bayes, Decision tree, SVM, Random Forest, and XGBoost for various test sizes of the data and cross-validations. The models are tested on a dataset that consists of one question, 80 answers, and a model answer. In total, 72 experiments are conducted, demonstrating that the proposed hybrid approach can be effectively applied to the Automatic Short Answer Grading (ASAG) task."
CONF,"M. A. Sayeed, D. Gupta",,Automate Descriptive Answer Grading using Reference based Models,14-16 Dec. 2022,2022,"Global universities are establishing institutional setups that offer a hybrid format of education. The next step of education is to maintain quality and flexibility, such as providing the option to convert online courses such as Massive Open Online Courses (MOOCS) to course credits. However, several universities are reluctant to completely transition to online-based education due to poor digital experience in educational tools. The available evaluation tools such as Multiple-choice answers (MCQ) aren't able to evaluate students holistically. In this study, research work aims for an improvised reference-based approach (utilizing student and reference answers) that evaluates descriptive answers with the Siamese architecture- Roberta bi-encoder based transformer models for Automated Short Answer Grading (ASAG). The architecture was designed considering ASAG tasks constrained to feasible compute resources. The research work presents the competitive performance of the models, further improvised with finetuning and hyperparameter optimization process on the benchmark SemEval-2013 2way task dataset."
JOUR,"X. Zhu, H. Wu, L. Zhang",,Automatic Short-Answer Grading via BERT-Based Deep Neural Networks,1 June 2022,2022,"Automatic short-answer grading (ASAG) is a key component of intelligent tutoring systems. Deep learning is an advanced method to deal with recognizing textual entailment tasks in an end-to-end manner. However, deep learning methods for ASAG still remain challenging mainly because of the following two major reasons: 1) high-precision scoring requires a deep understanding of the answer text; and 2) ASAG's corpus is usually small and cannot provide enough training data for deep learning. To address these challenges, in this article, we propose a novel bidirectional encoder representation from transformer (BERT)-based deep neural network framework for ASAG. First, we use a pretrained and fine-tuned BERT model to dynamically encode the answer text, which can effectively overcome the problem of a too small corpus in the ASAG task. Second, to generate a powerful semantic representation for ASAG, we construct a semantic refinement layer to refine the semantics of the BERT outputs, which consists of a bidirectional-Long Short-Term Memory (LSTM) network and a Capsule network with position information in parallel. Third, we propose a triple-hot loss strategy for regression tasks in ASAG, which changes the gold label representation in the standard cross-entropy loss function from one-hot to triple-hot. Experiments demonstrate that our proposed model is effective and outperforms most of the state-of-the-art systems on both the SemEval-2013 dataset and the Mohler dataset. The code is available online at https://github.com/wuhan-1222/ASAG."
JOUR,"C. N. Tulu, O. Ozkaya, U. Orhan",,Automatic Short Answer Grading With SemSpace Sense Vectors and MaLSTM,2021,2021,"Automatic assessment of exams is widely preferred by educators than multiple-choice exams because of its efficiency in measuring student performance, lack of subjectivity when evaluating student response, and faster evaluation time than the time consuming manual evaluation. In this study, a new approach for the Automatic Short Answer Grading (ASAG) is proposed using MaLSTM and the sense vectors obtained by SemSpace, a synset based sense embedding method built leveraging WordNet. Synset representations of the Student's answers and reference answers are given as input into parallel LSTM architecture, they are transformed into sentence representations in the hidden layer and the vectorial similarity of these two representation vectors are computed with Manhattan Similarity in the output layer. The proposed approach has been tested using the Mohler ASAG dataset and successful results are obtained in terms of Pearson (r) correlation and RMSE. Also, the proposed approach has been tested as a case study using a specific dataset (CU-NLP) created from the exam of the “Natural Language Processing” course in the Computer Engineering Department of Cukurova University. And it has achieved a successful correlation. The results obtained in the experiments show that the proposed system can be used efficiently and effectively in context-dependent ASAG tasks."
CONF,"A. A. P. Ratna, N. A. Wulandari, A. Kaltsum, I. Ibrahim, P. D. Purnamasari",,Answer Categorization Method Using K-Means for Indonesian Language Automatic Short Answer Grading System Based on Latent Semantic Analysis,22-24 July 2019,2019,"The Automatic Short Answer Grading (Simple-O) has been created for grading short answer with Bahasa Indonesia using K-Means and Latent Semantic Analysis (LSA) method. In this experiment, the text document feature will be extracted using Term Frequency-Inverse Document Frequency (TF-IDF) and then classified using K-Means. From the experiment, 149 documents are expected to be clustered into five classes. The result of the clustering using K-Means is 100% matched with clustering using human rater. The result of grading with LSA is 74%."
CONF,"A. K. -F. Lui, S. -c. Ng, S. W. -N. Cheung",,An Interactive Short Answer Grading System Based on Active Learning Models,6-8 May 2022,2022,Grading automation can improve learning experience with quick around-the-clock feedback and superior grading consistency. Obtaining annotated data for training short answer grading models is costly. Active learning has been proven an effective approach to build accurate models with few annotated data. This paper presents an active learning approach of short answer grading that comprises of a few novelties. The first is a specialized active learning formulation adapted to short answer grading principles. The second is a proposal to exploit human expertise in fine-tuning several active learning model parameters for adaptation to the specifics of each grading task. The third is an interactive short answer grading system that is designed for building better quality grading model by informing users with data visualizations. The prototype presented in the paper should provide a useful conceptual demonstration for real-life deployment of active learning for short answer grading and further research in an enhanced interactive form of active learning.
CONF,"A. Ahmed, A. Joorabchi, M. J. Hayes",,On the Application of Sentence Transformers to Automatic Short Answer Grading in Blended Assessment,9-10 June 2022,2022,"In Natural Language Processing, automatic short answer grading remains a necessary launch-pad for the analysis of human responses in a blended learning setting. This study presents pre-trained neural language models that use context dependent Sentence-Transformers to automatically grade student responses with two different input settings. It is found that the use of these models achieves promising results when compared to conventional Bidirectional Encoder Representation Transformer, (BERT), approaches when applying various text similarity-based tasks. This work presents experiments using the benchmark Mohler dataset to test these new models. In summary, an excellent Pearson Correlation score of 0.82 and a Root Mean Square Error of 0.69 is exhibited across a representative experiment sample size."
JOUR,"M. Putnikovic, J. Jovanovic",,Embeddings for Automatic Short Answer Grading: A Scoping Review,1 April 2023,2023,"Automatic grading of short answers is an important task in computer-assisted assessment (CAA). Recently, embeddings, as semantic-rich textual representations, have been increasingly used to represent short answers and predict the grade. Despite the recent trend of applying embeddings in automatic short answer grading (ASAG), there are no systematic reviews of literature reporting on their usage. Therefore, following the PRISMA-ScR guidelines, this scoping review summarizes relevant literature on the use of embeddings in ASAG, and reports on the current state of the art in that research area and on the identified knowledge gaps. We searched seven research databases for the relevant journal, conference, and workshop papers published from 2016 to 2021. The inclusion criteria were based on the type of publication, its venue ranking, study focus, and evaluation methods. Upon the full-text screening, 17 articles were included in the scoping review. Among these, most of the articles used word embeddings, mainly to estimate the similarity of student and model answers using the cosine similarity measure or to initialize a neural network-based classification model. The contribution of embeddings to the performance of ASAG models compared to nonembedding features is inconclusive. Models employing embeddings were mostly evaluated on four public ASAG datasets using earlier ASAG methods as baselines. We summarize the reported evaluation results and draw conclusions on the performance of the state-of-the-art ASAG models."
CONF,"M. Iqbal, R. Laili Udhiah, T. Rana Nugraha, H. -K. Pao",,ASAGeR: Automated Short Answer Grading Regressor via Sentence Simplification,1-2 Dec. 2023,2023,"We propose an automated short answer grading system (ASAG) to estimate the student answer scores via text summarization from LLMs. The step of text summarization provides enough question answer normalization so that the summarized answers have the answer keys well organized and the grading based on that should be more accurate and easier than before, no matter the answers are graded by human or automatic graders. On the other hand, we also discuss the scenario when more than one grader are involved in the grading but providing inconsistent scores. We adopt a majority voting mechanism to overcome such difficulty and produce superior result in average. Overall the proposed methodology has its evaluation done to show the superiority to other state-of-the-art methods. The pre-trained transformer version 3.5 (GPT 3.5) is used to serve the text summarization tool given a well-designed prompt."
CONF,"R. Kothari, B. Rangwala, K. Patel",,Automatic Subjective Answer Grading Software Using Machine Learning,11-13 April 2023,2023,"One of the major challenges during online examinations is the assessment of answers, particularly of the subjective type. Subjective answers test a student's ability to retain information and express it in natural language. While objective questions have a correct fixed answer, subjective questions can have multiple correct answers. These answers can convey the same information while using a completely different language and grammatical syntax. This makes it difficult to automate the process of grading subjective questions and requires a lot of manual work hours. This study intends to automate the process of grading subjective questions using Machine Learning (ML) and Natural Language Processing (NLP). The study has compared the subjective answer with an ideal answer that is provided by the authority that creates the question. Based on the similarity between the two answers, a score is generated which can be mapped to an appropriate grade. The authors have provided a web application made using the Django framework for people to give online examinations and be automatically graded in near real-time. No machine learning model can be 100% accurate, so there is a functionality for admins to edit the grades."
JOUR,"M. Kaya, I. Cicekli",,A Hybrid Approach for Automated Short Answer Grading,2024,2024,"With the widespread use of distance learning, technological developments have also been applied in the field of education. The need for accurate and efficient assessment methods for online exams has become even more apparent, especially with remote learning taking place during the pandemic. For a more efficient evaluation process, we propose a hybrid model of the Automatic Short Answer Grading (ASAG) system based on Bidirectional Encoder Representation of Transformers (BERT). The usage of novel state-of-the-art natural language processing (NLP) techniques in our model enhances the comprehension of text. Specifically, we employ a customized multi-head attention mechanism adapted with BERT, which enables reliable identification of semantic dependencies among words within a sentence and therefore contributes to the effectiveness and trustworthiness of the scoring system. We use a parallel connection of CNN layers in our proposed BERT based ASAG system instead of their serial connection and this usage improves the performance of the system. The proposed model is assessed using common datasets frequently used for ASAG related research projects. In this evaluation process, our model produces much better results compared to other systems available in the literature."
CONF,"C. Senanayake, D. Asanka",,Rubric Based Automated Short Answer Scoring using Large Language Models (LLMs),4-4 April 2024,2024,"The manual grading of short answers presents challenges in education due to time constraints, especially with larger student populations, and suffers from subjectivity and bias, leading to inconsistencies. Larger student populations increase the time needed for individual assessment, leading to potential delays and subjectivity introduces biases, resulting in inconsistent evaluations. Moreover, as student numbers rise, the imbalance in teacher-to-student ratios affects grading quality, impacting fairness and effectiveness in educational assessments. Automated grading systems have emerged as a solution to address these issues. These grading systems mainly prioritize appearance, emphasizing grammar and format. However, they struggle to accurately assess content quality, often missing contextual relevance. This problem can potentially be resolved by employing highly trained domain-specific models. However, a drawback arises as these models are limited to evaluating answers only within predefined domains. While these specialized models excel in assessing responses within their designated fields, their utility is restricted when evaluating answers outside of these predefined domains. This limitation poses a challenge in achieving broader applicability for assessing answers outside the specific areas the models were trained for. This study proposes a rubric-based method paired with Large Language Models (LLMs) to introduce objectivity, ensuring fairness and reliability in evaluations while achieving generalizability. Rubric provides a clear and customizable marking schema for assessing short answers across various domains. By using predetermined marking criteria and conditions, the grading process becomes more objective and transparent. The proposed method efficiently evaluates short answers in various domains using Large Language Models (LLMs), based on these established criteria, reducing subjective biases. This research aims to revolutionize education by creating a robust automated short answer scoring system that comprehensively evaluates contents across domains and addresses teacher-to-student ratio issues."
CONF,"P. Akhilesh, A. K. K, S. K. Bharadwaj, M. Venugopalan",,Automated Short Answer Grading With Word Embedding-Based Semantic Similarity Using PySpark,16-18 May 2024,2024,"Automated short answer grading, a pivotal advancement in educational assessment methodologies, addresses scalability challenges and streamlines evaluation processes using natural language processing and machine learning. This technology ensures timely, consistent, and objective feedback, replacing manual grading to mitigate biases and variations, thus enhancing the educational experience. The proposed model employs Word2Vec to generate word embeddings for each student response and the corresponding reference answer. By leveraging cosine similarity, the model calculates semantic similarity between the vectors, producing a score ranging from 0 to 1. This cosine similarity score is then scalable, allowing for the computation of final grades based on question-specific weightage, providing a robust and scalable approach for automated short-answer grading. In the context of this work, regression-based evaluation metrics yielded a Mean Squared Error (MSE) of 0.2727 & R2 score of 0.67, demonstrating the efficacy of the automated grading system in achieving accurate and reliable assessments."
CONF,"U. K. Chakraborty, A. Mishra",,Automatic Short Answer Grading Using a LSTM Based Approach,29-30 July 2023,2023,"Short Answer Grading is an emerging application of Natural Language Processing and text processing. Automated Short Answer Grading (ASAG) is the process of evaluating student-written short responses using computer techniques like Machine learning. The ASAG task has been studied for a long time, but because of the difficulties in the research, it still attracts attention. One of the primary limitations of ASAG is the scarcity of domain-relevant training data. The job of ASAG can be approached using a variety of methods, which can be broadly divided between traditional methods using hand-crafted features and methods based on deep learning. Due to the growing popularity of this field, researchers have been using Deep Learning Approaches to address this challenge over the past five years. This paper explores the methods of creating an LSTM model, to test how close this approach will bring the machine score to that of the Human Score."
CONF,"M. Wagdy, F. Khaled, M. Saeed, H. Mansour, W. H. Gomaa",,Elevating Assessment: Advancing Short Answer Evaluation Through Embedding and Text Alignment,13-14 July 2024,2024,"This paper addresses the critical challenge of automating short answer grading, an increasingly essential task in educational settings. We present a novel approach that integrates the Abydos package, which includes 171 string similarity algorithms, with a machine learning framework utilizing a Random Forest regressor. This combination enables the efficient and effective evaluation of student responses by extracting and utilizing textual features systematically and achieved a 60.43% correlation score on the Texas Data structure dataset. Our experiments demonstrate the practicality and superiority of this methodology in enhancing grading consistency and reducing educators' workload. The findings highlight significant improvements in grading automation, showcasing its potential to facilitate and transform educational assessment practices."
CONF,"M. M. Saeed, W. H. Gomaa",,An Ensemble-Based Model to Improve the Accuracy of Automatic Short Answer Grading,8-9 May 2022,2022,"Since 1966 much research has been done on the automatic grading of student answers task, and it was divided into short answer grading and essay scoring. In this paper, on the short answer grading challenge, we are working with text similarity approaches that are being classified into string, semantic (corpus and knowledge-based), and embedding text similarity approaches are the three types of text similarity techniques. On the Texas data-structure data set, different experiments were examined individually before being merged to give a maximum correlation result of 0.65."
JOUR,"Y. Chen, J. Luo, X. Zhu, H. Wu, S. Yuan",,A Cross-Lingual Hybrid Neural Network With Interaction Enhancement for Grading Short-Answer Texts,2023,2023,"Automatic Short-Answer Grading (ASAG) is an application for recognizing textual entailment in smart education. With the continuous expansion of the application scope of artificial neural networks, many deep learning models have been applied to grading short-answer texts. However, the coding structures and interaction forms of existing models are still too simple to meet the requirements of the ASAG task, resulting in low scoring accuracy. To address these challenges, we propose a cross-lingual hybrid neural network with interaction enhancement for ASAG. First, we sequentially use a convolutional neural network and bidirectional Long Short-Term Memory (LSTM) network to encode the answer text. Then, we introduce an interaction enhancement layer consisting of reference-answer-to-student-answer and student-answer-to-reference-answer attentions, and we combine the attentions and their inputs to form enhanced representations of answer texts. Finally, we introduce two Siamese Bi-LSTM networks to fuse the enhanced representations of answer texts and combine their multiple pooled vectors for grade classification on a multi-linear prediction layer. The experimental results show that our model significantly improves the performance of various simple models for Chinese and English ASAG tasks. The code is available online at https://github.com/wuhan-1222/DL_ASAG."
CONF,"A. Prabhudesai, T. N. B. Duong",,Automatic Short Answer Grading using Siamese Bidirectional LSTM Based Regression,10-13 Dec. 2019,2019,"Automatic student assessment plays an important role in education - it provides instant feedback to learners, and at the same time reduces tedious grading workload for instructors. In this paper, we investigate new machine learning techniques for automatic short answer grading (ASAG). The ASAG problem mainly involves assessing short, natural language responses to given questions automatically. While current research in the field has focused either on feature engineering or deep learning, we propose a new approach which combines the advantages of both. More specifically, we propose a Siamese Bidirectional LSTM Neural Network based Regressor in conjunction with handcrafted features for ASAG. Extensive experiments using the popular Mohler ASAG dataset which contains training samples from Computer Science courses, have demonstrated that our system, despite being simpler, provides similar or better overall performance in terms of grading accuracy (measured with Pearson r, mean absolute error and root mean squared error) compared to state-of-the-art results."
CONF,"S. Kripalani, T. Lipare, D. Kadam",,Subjective Answer Grader using Semantic Similarity and Keyword Matching,5-7 April 2024,2024,"Subjective exams and tests have been a staple metric of student evaluation. These tests require students to give brief theoretical responses to the questions. Evaluation of subjective responses is based on the presence of certain facts, keywords, phrases that need to be mentioned. Traditional assessment of these tests requires an examiner to affirm the understanding of concepts by students through their answers. The human-dependant evaluation, however, is tedious, time consuming and is rarely impartial. The time constraints often mean that the examiner is unable to provide a detailed feedback to each and every student. This calls for the need to develop an objective automated grader system, which can investigate and analyze the student performances by considering different facets of learning based on semantic similarity. The enhanced BERT model, which has been fine-tuned, is utilized to capture the semantic characteristics found in the student’s response. In order to achieve this, the model compares the student’s response with the model answer and generates a model score based on the comparison. This model score is boosted through a keyword matching algorithm, which emphasizes the factual information contained within the student’s response. These final similarity scores are employed to offer comprehensive feedback that illuminates the specific areas in which the student’s comprehension may be lacking. Finally, the proposed approach is compared to other renowned algorithms like Cosine Similarity, Word Mover’s Distance, Paraphrase-mpnet, and Multi-qa-mpnet. The proposed system yields an experimental Mean Absolute Error (MAE) of 2.11, which is significantly better as compared to other algorithms."
JOUR,"R. M. Badry, M. Ali, E. Rslan, M. R. Kaseb",,Automatic Arabic Grading System for Short Answer Questions,2023,2023,"The era of technology and digitalization has been advantageous to the educational sector. The examination system is one of the most important educational pillars that have been affected. As automatic exam grading is a revolution in the history of exam development, and therefore the automatic grading system has started to replace the traditional assessment system. The automatic grading system allows the examiners to automatically assign grades for students’ answers compared to the model answers. And, generate results based on the examiners’ answers. In this paper, we especially address the short answer questions. Most research has been done on the English language. On the other side, few research works have been conducted on Arabic. Moreover, Arabic is considered one of the rare resource languages. This paper is aimed to build an Automatic Arabic Short Answer Grading (AASAG) model using semantic similarity approaches. It is used to measure the semantic similarity between the student and model answer. The proposed model is applied to one of the Arabic scarce publicly available datasets which is called (AR-ASAG). It contains 2133 pairs of models and student answers in several versions such as txt, xml, and db. The efficiency of the proposed model was evaluated through two conducted experiments using two weighting schemas local, and hybrid local and global weighting schema. The developed approach with hybrid local and global weight-based LSA achieved better results than using local weight-based LSA with (82.82%) as F1-score value, and 0.798 as an RMSE (Root-Mean-Square Error) value using hybrid local and global weight-based LSA."
CONF,"S. Forsyth, N. Mavridis",,Short Answer Marking Agent for GCSE Computer Science,14-17 March 2021,2021,"Teachers often spend a long time assessing work and examinations for students; automatic short answer grading dramatically reduces any time spent grading. Also is can be tough for teachers to be entirely unbiased when assessing work. Towards addressing this, a short answer automatic grading agent utilizing answer segmentation for GCSE Computer Science with semantic matching was designed and implemented using a four stage pipeline. The short answer marking agent has over a 96% accuracy rating and marks over 55% of student answers with the rest being referred for human grading. The human graded answers are then used to further automatically improve the system. In the future the agent could easily be extended to other subjects and used for staff training in a wide variety of areas or possibly even to form the basis for active tutoring systems."
CONF,"A. K. -F. Lui, S. -C. Ng, S. W. -N. Cheung",,Entropy-based Recognition of Anomalous Answers for Efficient Grading of Short Answers with an Evolutionary Clustering Algorithm,1-4 Dec. 2020,2020,"Short answer question is a common assessment tool eliciting a specific textual response for knowledge assessment. The divide-and-grade is an automated grading approach that uses clustering to assign answers into sets each of which is supposed to be sufficiently similar to receive the same grade. This approach can potentially produce accurate grading with significantly reduced manual grading effort. Many current clustering methods are known to suffer from the presence of anomalies, answers that are deviated from the modes of model answers or common misconceptions. The freedom afforded to the composition of answers often lead to these anomalies, and in particular, contextual anomalous answers that are marginally correct or wrong. This paper proposes an evolutionary clustering method for the divide-and-conquer approach. The method is coupled with anomalous answer recognition based on an entropy formulation of the cluster membership of answers for rectifying misclustered answers. The method has been evaluated with an open short answer grading dataset and the accuracy compares favorably with existing algorithms. Result analysis has suggested that the method can effectively leverage small manual grading effort on issues of great impact on short answer grading accuracy."
CONF,"V. Sreevidhya, J. Narayanan",,Short descriptive answer evaluation using word-embedding techniques,6-8 July 2021,2021,"The score given for short answers may vary from instructor to instructor. There are many short answer grading and essay grading systems existing that are either automated or semi-automated. Automated grading systems reduce human effort, but no popular tool still exists. In this paper, we are focusing on short-answer grading systems. We use simple and effective methods to evaluate short descriptive student answers. The similarity between each student's answer with its model answer is evaluated using word embedding algorithms. The similarity score is used to calculate the score. The accuracy of the scores obtained in the case of each algorithm is calculated and analyzed method-wise."
CONF,"S. Disa, Purnamawati, A. M. Idkhan",,Web e-Learning: Automated Essay Assessment Based on Natural Language Processing Using Vector Space Model,8-9 Oct. 2022,2022,"Automatic essay assessment aims to determine the value of essay and provides feedback based on a computer system. Using a computer-based system can make essay assessments more objective so that the students are more satisfied with the results they get. The assessment of the learning outcomes is very important for web e-learning systems. The application of the right algorithm can provide the right assessment results. This article aims to develop a web e-Learning system with the automatic essay answer scoring application based on natural language processing (NLP) with the text processing. It consists of tokenizing, stopward removal and stemming by using a vector space model algorithm to calculate the word weights. The feasibility validation test phase of application system was carried out by comparing between manual assessment and automatic assessment. The results of manual calculation shows the similaritty with a percentage of 82%. while the level of similarity of the automatic calculation system is 81.6%. The calculation value of similarity to all sample questiosn tested has a significant proximity."
CONF,"X. Nyomi, L. Moccozet",,Anatomy of a large-scale real-time peer evaluation system,7-9 Nov. 2022,2022,"In the past decades, we have seen benefits from digital education tools to increase interaction and allow for more regular assessment of students’ knowledge. The existing suggestions are however limited in how comprehensively they can assess students’ production skills based on the taught syllabus. There are some endeavours in the area of automated essay scoring, automated short answer grading or similar methods which would provide feedback without necessarily providing a grade. In terms, of rapid in class feedback of open ended questions there aren’t many helpful solution for the population we want to help. More suggestions which focus on the people either evaluating or being evaluated is necessary. Given the pressures of teaching at scale, how can human-centered technology aid in the development of comprehensive evaluation methods? In this paper, we suggest and implement a method to conduct qualitative evaluations for large scale settings in the context of undergraduate education. To do this, we use word vectors to visualize what students think in response to a prompt."
JOUR,"D. van der Linden, E. Williams, J. Hallett, A. Rashid",,The Impact of Surface Features on Choice of (in)Secure Answers by Stackoverflow Readers,1 Feb. 2022,2022,"Existing research has shown that developers will use StackOverflow to answer programming questions: but what draws them to one particular answer over any other? The choice of answer they select can mean the difference between a secure application and insecure one, as the quality of supposedly secure answers can vary. Prior work has studied people posting on Stack Overflow—a two-way communication between the original poster and the Stack Overflow community. Instead, we study the situation of one-way communication, where people only read a Stack Overflow thread without being actively involved in it, sometimes long after a thread has closed. We report on a mixed-method study including a controlled between-groups experiment and qualitative analysis of participants’ rationale (N=1188), investigating whether explanation detail, answer scoring, accepted answer marks, as well as the security of the code snippet itself affect the answers participants accept. Our findings indicate that explanation detail affects what answers participants reading a thread select (p<0.01), while answer score and acceptance do not (p>0.05)—the inverse of what research has shown for those asking and answering questions. The qualitative analysis of participants’ rationale further explains how several cognitive biases underpin these findings. Correspondence bias, in particular, plays an important role in instilling readers with a false sense of confidence in an answer through the way it looks, regardless of whether it works, is secure, or if the community agrees with it. As a result, we argue that StackOverflow's use as a knowledge base by people not actively involved in threads—when there is only one-way-communication—may inadvertently contribute to the spread of insecure code, as the community's voting mechanisms hold little power to deter them from answers."
JOUR,"Liu, Yuanchao, Han, Jiawei, Sboev, Alexander, Makarov, Ilya",GEEF: A neural network model for automatic essay feedback generation by integrating writing skills assessment,,,2024,"Assessing students' writing ability has always been an important component of research on automatic essay evaluation. The existing methods usually focus on outputting numerical scores, and there is little research on providing feedback on writing quality based on text generation techniques. We believe that the generation of quality feedback in essay writing is more valuable as a reference. In this study, we address the problem of essay feedback generation by proposing an encoder-decoder neural network model called GEEF (Generate Essay Feedback) and suppose that feedbacks are written based on the source essay text and the grading of important writing skills. Besides from the text of input essay, our model also takes in additional features including fluency, coherence, richness, and literary talent. We construct an essay feedback corpus along with human-tagged resources to facilitate the study. Experimental results demonstrate that the proposed approach achieves promising performance compared with other baseline methods on automatic and human evaluation metrics. The generated feedback sentences on different aspects of essay writing can help students understand their strengths and weaknesses in writing skills. In addition, the potential application of this study is that it can assist raters in writing more complex feedback on this basis, as it is often difficult to remember many commonly used feedback patterns when writing comments."
JOUR,"Lyashevskaya, Olga, Panteleeva, Irina, Vinogradova, Olga",Automated assessment of learner text complexity,,,2021,"EFL methodology has always recognized the importance of giving student learners of foreign languages regular and quick feedback on student production, both written and oral. The presented paper describes the decisions taken during the development of an application to measure text complexity, and shows how the results achieved with this application were translated into feedback related to the author’s language proficiency. Along with some standard text complexity features, this tool takes into account those that are significant for Russian learners of English. The application provides students with the statistics of the relevant linguistic features of the text in comparison with texts of the learner essays that were considered the top and the bottom levels in the learner corpus. The paper also points out what text features are especially relevant for the assessment of the essays written in English by Russian students. The choice was made possible after the analysis of 3440 texts from Russian Error-Annotated English Learner Corpus, and after applying methods of machine learning and statistical analysis to predict the grade that could be received for the essay."
JOUR,"Papageorgiou, Spyridon N., Koletsi, Despina, Patcas, Raphael, Seehra, Jadbinder, Cobourne, Martyn T., Will, Leslie A., Eliades, Theodore",Knowledge of evidence-based research methodology amongst orthodontic postgraduate residents in four universities: An international survey,,,2022,"Summary Aim The aim of this international survey was to assess knowledge concerning the design, conduct, critical appraisal and synthesis of clinical studies among senior orthodontic postgraduate residents. Materials and methods Senior postgraduate residents from four universities in Europe and the United States were invited to complete a custom questionnaire. The overall correct answer score and proportion of residents correctly answering each of the 10 questions within the survey were analysed with descriptive statistics, analysis-of-variance, chi-squares test and linear regression at 5%. Results A total of 46 residents with mean age of 30.4 years scored an overall % correct score of 48.8%±13.8%, with the % of correct answers to each question ranging from 7 to 89%. The worst-answered questions pertained to correctly characterizing sensitivity and specificity (7%), number needed to treat (9%), credibility of trial synthesis in meta-analysis (35%) and publication bias (37%). The vast majority of postgraduate students could correctly identify entities that can be blinded in a randomized trial (89%), statistical power of a trial (74%) and proper methods for random allocation sequence (67%). No statistically significant differences were found among the four included universities, while residents having obtained another degree apart from dentistry scored better than others (+9.5%; 95% confidence interval: 0.6% to 18.5%; P=0.04). Conclusions Postgraduate residents in orthodontics possessed moderate knowledge on evidence-based methodology. Efforts should be reinforced to assimilate research methodology perspectives in the postgraduate curricula of universities, in order to further augment critical training of orthodontic specialists."
JOUR,"Bonthu, Sridevi, Rama Sree, S., Krishna Prasad, M.H.M.",Improving the performance of automatic short answer grading using transfer learning and augmentation,,,2023,"The task of grading answers ranging from one phrase to one paragraph using computational techniques is known as Automated Short Answer Grading (ASAG). The performance of existing systems is not good enough due to limited data and the lack of availability of data in many domains. Many ASAG systems were developed as an outcome of the active research in this field. This study builds an effective system for grading short answers in the programming domain by leveraging Pre-trained Language Models and Text Augmentation. We fine-tuned three-sentence transformer models on the SPRAG corpus with five different augmentation techniques: viz., Random Deletion, Synonym Replacement, Random Swap, Backtranslation, and NLPAug. The SPRAG corpus contains student responses involving keywords and special symbols. We experimented with four different data sizes with the augmented data to determine the impact of training data on the fine-tuned sentence transformer model. this paper provides an exhaustive analysis of fine-tuning pretrained sentence transformer models with varying sizes of data by applying text augmentation techniques. we found that applying random swap and synonym replacement techniques together while fine-tuning has given a significant improvement, With a 4.91% increase in accuracy and a 3.36% increase in the F1-score. All the trained models are publicly available11https://github.com/sridevibonthu/SPRAG/tree/main/augmentation.."
JOUR,"Süzen, Neslihan, Gorban, Alexander N., Levesley, Jeremy, Mirkes, Evgeny M.",Automatic short answer grading and feedback using text mining methods,,,2020,"Automatic grading is not a new approach but the need to adapt the latest technology to automatic grading has become very important. As the technology has rapidly became more powerful on scoring exams and essays, especially from the 1990s onwards, partially or wholly automated grading systems using computational methods have evolved and have become a major area of research. In particular, the demand of scoring of natural language responses has created a need for tools that can be applied to automatically grade these responses. In this paper, we focus on the concept of automatic grading of short answer questions such as are typical in the UK GCSE system, and providing useful feedback on their answers to students. We present experimental results on a dataset provided from the introductory computer science class in the University of North Texas. We first apply standard data mining techniques to the corpus of student answers for the purpose of measuring similarity between the student answers and the model answer. This is based on the number of common words. We then evaluate the relation between these similarities and marks awarded by scorers. We consider an approach that groups student answers into clusters. Each cluster would be awarded the same mark, and the same feedback given to each answer in a cluster. In this manner, we demonstrate that clusters indicate the groups of students who are awarded the same or the similar scores. Words in each cluster are compared to show that clusters are constructed based on how many and which words of the model answer have been used. The main novelty in this paper is that we design a model to predict marks based on the similarities between the student answers and the model answer. We argue that computational methods be used to enhance the reliability of human scoring, and not replace it. Humans are required to calibrate the system, and to deal with situations that are challenging. Computational methods can provide insight into which student answers will be found challenging and thus be a place human judgement is required."
JOUR,"Li, Tuo Peter, Slocum, Stewart, Sahoo, Arpan, Ochuba, Arinze, Kolakowski, Logan, Henn III, Ralph Frank, Johnson, Alex A., LaPorte, Dawn M.",Socratic Artificial Intelligence Learning (SAIL): The Role of a Virtual Voice Assistant in Learning Orthopedic Knowledge,,,2024,"Objective We hypothesized that learning through multiple sensory modalities would improve knowledge recall and recognition in orthopedic surgery residents and medical students. Design We developed a virtual study assistant, named Socratic Artificial Intelligence Learning (SAIL), based on a custom-built natural language processing algorithm. SAIL draws from practice questions approved by the American Board of Orthopaedic Surgery and quizzes users through a conversational, voice-enabled Web interface. We performed a randomized controlled study using a within-subjects, repeated measures design. Setting Participants first took a pretest to assess their baseline knowledge. They then underwent 10 days of spaced repetition training with practice questions using 3 modalities: oral response, typed response, and multiple-choice. Recall and recognition of the practiced knowledge were assessed via a post-test administered on the first day, first week, and 2 months after the training period. Participants Twenty-four volunteers, who were medical students and orthopedic surgery residents at multiple US medical institutions. Results The oral, typed, and multiple-choice modalities produced similar recall and recognition rates. Although participants preferred using the traditional multiple-choice modality to study for standardized examinations, many were interested in supplementing their study routine with SAIL and believe that SAIL may improve their performance on written and oral examinations. Conclusions SAIL is not inferior to the multiple-choice modality for learning orthopedic core knowledge. These results indicate that SAIL can be used to supplement traditional study methods. Competencies medical knowledge; practice-based learning and improvement."
JOUR,"Guzmán-Valdivia Gómez, Gilberto, Domínguez-González, Alejandro D.",Estrategia didáctica con estudios de casos para el desarrollo del razonamiento clínico en estudiantes de Medicina. Estudio preliminar,,,2025,"Resumen Introducción el razonamiento clínico se va desarrollando, complementando lo aprendido con la información teórica y con lo que el alumno experimenta con sus pacientes. El objetivo del presente trabajo es evaluar si la enseñanza en la construcción de casos clínicos favorece la adquisición de habilidades de razonamiento clínico del estudiante de Medicina. Métodos se incluyeron a 48 estudiantes de Medicina. A todos ellos se les instruyó en una clase teórico práctica cómo construir un examen de casos clínicos estandarizados. Posteriormente, se dividieron en 2 grupos de 24 estudiantes cada uno, tomando en cuenta su grado académico. Al grupo A se les indicó construir 5 casos clínicos y al grupo B que analizaran 5 casos clínicos ya existentes. Se realizó una evaluación final con 10 casos clínicos estandarizados, elaborados por investigadores docentes, comparando 3 criterios: aciertos a las respuestas, calificación obtenida y rendimiento. Dos meses después se evaluaron ante estaciones de casos clínicos con paciente simulado, evaluando su desempeño y razonamiento clínico. Los grupos se compararon mediante t de Student de grupos independientes. Resultados en el grupo A, en el examen de casos, se obtuvo mayor número de aciertos, mejor calificación y rendimiento. Con relación al razonamiento clínico los estudiantes del grupo A evaluaron mejor precisión diagnóstica, correlación de datos, organización de la información y elaboración diagnóstica. Conclusión la construcción de casos clínicos por el propio estudiante ayuda a desarrollar su razonamiento clínico y, por lo tanto, puede ser utilizado como estrategia didáctica. Introduction Clinical reasoning is developed by complementing what is learned with theoretical information and what the student experiences with their patients. The present study aims to evaluate whether teaching in clinical case construction enhances the acquisition of clinical reasoning skills in medical students. Methods Forty-eight medical students were included. All of them were instructed in a theoretical and practical class on how to construct an examination of standardized clinical cases. Subsequently, they were divided into two groups of 24 students, each considering their academic degrees. Group A was instructed to construct five clinical cases, and group B was instructed to analyze five existing clinical cases. A final evaluation was conducted with ten standardized clinical cases prepared by teaching researchers, comparing three criteria: correct answers, grade obtained, and performance. Two months later, they were evaluated before clinical case stations with simulated patients, and their performance and clinical reasoning were evaluated. The groups were compared using the student's t-test of independent groups. Results In group A, in the case exam, a more significant number of correct answers, better grades, and better performance were obtained. About the CR, the students in group A evaluated better diagnostic accuracy, data correlation, organization of information, and diagnostic elaboration. Conclusion The construction of clinical cases by the student himself helps to develop his clinical reasoning and, therefore, can be used as a teaching strategy."
JOUR,"ElNaka, Abdelrahman, Nael, Omar, Afifi, Hadeel, Sharaf, Nada",AraScore: Investigating Response-Based Arabic Short Answer Scoring,,,2021,"There are more than 80 million students in the Arab world. Students take tests and examinations as an intrinsic part of their educational journey to assess the quality of learning and understanding of the examined material. Exams require an immense amount of resources to be conducted, but even a bigger amount of resources to be scored. Scoring of exams and papers takes up enormous time and effort from teachers all over the Arab world. This time and effort can be better utilized in other teaching activities that would elevate the quality of learning in the region. For that reason, the work presented in this paper investigates multiple supervised learning approaches for the domain of Arabic short answer scoring. Moreover, due to the scarcity of Arabic datasets, and to our knowledge, there is only one publicly available dataset for this specific task(AR-ASAG). Thus, we introduce a new publicly available dataset AraScore-Dataset. The model proposed is evaluated on 3 different datasets: 1-AraScore-Dataset 2-AR-ASAG 3-Two translated answer sets taken from the Hewlett Foundation SAS dataset. Based on the investigation, the most effective approach for Arabic automated short answer scoring is proposed, and the performance of using our dataset is compared to other publicly available datasets. The aim is to scale efficient and unbiased content scoring applications across different Arabic educational domains. The results showed that our newly developed response-based system and AraScore-Dataset have achieved state-of-the-art performance on Arabic Automated Short Answer Scoring."
JOUR,"Whitelock-Wainwright, Alexander, Laan, Nathan, Wen, Dunwei, Gašević, Dragan",Exploring student information problem solving behaviour using fine-grained concept map and search tool data,,,2020,"For learners to be successful in an information problem solving task, they should be able to effectively regulate their own behaviour. Despite views that such behaviour may come naturally to an individual, research generally shows that some learners do experience problems with information problem solving that may stem from such things as limited prior knowledge. As a means of addressing this challenge, the authors explored how the provision of both a concept map and search tool could overcome barriers to effective information problem solving. This was explored in the current study using data collected from 111 undergraduate students who completed an information problem solving activity, wherein a concept map and search tool were provided to help them write two short essays. Through the use of event-sequence analysis and hierarchical clustering, two information problem solving strategy groups were identified (High Engagement and Low Engagement), which differed across time-on-task and essay grades. Additional analyses were undertaken to explore self-reported prior knowledge or motivation as predictors of group assignment. The findings show that even when presented with opportunities (i.e., concept map) to support effective information problem solving, not all learners will take advantage or glean the benefits of such tools. Trace data methodology is shown to be a promising approach to explore information problem solving behaviour that can overcome the limitations of solely relying upon self-report measures."
JOUR,"Wilson, Joshua, Rodrigues, Jessica",Classification accuracy and efficiency of writing screening using automated essay scoring,,,2020,"The present study leveraged advances in automated essay scoring (AES) technology to explore a proof of concept for a writing screener using the Project Essay Grade (PEG) program. First, the study investigated the extent to which an AES-scored multi-prompt writing screener accurately classified students as at risk of failing a Common Core-aligned English language arts state test. Second, the study explored whether a similar level of classification accuracy could be achieved with a more efficient form of the AES-screener with fewer writing prompts. Third, the classification accuracy of the AES-scored screeners was compared to that of screeners scored for word count. Students in Grades 3–5 (n = 185, 167, and 187, respectively) composed six essays in response to multiple writing-prompt screeners on six different randomly assigned topics, consisting of two essays in each of three different genres (narrative, informative, and persuasive). Receiver operating characteristic (ROC) curve analysis was used to assess classification accuracy and to identify multiple cut scores with associated sensitivity and specificity values, and positive and negative posttest probabilities. Results indicated that the AES-scored multi-prompt screener and screeners with fewer prompts yield acceptable classification accuracy, are efficient, and are more accurate than screeners scored for word count. Overall, results illustrate the viability of writing screening using AES."
JOUR,"Al-azani, Samah Ali, Namrata Mahender, C., Hasan, Mohammed",Development of an Arabic HQAS-based ASAG to consider an ignored knowledge in misspelled multiple words short answers,,,2022,"Many traditional question answering systems depend on an Automatic Short Answer Grading (ASAG) to evaluate misspelled multiple words short answers in an Arabic Language using common edit-based algorithms such as Hamming, Levenshtein, and Jaro_Winkler, but they ignore and hide a big amount of a significant knowledge of the student answer. In this paper, we have implemented a proposed edit-based Hierarchical question answering system (HQAS) using a traversing by Breadth-First Search (BFS) within an m-ary tree to consider the ignored significant knowledge due to the misspelling at the middle of the dual-ordered incomplete answer, the misspelling at middle and the end of the intra-ordered incomplete answer, and the misspelling due to switching in words of the intra-ordered complete answer. It can differentiate among the students based on their significant hidden knowledge and show a distribution of knowledge content on different depths of the topic to determine which of the topic depths the student has the most significant knowledge."
